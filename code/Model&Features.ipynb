{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45ffa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Feature Extraction and model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca3fb60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TextBlob in c:\\users\\om\\anaconda3\\ai\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\om\\anaconda3\\ai\\lib\\site-packages (from TextBlob) (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\om\\anaconda3\\ai\\lib\\site-packages (from nltk>=3.1->TextBlob) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\om\\anaconda3\\ai\\lib\\site-packages (from nltk>=3.1->TextBlob) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\om\\anaconda3\\ai\\lib\\site-packages (from nltk>=3.1->TextBlob) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\om\\anaconda3\\ai\\lib\\site-packages (from nltk>=3.1->TextBlob) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\om\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk>=3.1->TextBlob) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "#importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import math\n",
    "!pip install TextBlob\n",
    "from textblob import TextBlob\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "03a74687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "train_df = pd.read_csv('python_comments_posts.csv')#dataset for training \"python tags\"\n",
    "test_df = pd.read_csv('C:\\\\Users\\\\om\\\\Downloads\\\\comments_1221.csv')#dataset for testing \"java tags\" from replicated paper\n",
    "\n",
    "test_df = test_df.rename(columns={\n",
    "    'questionID': 'QuestionId',\n",
    "    'answerID': 'answer_Id',\n",
    "    'commentID': 'commentId',\n",
    "    'UserId': 'OwnerUserId',\n",
    "    'CreationDate': 'CreationDate',\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06ee9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Extraction of Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b824000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining features\n",
    "def extract_features(df):\n",
    "    \n",
    "    users = dict(zip(train_df['OwnerUserId'], train_df['Score']))\n",
    "\n",
    "    # compute the number of comments on each post\n",
    "    post_comment_count = df.groupby('QuestionId')['commentId'].count().to_dict()\n",
    "\n",
    "    # compute the score of each post\n",
    "    Score = dict(zip(df['QuestionId'], train_df['Score']))\n",
    "\n",
    "    # Extract the comment features\n",
    "    df['comment_score'] = np.where(df['Score']>0, df['Score'], 0)\n",
    "    df['comment_order'] = df.groupby('QuestionId')['CreationDate'].rank(ascending=True)\n",
    "\n",
    "    # Extract the user features\n",
    "    df['by_asker'] = df['OwnerUserId'] == df['QuestionId']\n",
    "    df['by_answerer'] = df['OwnerUserId'] == df['answer_Id']\n",
    "    df['by_not_seen_commenter'] = (df['OwnerUserId'] != df['QuestionId']) & \\\n",
    "                                   (df['OwnerUserId'] != df['answer_Id']) & \\\n",
    "                                   ~(df['OwnerUserId'].isin(df.loc[df['QuestionId']==df['QuestionId'].shift(), 'OwnerUserId'])) & \\\n",
    "                                   ~(df['OwnerUserId'].isin(df.loc[df['answer_Id']==df['answer_Id'].shift(), 'OwnerUserId']))\n",
    "    df['by_seen_commenter'] = (df['OwnerUserId'] != df['QuestionId']) & \\\n",
    "                               (df['OwnerUserId'] != df['answer_Id']) & \\\n",
    "                               (df['OwnerUserId'].isin(df.loc[df['QuestionId']==df['QuestionId'].shift(), 'OwnerUserId'])) & \\\n",
    "                               ~(df['OwnerUserId'].isin(df.loc[df['answer_Id']==df['answer_Id'].shift(), 'OwnerUserId']))\n",
    "\n",
    "    # Replace NaN values in OwnerUserId column with -1\n",
    "    df['OwnerUserId'].fillna(-1, inplace=True)\n",
    "\n",
    "    # Define a function to map user IDs to reputations\n",
    "    def get_user_reputation(user_id):\n",
    "        if user_id == -1:\n",
    "            return 0 # Or any other default value you prefer\n",
    "        else:\n",
    "            return users[user_id]\n",
    "\n",
    "    # Apply the function to the OwnerUserId column\n",
    "    #df['user_reputation'] = df['OwnerUserId'].apply(get_user_reputation)\n",
    "    \n",
    "    \n",
    "    # extract the time features\n",
    "\n",
    "    df['CreationDate'] = pd.to_datetime(df['CreationDate'], infer_datetime_format=True)\n",
    "    df['CreationDate'].isnull().sum()\n",
    "    df['QuestionId'].duplicated().sum()\n",
    "\n",
    "    df['prev_post_edit_time'] = (df['CreationDate'] - df.groupby('QuestionId')['CreationDate'].shift(1)).dt.total_seconds().div(60).apply(lambda x: math.log(x) if x > 0 else 0)\n",
    "    df['next_post_edit_time'] = (df.groupby('QuestionId')['CreationDate'].shift(-1) - df['CreationDate']).dt.total_seconds().div(60).apply(lambda x: math.log(x) if x > 0 else 0)\n",
    "    df['prev_comment_time'] = (df['CreationDate'] - df.groupby('QuestionId')['CreationDate'].shift(1)).dt.total_seconds().div(60).apply(lambda x: math.log(x) if x > 0 else 0)\n",
    "    \n",
    "    # compute polarity and subjectivity of comment text\n",
    "    df['polarity'] = df['Text'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "    df['subjectivity'] = df['Text'].apply(lambda x: TextBlob(str(x)).sentiment.subjectivity)\n",
    "    \n",
    "\n",
    "\n",
    "    # text length\n",
    "    df['text_len'] = df['Text'].apply(len)\n",
    "\n",
    "    # starts with @\n",
    "    df['starts_with_@'] = df['Text'].str.startswith('@').astype(int)\n",
    "\n",
    "    # contains question mark\n",
    "    df['contains_question_mark'] = df['Text'].str.contains('\\?').astype(int)\n",
    "\n",
    "    # contains exclamation mark\n",
    "    df['contains_exclamation_mark'] = df['Text'].str.contains('\\!').astype(int)\n",
    "\n",
    "    # contains but\n",
    "    df['contains_but'] = df['Text'].str.contains(' but ').astype(int)\n",
    "\n",
    "    # contains exception\n",
    "    df['contains_exception'] = df['Text'].str.contains(' exception').astype(int)\n",
    "\n",
    "    # contains URL\n",
    "    url_pattern = r'http\\S+|www\\.\\S+'\n",
    "    df['contains_url'] = df['Text'].str.contains(url_pattern).astype(int)\n",
    "\n",
    "    # contains emotions\n",
    "    emoticon_pattern = r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)'\n",
    "    df['contains_emotions'] = df['Text'].str.contains(emoticon_pattern).astype(int)\n",
    "\n",
    "    # talks to role\n",
    "    df['talks_to_role'] = 0\n",
    "    df.loc[df['Text'].str.startswith('@questioner'), 'talks_to_role'] = 1\n",
    "    df.loc[df['Text'].str.startswith('@answerer'), 'talks_to_role'] = 2\n",
    "    df.loc[df['Text'].str.startswith('@'), 'talks_to_role'] = 3\n",
    "    \n",
    "    return df[['comment_score', 'comment_order', 'by_asker', 'by_answerer', \n",
    "               'by_not_seen_commenter', 'by_seen_commenter', 'prev_post_edit_time', 'next_post_edit_time', 'prev_comment_time','polarity', 'subjectivity','text_len', 'starts_with_@', 'contains_question_mark', 'contains_exclamation_mark', 'contains_but', 'contains_exception', 'contains_url','contains_emotions','talks_to_role']]\n",
    "\n",
    "\n",
    "#Function call\n",
    "train_df1 = extract_features(train_df)\n",
    "test_df2 = extract_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1fa16657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing for text feature extraction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e20bcca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess train and test text columns\n",
    "vectorizer = CountVectorizer(stop_words='english', lowercase=True)\n",
    "X_train = vectorizer.fit_transform(train_df['Text'])\n",
    "X_test = vectorizer.transform(test_df['Text'])\n",
    "\n",
    "# Convert categorical variable to binary variable\n",
    "y_train = train_df['need_update'].apply(lambda x: 1 if x == 'update' else 0)\n",
    "y_test = test_df['need_update'].apply(lambda x: 1 if x == 'update' else 0)\n",
    "\n",
    "# Extract features from train and test datasets\n",
    "train_features = train_df1[['comment_score', 'comment_order', 'by_asker', 'by_answerer','by_not_seen_commenter', 'by_seen_commenter', 'prev_post_edit_time', 'next_post_edit_time', 'prev_comment_time','polarity', 'subjectivity','text_len', 'starts_with_@', 'contains_question_mark', 'contains_exclamation_mark', 'contains_but', 'contains_exception', 'contains_url','contains_emotions','talks_to_role']]\n",
    "\n",
    "test_features = test_df2[['comment_score', 'comment_order', 'by_asker', 'by_answerer', 'by_not_seen_commenter', 'by_seen_commenter', 'prev_post_edit_time', 'next_post_edit_time', 'prev_comment_time','polarity', 'subjectivity','text_len', 'starts_with_@', 'contains_question_mark', 'contains_exclamation_mark', 'contains_but', 'contains_exception', 'contains_url','contains_emotions','talks_to_role']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8e77bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([pd.DataFrame(X_train.toarray()), train_features.reset_index(drop=True)], axis=1)\n",
    "X_test = pd.concat([pd.DataFrame(X_test.toarray()), test_features.reset_index(drop=True)], axis=1)\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "X_test.columns = X_test.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad9e0450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model buiding for feature extraction of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5f28959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy (only features): 0.5799, Precision: 0.7252, Recall: 0.3011, F1 score: 0.4255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\om\\anaconda3\\AI\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression (Features)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Testing  model\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate  model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Logistic Regression Accuracy (only features): {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4e0f83ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy(only features): 0.5807, Precision: 0.7333, Recall: 0.2964, F1 score: 0.4221\n"
     ]
    }
   ],
   "source": [
    "#Random Forest (Features)\n",
    "rm = RandomForestClassifier()\n",
    "rm.fit(X_train, y_train)\n",
    "\n",
    "# Testing  model\n",
    "y_pred = rm.predict(X_test)\n",
    "\n",
    "# Evaluate logistic regression model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Random Forest Accuracy(only features): {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "489c0552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Guassian Bayes Accuracy(only features): 0.4889, Precision: 0.5063, Recall: 0.4485, F1 score: 0.4756\n"
     ]
    }
   ],
   "source": [
    "#Guassian Bayes (Features)\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Testing  model\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate  model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f' Guassian Bayes Accuracy(only features): {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b84847a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing for TF-IDF Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b1bbf06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess train and test text columns\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_df['Text'])\n",
    "X_test = vectorizer.transform(test_df['Text'])\n",
    "\n",
    "# Convert categorical variable to binary variable\n",
    "y_train = train_df['need_update'].apply(lambda x: 1 if x == 'update' else 0)\n",
    "y_test = test_df['need_update'].apply(lambda x: 1 if x == 'update' else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8100439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model buiding for tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "187ebb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy (TF-IDF): 0.4898, Precision: 0.5250, Recall: 0.1331, F1 score: 0.2124\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression (TF-IDF)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Testing  model\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate  model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Logistic Regression Accuracy (TF-IDF): {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c7937f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy(TF-IDF): 0.5045, Precision: 0.5586, Recall: 0.1965, F1 score: 0.2907\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF Extraction (TF-IDF)\n",
    "rm = RandomForestClassifier()\n",
    "rm.fit(X_train, y_train)\n",
    "\n",
    "# Testing  model\n",
    "y_pred = rm.predict(X_test)\n",
    "\n",
    "# Evaluate logistic regression model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Random Forest Accuracy(TF-IDF): {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af0eee4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Guassian Bayes Accuracy(TF-IDF): 0.4930, Precision: 0.5113, Recall: 0.4295, F1 score: 0.4668\n"
     ]
    }
   ],
   "source": [
    "#Guassian Bayes (TF-IDF)\n",
    "\n",
    "X_train = X_train.toarray()\n",
    "X_test= X_test.toarray()\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Testing  model\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate  model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy Guassian Bayes Accuracy(TF-IDF): {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "66032cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing for features+tf-idf extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "166807fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess train and test text columns\n",
    "vectorizer = TfidfVectorizer(stop_words='english', lowercase=True)\n",
    "X_train = vectorizer.fit_transform(train_df['Text'])\n",
    "X_test = vectorizer.transform(test_df['Text'])\n",
    "\n",
    "# Convert categorical variable to binary variable\n",
    "y_train = train_df['need_update'].apply(lambda x: 1 if x == 'update' else 0)\n",
    "y_test = test_df['need_update'].apply(lambda x: 1 if x == 'update' else 0)\n",
    "\n",
    "# Extract features from train and test datasets\n",
    "train_features = train_df1[['comment_score', 'comment_order', 'by_asker', 'by_answerer','by_not_seen_commenter', 'by_seen_commenter', 'prev_post_edit_time', 'next_post_edit_time', 'prev_comment_time','polarity', 'subjectivity','text_len', 'starts_with_@', 'contains_question_mark', 'contains_exclamation_mark', 'contains_but', 'contains_exception', 'contains_url','contains_emotions','talks_to_role']]\n",
    "\n",
    "test_features = test_df2[['comment_score', 'comment_order', 'by_asker', 'by_answerer', 'by_not_seen_commenter', 'by_seen_commenter', 'prev_post_edit_time', 'next_post_edit_time', 'prev_comment_time','polarity', 'subjectivity','text_len', 'starts_with_@', 'contains_question_mark', 'contains_exclamation_mark', 'contains_but', 'contains_exception', 'contains_url','contains_emotions','talks_to_role']]\n",
    "\n",
    "X_train = pd.concat([pd.DataFrame(X_train.toarray()), train_features.reset_index(drop=True)], axis=1)\n",
    "X_test = pd.concat([pd.DataFrame(X_test.toarray()), test_features.reset_index(drop=True)], axis=1)\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "X_test.columns = X_test.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "428ee805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model buiding for features + tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "67b8371c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy (tf-idf + features): 0.5889, Precision: 0.7345, Recall: 0.3201, F1 score: 0.4459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\om\\anaconda3\\AI\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression (Features+tf-idf)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Testing  model\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate  model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Logistic Regression Accuracy (tf-idf + features): {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1ee29b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy (tf-idf + features): 0.5864, Precision: 0.7351, Recall: 0.3122, F1 score: 0.4383\n"
     ]
    }
   ],
   "source": [
    "#Random Forest (Features+tf-idf)\n",
    "rm = RandomForestClassifier()\n",
    "rm.fit(X_train, y_train)\n",
    "\n",
    "# Testing  model\n",
    "y_pred = rm.predict(X_test)\n",
    "\n",
    "# Evaluate  model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Random Forest Accuracy (tf-idf + features): {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "896161c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guassian NB Accuracy (tf-idf + features): 0.5004, Precision: 0.5214, Recall: 0.4057, F1 score: 0.4563\n"
     ]
    }
   ],
   "source": [
    "#Guassian NB (Features+tf-idf)\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Testing  model\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate  model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Guassian NB Accuracy (tf-idf + features): {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7748169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep learning CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3556f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_df['Text'])\n",
    "X_train = tokenizer.texts_to_sequences(train_df['Text'])\n",
    "X_test = tokenizer.texts_to_sequences(test_df['Text'])\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "640b7897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model building\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=32, input_length=maxlen))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "78813bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/19\n",
      "17/17 [==============================] - 1s 9ms/step - loss: 0.6952 - accuracy: 0.4761\n",
      "Epoch 2/19\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.6699 - accuracy: 0.5893\n",
      "Epoch 3/19\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.6535 - accuracy: 0.5884\n",
      "Epoch 4/19\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.6362 - accuracy: 0.5940\n",
      "Epoch 5/19\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.6119 - accuracy: 0.6595\n",
      "Epoch 6/19\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.5784 - accuracy: 0.7802\n",
      "Epoch 7/19\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.5360 - accuracy: 0.7970\n",
      "Epoch 8/19\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4867 - accuracy: 0.8195\n",
      "Epoch 9/19\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.4354 - accuracy: 0.8372\n",
      "Epoch 10/19\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.3832 - accuracy: 0.8765\n",
      "Epoch 11/19\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.3298 - accuracy: 0.9055\n",
      "Epoch 12/19\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2792 - accuracy: 0.9373\n",
      "Epoch 13/19\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.2325 - accuracy: 0.9616\n",
      "Epoch 14/19\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1894 - accuracy: 0.9747\n",
      "Epoch 15/19\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1540 - accuracy: 0.9869\n",
      "Epoch 16/19\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1240 - accuracy: 0.9925\n",
      "Epoch 17/19\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1002 - accuracy: 0.9935\n",
      "Epoch 18/19\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0812 - accuracy: 0.9944\n",
      "Epoch 19/19\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0664 - accuracy: 0.9963\n",
      "39/39 [==============================] - 0s 3ms/step - loss: 1.0825 - accuracy: 0.5061\n",
      "Accuracy: 50.61\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of model\n",
    "model.fit(X_train, y_train, epochs=19, batch_size=64)\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d6496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kp",
   "language": "python",
   "name": "kp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
