Id,PostTypeId,CreationDate,Score,ViewCount,Tags,Title,Body,POSTTYPEID,ACCEPTEDANSWERID,ParentId,score,OwnerUserId,LastEditoruserid,LastActivityDate,LastEditDate,AnswerCount,CommentCount,closed_date,Community_owned_date
33486,1,2018-06-21T19:09:41.640,0,515,<python><predictive-modeling><time-series>,Predict next month's loan balance from historical data,"<p>I work for a bank. Every month I get a list of 10,000 customers of the bank with the outstanding loan balance for each customer. I add them up and report the total outstanding balance every month. I have data for past 24 months.</p>

<p>I am asked to give a rough prediction of the next month's total outstanding balance. I am not a statistician, hence need some help. So far ,I have below ideas, can someone comment on pro/cons of each?</p>

<ol>
<li><p>Compute the average monthly % growth over last 6 months on Total balance; Multiply current balance by % growth  to predict next month balance</p></li>
<li><p>Do the same at an individual customer level, that gives us 10,000 predicted balances for next month. Add them up to get total balance</p></li>
<li><p>Are there any time series techniques I can use here?</p></li>
<li><p>Can I find the answer by some simulation techniques?</p></li>
</ol>
",1,33507,,0,10522,,2018-06-22T09:46:53.313,,1,2,,
27288,1,2018-01-31T11:23:54.903,2,3654,<python><neural-network><tensorflow><convolution>,TensorFlow: trainable_variables() is empty,"<p>I want to retrieve the list of trainable variables/weights in my model (wrapped in a <code>tf.Estimator</code>). However, <code>tf.trainable_variables</code> always returns an empty list, what am I doing wrong?</p>

<pre><code>import numpy as np
import pandas as pd
import sys
import globals
import pkg_resources
import numpy as np

import tensorflow as tf


def cnn_model_fn(features, labels, mode):

    input_layer = tf.reshape(features[""x""], [-1, 51, 13])
    input_layer = tf.cast(input_layer, tf.float32)

    # Convolutional Layer #1
    conv1 = tf.layers.conv1d(inputs=input_layer, filters=32, kernel_size=5, padding=""same"", activation=tf.nn.relu)

    # Pooling Layer #1
    pool1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2)

    # Convolutional Layer #2 and Pooling Layer #2
    conv2 = tf.layers.conv1d(inputs=pool1, filters=64, kernel_size=5, padding=""same"", activation=tf.nn.relu)

    # Pooling layer #2
    pool2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2)

    # flatten the feature map
    pool2_flat = tf.reshape(pool2, [-1, 12 * 64])

    # Dense Layer
    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)
    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)

    # Logits Layer
    logits = tf.layers.dense(inputs=dropout, units=5)

    predictions = {
        # Generate predictions (for PREDICT and EVAL mode)
        ""classes"": tf.argmax(input=logits, axis=1),
        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the `logging_hook`.
        ""probabilities"": tf.nn.softmax(logits, name=""softmax_tensor"")
    }

    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

    # Calculate Loss (for both TRAIN and EVAL modes)
    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)

    # Configure the Training Op (for TRAIN mode)
    if mode == tf.estimator.ModeKeys.TRAIN:
        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())
        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)

    # Add evaluation metrics (for EVAL mode)
    eval_metric_ops = {""accuracy"": tf.metrics.accuracy(labels=labels, predictions=predictions[""classes""])}

    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)

def main(unused_argv):

    total = pd.read_feather('testfile.feather')
    labels = total['labels']
    features = total.iloc[:, 16:679]

    mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=""/tmp/gait_convnet_model"")

    # Log the values in the ""Softmax"" tensor with label ""probabilities""
    tensors_to_log = {""probabilities"": ""softmax_tensor""}
    logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)    

    # Train the model
    train_input_fn = tf.estimator.inputs.numpy_input_fn(x={""x"": np.array(features)}, y=np.array(labels), batch_size=100, num_epochs=None, shuffle=True)
    mnist_classifier.train(input_fn=train_input_fn, steps=1, hooks=[logging_hook])

    temp_list = tf.trainable_variables()
    print(temp_list)

if __name__ == '__main__':
    tf.app.run()
</code></pre>
",1,30632,,2,42681,,2018-04-22T14:03:24.280,,1,3,,
2398,1,2014-11-04T00:58:00.137,3,429,<machine-learning><python>,Python Machine Learning Experts,"<p>I'd like to apply some of the more complex supervised machine learning techniques in python - deep learning, generalized addative models, proper implementation of regularization, other cool stuff I dont even know about, etc.</p>

<p>Any recommendations how I could find expert ML folks that would like to collaborate on projects?</p>
",1,2401,,3,4910,,2014-11-04T13:41:52.240,,1,3,2014-11-07T08:24:49.463,
92705,1,2021-04-07T16:52:58.057,1,304,<machine-learning><python><decision-trees><genetic-algorithms>,Are there any tree-based models that use a genetic algorithm to generate the trees?,"<p>I have a large dataset (195 features x 20m samples) that I have trained using XGBoost. I would like to see if a genetic algorithm can beat XGBoost since the data has so much noise it is prone to overfitting.</p>
<p>I would like to use a  tree-based model so I don't have to standardize the data, and the features do have some interrelationships.</p>
<p>Are there any python packages that have this all done? Ie.that can create trees through a genetic optimization process?</p>
",1,92706,,1,115595,,2021-04-07T17:08:23.217,,1,1,,
76523,1,2020-06-23T13:27:03.513,0,100,<python><classification><regex>,Separate business emails from personal emails,"<p>I am working on a classification problem where I would like to separate business emails from personal emails to analyse their behaviours separately. I am thinking about using regex but after looking at the emails, I realised that the email addresses vary significantly. Although I could manually spot some emails with obvious business names, such as xxx@carsales.com.au, it is hard to filter these emails systematically. Are there some useful techniques I could use? Thx</p>
",1,76584,,0,83084,,2020-06-24T09:58:14.260,,1,3,,
17533,1,2017-03-12T11:38:30.190,1,1138,<python><linear-regression>,Wrong output multiple linear regression statsmodels,"<p>I recently moved to python for data analysis and apparently I am stuck on the basics. I am trying to regress the parameters of the following expression: z=20+x+3*y+noise, and I get the right intercept but the x and y parameters are clearly wrong. What am I doing missing? Code below:</p>

<pre><code>import numpy as np
import pandas as pd
import statsmodels.formula.api as smf 

# generate true values, and noise around them
np.random.seed(5)
x = np.arange(1, 101)
y = np.arange(1, 101)
z = 20 + x + 3* y + np.random.normal(0, 20, 100)

data = pd.DataFrame({'x':x, 'y':y, 'z': z})

lm = smf.ols(formula='z ~ x + y', data=data).fit()

# print the coefficients
lm.summary()
</code></pre>

<p>returns </p>

<p><a href=""https://i.stack.imgur.com/kMaqG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kMaqG.png"" alt=""enter image description here""></a></p>

<p>where the x and y parameters are both 1.5, instead of being 1 and 3. What's wrong?</p>
",1,17546,,1,27768,,2017-03-13T03:02:32.520,,1,1,,
67768,1,2020-02-09T14:20:18.570,1,2673,<python><dataframe>,Convert CSV from an api to a dataframe format in python,"<p>I am new to python, I have extracted some reviews from a website and I used the api  of the webscrapping tool to import my data in python and the format is in csv. I want to convert this csv to a dataframe in python. Can someone guide me on how to perform this please.</p>

<p>Below is the code for importing the api extraction in csv format.</p>

<pre><code>import requests

params = {
  ""api_key"": ""abc"",
  ""format"": ""csv""
}
r = requests.get('https://www.parsehub.com/api/v2/runs/ttx8PT-EL6Rf/data', params=params)
print(r.text)
</code></pre>

<p>My output for the above codes are as follows:</p>

<pre><code>""selection1_name"",""selection1_url"",""selection1_CommentID_name"",""selection1_CommentID_Date"",""selection1_CommentID_comment""
""A"",""https://www..html"",""137"",""February 02, 2020"",""I enjoy the daily package from the start with the welcoming up to the end.
I recommend this hotel.""
""A"",""https://www.e a lot. Relaxing moments with birds chirping, different swings to chill. Overall, I shall visit again. Thanks Azuri &amp; Marideal.""
""A"",""https://www.html"",""17"",""June 12, 2019"",""Had an amazing stay for 2 nights.
The cleanliness of the room is faultless""
""B"",""https://www.html"",""133"",""April 16, 2019"",""Had a good time. Food is good.""
</code></pre>

<p>etc...
Can you please help me to convert this into a dataframe in python please please.</p>
",1,67787,,1,89502,89502,2020-02-09T18:46:13.080,2020-02-09T18:41:51.560,1,16,,
66201,1,2020-01-09T16:05:17.217,3,171,<python><nlp><text-filter>,Method to assess text credibility,"<p>I am searching for an automated method (ideally a python package) that produces a score to assess the <em>credibility</em> of a given text (e.g. from a webpage).</p>

<p>I am <strong>not</strong> searching for: </p>

<ul>
<li>text <em>complexity</em> assessments (i.e. how long sentences are and how many difficult words are used) as for example flesch reading ease, smog
index, flesch kincaid grade, coleman liau index, automated
readability index, dale chall readability score, difficult words
index, linsear write formula, or gunning fog.</li>
<li>text <em>coherence</em> (i.e. how well the next sentence fit with the previous one) as for example <a href=""https://arxiv.org/pdf/1710.07770.pdf"" rel=""nofollow noreferrer"">Text Coherence Analysis Based on Deep Neural Network</a></li>
</ul>

<p>Why is complexity/coherence not the same credibility? Because many texts advertising for example homeopathy use long complex scientifically sounding and complex word loaded sentences while being nonsense in terms of trueness. Therefore I am wondering if there is any method to assess the credibility/reliability of a given piece of text/webpage information automatically? </p>
",1,66408,,3,88079,,2020-01-29T10:00:56.367,,2,1,,
24093,1,2017-10-26T12:36:27.727,71,166551,<python><anaconda>,How to clone Python working environment on another machine?,"<p>I developed a machine learning model with Python (Anaconda + Flask) on my workstation and all goes well. Later, I tried to ship this program onto another machine where of course I tried to set up the same environment, but the program fails to run. I copied the program to other machines where it also runs smoothly.</p>

<p>I cannot figure out what the problem is in the failed case (both the program code and the error message are copious so I am not able to present them here) but I'm almost certain that it is something with the different versions of the dependencies.</p>

<p>So, my question is that given an environment where a certain program runs well, how can I clone it to another where it should run well also? Of course, without the cloning of the full system ;)</p>
",1,24096,,71,21560,29169,2022-07-29T13:31:51.463,2019-06-20T00:33:49.773,9,1,,
15075,1,2016-11-12T14:35:25.700,4,5975,<python><predictive-modeling><time-series><feature-selection><feature-extraction>,Use TSFRESH-library to forecast values,"<p>Have some issue with understanding how to use TSFERSH-library (version 0.4.0) to forecast next N-values of particular series. Below my code:</p>

<pre><code>    # load data train/test datasets        
    train, Y, test, YY = prepare_train_test()
    # add series ID         
    train['TS_ID'] = pd.Categorical(train['QTR_HR_START']).codes
    test['TS_ID'] = pd.Categorical(test['QTR_HR_START']).codes
    # add ordered id for concrete event of series
    for id in sorted(train['TS_ID'].unique()):
        train.ix[train.TS_ID == id, 'TIME_ORDER_ID'] =  pd.Categorical(train[train.TS_ID == id]['DATETIME']).codes
    for id in sorted(test['TS_ID'].unique()):
        test.ix[test.TS_ID == id, 'TIME_ORDER_ID'] = pd.Categorical(test[test.TS_ID == id]['DATETIME']).codes
    # perform feature extraction for my signal
    extraction_settings = FeatureExtractionSettings()
    extraction_settings.IMPUTE = impute  # Fill in Infs and NaNs
    X = extract_features(train, column_id='TS_ID', feature_extraction_settings=extraction_settings).values
    XT = extract_features(test, column_id='TS_ID', feature_extraction_settings=extraction_settings).values

    # there should be as example 
    # model = xgb.DMatrix(X, label=Y, missing=np.nan)
    # model.fit()
    # model.predict(XT)
</code></pre>

<p>However, after line <code>X = extract_features(...)</code> I see at debugger following results
 <a href=""https://i.stack.imgur.com/tHkeu.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tHkeu.png"" alt=""enter image description here""></a></p>

<p>It's mean that initial <code>X-dataset/features</code> (shape=(722,10) were transformed to shape (80, 1899). </p>

<p>Where does '80' come from? I guess from <code>train.TS_ID</code> comes. But my <code>XT</code>-dataset still contains 722-rows (9 days * 80 different series per day). </p>

<p>So, how can I predict for 9 days in advance? or is there only forecast for next period?</p>
",1,22893,,4,14684,14684,2020-08-04T10:54:19.500,2016-12-27T11:11:00.680,1,5,,
45856,1,2019-02-20T06:30:01.623,5,1878,<machine-learning><python><nlp><nltk><regex>,"Machine learning or NLP approach to convert string about month ,year into dates","<p>I'm currently in the process of developing a program with the capability of converting human style of representing year into actual dates.
Example : <strong>last year last month</strong> into <strong>December 2018</strong>
string may be complete sentence like : <strong>what were you doing 5 years ago</strong> </p>

<p>it will gives <strong>2014</strong></p>

<p>The purpose is to evalute human style of represting year or date into actual date, i have created collection of this type of strings and matching them with regex.</p>

<p>I have read some machine learning but I'm not sure which algorithm suits this problem the best or if I should consider using NLP.</p>

<p>Does anyone have a suggestion of what algorithm to use or where I can find the necessary literature to solve my problem?</p>

<p>Thanks for any contribution!</p>
",1,45990,,5,63693,,2020-08-07T07:24:06.313,,3,2,,
57608,1,2019-08-15T18:06:37.827,2,403,<python><pandas><data-cleaning>,Filtering a panda dataframe in one line,"<p>I had the following data-cleaning question in an interview test that I struggled on (I've changed the details to anonymise it and protect the company's interview process)</p>

<blockquote>
  <p>Given the following dataframe <code>df</code>, return a new series with <code>day</code> as the index, and a single column with the set of meals consumed by everyone who ate that day (i.e, <em>both</em> Alice and Bob on days 1 and 3, but <em>only</em> Alice on day 2). Do not use for loops or list comprehensions, only method chaining and a single lambda function that accepts only a single argument.</p>
</blockquote>

<pre class=""lang-py prettyprint-override""><code>df = pd.DataFrame({'day':[1, 2, 3, 1, 3]*3,
                   'person':['Alice', 'Alice', 'Alice', 'Bob', 'Bob']*3,
                   'meal':['breakfast', 'breakfast', 'breakfast', 'breakfast', 'breakfast']+
                          ['lunch', 'brunch', 'brunch', 'lunch', 'lunch']+
                          ['dessert', 'dinner', 'snack', 'beer', 'dessert']
                  })
</code></pre>

<p>In other words, the goal is to obtain the following dataframe:</p>

<pre class=""lang-py prettyprint-override""><code>goal = pd.DataFrame({'day':[1, 2, 3], 
                     'meal':[{'breakfast', 'lunch'}, 
                             {'breakfast', 'brunch', 'dinner'},
                             {'breakfast'}]
                    }).set_index('day')
</code></pre>

<p>Does anyone know how to do this? Thanks!</p>
",1,57950,,2,45573,,2019-08-21T11:01:35.493,,1,4,,
73151,1,2020-04-28T12:42:59.263,0,205,<python><data-mining><similarity><bert><topic-model>,How to identify topic transition in consecutive sentences using Python?,"<p>I'm new to data mining. I want to detect topic transition among consecutive sentences. For instance, I have a paragraph (this could be a collection of dozens of sentences, sometimes without transitional words) as follows:</p>
<blockquote>
<p>As I really like Mickey Mouse, I was hopping to go to Florida. But my
dad took me to Nevada. Obviously, Mickey Mouse was not there. But, I
attended a camp with other children. And, I really enjoyed and learnt a lot from my
camp.</p>
</blockquote>
<p>Here, I want to automatically split this into following sub-paraphs:</p>
<blockquote>
<ol>
<li><p>As I really like Mickey Mouse, I was hopping to go to Florida. But my
dad took me to Nevada. Obviously, Mickey Mouse was not there.</p>
</li>
<li><p>But, I attended a camp with other children. And, I really enjoyed and learnt a lot from my
camp.</p>
</li>
</ol>
</blockquote>
<p>As far as I know, this is not the sentence similarity measurement. What technique should be used here? Any example using python or tensorflow models would be greatly appreciated.</p>
",1,73161,,0,95955,-1,2020-04-28T16:55:45.557,2020-06-16T11:08:43.077,1,6,,
47014,1,2019-03-09T23:27:28.590,2,743,<python><predictive-modeling><prediction><data-science-model>,Forecasting ticket sales and city,"<p>I am learning data science. I have the following dataset for train tickets:</p>

<pre><code>1. order_date_meduim

order,date,medium
95062,2017-09-11,35
171081,2017-07-05,39
122867,2017-08-18,39
107186,2017-11-23,
171085,2017-09-02,

2. order_ordercityA_ordercityB [some order has only 1 ordercity, I think ordercity means here which city is something like source and destination]

order,ordercityA,ordercityB
81773,4,11
105838,4,
76153,24,18
93058,12,
11623,24,3
3070,24,3

3. order_ticketcount,ticketclass

order,ticketcount,ticketclass
246783,1,pax
1693998,2,pax
1958576,1,other
673681,1,pax
1593899,1,pax
194035,1,pax
</code></pre>

<p>I need to forecast the ticket sales for a week and also the ordercity with medium of booking. </p>

<p>As I am new, could someone give a possible answer about how to create a prediction model that could predict the sales for 1 week? Also, I doubt the data is time-series data. </p>

<p>I code in Python.  </p>
",1,47344,,2,29033,29033,2019-03-17T15:31:53.887,2019-03-09T23:40:59.047,3,1,,
41400,1,2018-11-19T06:09:30.727,0,122,<machine-learning><python><random-forest><decision-trees><xgboost>,Why xgboost can not deal with this simple sentence case?,"<p>There is only 1 feature dim. But the result is unreasonable. The code and data is below. The purpose of the code is to judge whether the two sentences are the same.</p>

<p><strong>In fact, the final input to the model is: feature is [1] with label 1, and feature is [0] with label 0.</strong></p>

<p>The data is quite simple:</p>

<hr>

<p>sent1 sent2 label</p>

<p>我想听 我想听 1</p>

<p>我想听 我想说 0</p>

<p>我想说 我想说 1</p>

<p>我想说 我想听 0</p>

<p>我想听 我想听 1</p>

<p>我想听 我想说 0</p>

<p>我想说 我想说 1</p>

<p>我想说 我想听 0</p>

<p>我想听 我想听 1</p>

<p>我想听 我想说 0</p>

<p>我想说 我想说 1</p>

<p>我想说 我想听 0</p>

<p>我想听 我想听 1</p>

<p>我想听 我想说 0</p>

<p>我想说 我想说 1</p>

<p>我想说 我想听 0</p>

<p>我想听 我想听 1</p>

<p>我想听 我想说 0</p>

<p>我想说 我想说 1</p>

<p>我想说 我想听 0</p>

<hr>

<pre><code>import pandas as pd
import xgboost as xgb
d = pd.read_csv(""data_small.tsv"",sep="" "")


def my_test(sent1,sent2):
    result = [0]
    if ""我想说"" in sent1 and ""我想说"" in sent2:
        result[0] = 1
    if ""我想听"" in sent1 and ""我想听"" in sent2:
        result[0] = 1
    return result

fea_ = d.apply(lambda row: my_test(row['sent1'], row['sent2']), axis=1).tolist()

labels = d[""label""].tolist()
fea = pd.DataFrame(fea_)
for i in range(len(fea_)):
    print(fea_[i],labels[i])

labels = pd.DataFrame(labels)
from sklearn.model_selection import train_test_split
# train_x_pd_split, valid_x_pd, train_y_pd_split, valid_y_pd = train_test_split(fea, labels, test_size=0.2,
#                                                                                random_state=1234)

train_x_pd_split = fea[0:16]
valid_x_pd = fea[16:20]
train_y_pd_split = labels[0:16]
valid_y_pd = labels[16:20]


train_xgb_split = xgb.DMatrix(train_x_pd_split, label=train_y_pd_split)
valid_xgb = xgb.DMatrix(valid_x_pd, label=valid_y_pd)
watch_list = [(train_xgb_split, 'train'), (valid_xgb, 'valid')]


params3 = {
    'seed': 1337,
    'colsample_bytree': 0.48,
    'silent': 1,
    'subsample': 1,
    'eta': 0.05,
    'objective': 'binary:logistic',
    'eval_metric': 'logloss',
    'max_depth': 8,
    'min_child_weight': 20,
    'nthread': 8,
    'tree_method': 'hist',
}

xgb_trained_model = xgb.train(params3, train_xgb_split, 1000, watch_list, early_stopping_rounds=50,
                              verbose_eval=10)
# xgb_trained_model.save_model(""predict/model/xgb_model_all"")
print(""feature importance 0:"")
importance = xgb_trained_model.get_fscore()
temp1 = []
temp2 = []

for k in importance:
    temp1.append(k)
    temp2.append(importance[k])

print(""-----"")
feature_importance_df = pd.DataFrame({
    'column': temp1,
    'importance': temp2,
}).sort_values(by='importance')

# print(feature_importance_df)

feature_sort_list = feature_importance_df[""column""].tolist()
feature_importance_list = feature_importance_df[""importance""].tolist()
print()
for i,item in enumerate(feature_sort_list):
    print(item,feature_importance_list[i])


train_x_xgb = xgb.DMatrix(train_x_pd_split)
train_predict = xgb_trained_model.predict(train_x_xgb)

print(train_predict)

train_predict_binary = (train_predict &gt;= 0.5) * 1
print(""TRAIN DATA SELF"")
from sklearn import metrics
print('LogLoss: %.4f' % metrics.log_loss(train_y_pd_split, train_predict))
print('AUC: %.4f' % metrics.roc_auc_score(train_y_pd_split, train_predict))
print('ACC: %.4f' % metrics.accuracy_score(train_y_pd_split, train_predict_binary))
print('Recall: %.4f' % metrics.recall_score(train_y_pd_split, train_predict_binary))
print('F1-score: %.4f' % metrics.f1_score(train_y_pd_split, train_predict_binary))
print('Precesion: %.4f' % metrics.precision_score(train_y_pd_split, train_predict_binary))

print()
valid_xgb = xgb.DMatrix(valid_x_pd)
valid_predict = xgb_trained_model.predict(valid_xgb)

print(valid_predict)

valid_predict_binary = (valid_predict &gt;= 0.5) * 1
print(""TEST DATA PERFORMANCE"")
from sklearn import metrics
print('LogLoss: %.4f' % metrics.log_loss(valid_y_pd, valid_predict))
print('AUC: %.4f' % metrics.roc_auc_score(valid_y_pd, valid_predict))
print('ACC: %.4f' % metrics.accuracy_score(valid_y_pd, valid_predict_binary))
print('Recall: %.4f' % metrics.recall_score(valid_y_pd, valid_predict_binary))
print('F1-score: %.4f' % metrics.f1_score(valid_y_pd, valid_predict_binary))
print('Precesion: %.4f' % metrics.precision_score(valid_y_pd, valid_predict_binary))
</code></pre>

<p>But result shows that xgboost do not fit the data:</p>

<pre><code>TRAIN DATA SELF
LogLoss: 0.6931
AUC: 0.5000
ACC: 0.5000
Recall: 1.0000
F1-score: 0.6667
Precesion: 0.5000

TEST DATA PERFORMANCE
LogLoss: 0.6931
AUC: 0.5000
ACC: 0.5000
Recall: 1.0000
F1-score: 0.6667
Precesion: 0.5000
</code></pre>
",1,41445,,0,62846,62846,2018-11-22T01:09:45.797,2018-11-20T07:04:36.093,1,4,,
36645,1,2018-08-08T15:03:06.170,3,1704,<python><neural-network><machine-learning-model>,Python OneHotEncoder Using Many Dummy Variables or better practice?,"<p>I am building a neural network and am at the point of using OneHotEncoder on many independent(categorical) variables.  I would like to know if I am approaching this properly with dummy variables or if since all of my variables require dummy variables there may be a better way. </p>

<pre><code>df  
    UserName    Token                       ThreadID    ChildEXE       
0   TAG     TokenElevationTypeDefault (1)   20788       splunk-MonitorNoHandle.exe  
1   TAG     TokenElevationTypeDefault (1)   19088       splunk-optimize.exe 
2   TAG     TokenElevationTypeDefault (1)   2840        net.exe 
807 User    TokenElevationTypeFull (2)      18740       E2CheckFileSync.exe 
808 User    TokenElevationTypeFull (2)      18740       E2check.exe 
809 User    TokenElevationTypeFull (2)      18740       E2check.exe 
811 Local   TokenElevationTypeFull (2)      18740       sc.exe  

ParentEXE           ChildFilePath               ParentFilePath   
splunkd.exe         C:\Program Files\Splunk\bin C:\Program Files\Splunk\bin 0
splunkd.exe         C:\Program Files\Splunk\bin C:\Program Files\Splunk\bin 0
dagent.exe          C:\Windows\System32         C:\Program Files\Dagent 0
wscript.exe         \Device\Mup\sysvol          C:\Windows  1
E2CheckFileSync.exe C:\Util                     \Device\Mup\sysvol\ 1
cmd.exe             C:\Windows\SysWOW64         C:\Util\E2Check 1
cmd.exe             C:\Windows                  C:\Windows\SysWOW64 1

DependentVariable
0
0
0
1
1
1
1
</code></pre>

<p>I import the data and using the LabelEncoder on the independent variables</p>

<pre><code>from sklearn.preprocessing import LabelEncoder, OneHotEncoder

#IMPORT DATA
#Matrix x of features
X = df.iloc[:, 0:7].values
#Dependent variable
y = df.iloc[:, 7].values

#Encoding Independent Variable
#Need a label encoder for every categorical variable
#Converts categorical into number - set correct index of column
#Encode ""UserName""
labelencoder_X_1 = LabelEncoder()
X[:, 0] = labelencoder_X_1.fit_transform(X[:, 0])
#Encode ""Token""
labelencoder_X_2 = LabelEncoder()
X[:, 1] = labelencoder_X_2.fit_transform(X[:, 1])
#Encode ""ChildEXE""
labelencoder_X_3 = LabelEncoder()
X[:, 3] = labelencoder_X_3.fit_transform(X[:, 3])
#Encode ""ParentEXE""
labelencoder_X_4 = LabelEncoder()
X[:, 4] = labelencoder_X_4.fit_transform(X[:, 4])
#Encode ""ChildFilePath""
labelencoder_X_5 = LabelEncoder()
X[:, 5] = labelencoder_X_5.fit_transform(X[:, 5])
#Encode ""ParentFilePath""
labelencoder_X_6 = LabelEncoder()
X[:, 6] = labelencoder_X_6.fit_transform(X[:, 6])
</code></pre>

<p>This gives me the following array:</p>

<pre><code>X
array([[2, 0, 20788, ..., 46, 31, 24],
       [2, 0, 19088, ..., 46, 31, 24],
       [2, 0, 2840, ..., 27, 42, 15],
       ...,
       [2, 0, 20148, ..., 17, 40, 32],
       [2, 0, 20148, ..., 47, 23, 0],
       [2, 0, 3176, ..., 48, 42, 32]], dtype=object)
</code></pre>

<p>Now for all of the independent variables I have to create dummy variables:</p>

<p>Should I use:</p>

<pre><code>onehotencoder = OneHotEncoder(categorical_features = [0, 1, 2, 3, 4, 5, 6])
X = onehotencoder.fit_transform(X).toarray() 
</code></pre>

<p>Which gives me:</p>

<pre><code>X
array([[0., 0., 1., ..., 0., 0., 0.],
       [0., 0., 1., ..., 0., 0., 0.],
       [0., 0., 1., ..., 0., 0., 0.],
       ...,
       [0., 0., 1., ..., 1., 0., 0.],
       [0., 0., 1., ..., 0., 0., 0.],
       [0., 0., 1., ..., 1., 0., 0.]])
</code></pre>

<p>Or is there a better way to approach this this?</p>
",1,55001,,3,56985,,2019-07-13T10:57:15.027,,2,2,,
32814,1,2018-06-08T09:27:01.080,0,802,<python><keras>,Error while using flow_from_generator,"<p>Getting this error while using flow_from_generator in keras</p>

<pre><code>  63/3851 [..............................] - ETA: 6:41:59 - loss: 12.8586 - acc: 0.1930
  64/3851 [..............................] - ETA: 6:41:40 - loss: 12.8544 - acc: 0.1934Traceback (most recent call last):
  File ""/tools/anaconda3/envs/py35/lib/python3.5/site-packages/keras/utils/data_utils.py"", line 551, in get
    inputs = self.queue.get(block=True).get()
  File ""/tools/anaconda3/envs/py35/lib/python3.5/multiprocessing/pool.py"", line 644, in get
    raise self._value
  File ""/tools/anaconda3/envs/py35/lib/python3.5/multiprocessing/pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))
  File ""/tools/anaconda3/envs/py35/lib/python3.5/site-packages/keras/utils/data_utils.py"", line 391, in get_index
    return _SHARED_SEQUENCES[uid][i]
  File ""/tools/anaconda3/envs/py35/lib/python3.5/site-packages/keras/preprocessing/image.py"", line 761, in __getitem__
    return self._get_batches_of_transformed_samples(index_array)
  File ""/tools/anaconda3/envs/py35/lib/python3.5/site-packages/keras/preprocessing/image.py"", line 1106, in _get_batches_of_transformed_samples
    interpolation=self.interpolation)
  File ""/tools/anaconda3/envs/py35/lib/python3.5/site-packages/keras/preprocessing/image.py"", line 364, in load_img
    img = img.resize(width_height_tuple, resample)
  File ""/tools/anaconda3/envs/py35/lib/python3.5/site-packages/PIL/Image.py"", line 1743, in resize
    self.load()
  File ""/tools/anaconda3/envs/py35/lib/python3.5/site-packages/PIL/ImageFile.py"", line 233, in load
    ""(%d bytes not processed)"" % len(b))
OSError: image file is truncated (42 bytes not processed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""convolutional.py"", line 394, in &lt;module&gt;
    runCNNconfusion()
  File ""convolutional.py"", line 379, in runCNNconfusion
    epochs=epochs,verbose=1, callbacks = [MetricsCheckpoint('logs')])
  File ""/tools/anaconda3/envs/py35/lib/python3.5/site-packages/keras/legacy/interfaces.py"", line 87, in wrapper
    return func(*args, **kwargs)
  File ""/tools/anaconda3/envs/py35/lib/python3.5/site-packages/keras/models.py"", line 1227, in fit_generator
    initial_epoch=initial_epoch)
  File ""/tools/anaconda3/envs/py35/lib/python3.5/site-packages/keras/legacy/interfaces.py"", line 87, in wrapper
    return func(*args, **kwargs)
  File ""/tools/anaconda3/envs/py35/lib/python3.5/site-packages/keras/engine/training.py"", line 2115, in fit_generator
    generator_output = next(output_generator)
  File ""/tools/anaconda3/envs/py35/lib/python3.5/site-packages/keras/utils/data_utils.py"", line 557, in get
    six.raise_from(StopIteration(e), e)
  File ""&lt;string&gt;"", line 3, in raise_from
StopIteration: image file is truncated (42 bytes not processed)
</code></pre>

<p>Can someone please help, totally blank on how to proceed</p>
",1,32826,,0,44680,,2018-06-08T12:11:25.473,,1,1,,
86244,1,2020-12-03T16:02:10.540,0,323,<machine-learning><python><preprocessing>,Different strategies for dealing with features with multiple values per sample in python machine learning models,"<p>I have a dataset which contains pregnancy, maternal, foetal and children data and I am developing a predictive machine learning model to predict adverse pregnancy outcomes.</p>
<p>The dataset contains mostly features with a single value per pregnancy, e.g. maternalObesity = [&quot;Yes&quot;, &quot;No]. However, I have some features that have multiple values per pregnancy, such as the foetal abdominal circumference and estimated foetal weight which have been recorded multiple times at different times during gestation (so each pregnancy will have between 1 and 26 observations for these features each), like so:</p>
<pre><code>PregnancyID     gestationWeek    abdomcirc     maternalObesity
1               13               200           Yes
1               18               240           Yes
1               30               294           Yes
2               11               156           No
2               20               248           No
</code></pre>
<p>So in pregnancy 1, we can see that the abdominal circumference was recorded 3 times at weeks 13, 18 and 30.</p>
<p>All questions I have seen here which have addresses the issue of multiple values per sample have been about categorical features, like <a href=""https://datascience.stackexchange.com/questions/14324/handling-a-feature-containing-multiple-values"">this</a> and <a href=""https://datascience.stackexchange.com/questions/14847/multiple-categorical-values-for-a-single-feature-how-to-convert-them-to-binary-u"">this</a>. Here the suggested solution was to OneHotEncode the features. However, like I said, this does not apply in my case as I have continuous (float) variables.</p>
<p>I have spent the last few months attempting different methods to best handle these features such that I don't lose any valuable information. Simply adding these features into in my dataset will result in almost duplicate rows as the vast majority of my samples have single values (like in the table above.</p>
<p>Here are some of the different approaches I have considered to handle these features:</p>
<ol>
<li><p>Derive statistical values from the features, like <a href=""https://datascience.stackexchange.com/a/78134/99648"">here</a>. So I compute mean the maximum, minimum, variance, range, etc. of all the observations per pregnancy. However, the downfall with this approach is that the time at which the values are recorded is neglected. The time of the measurement may be significant as a higher abdominal circumference earlier in pregnancy may be more correlated with the adverse outcome I am trying to predict.</p>
</li>
<li><p>Summarise the measurements into a fixed number of features by grouping them into 3 trimester, like <a href=""https://stackoverflow.com/questions/65106011/summarising-features-with-multiple-values-in-python-for-machine-learning-model/65109630?noredirect=1#comment115141184_65109630"">here</a>. So I can group all measurements by 3 trimesters, and each feature would hold the maximum measurement recorded during that trimester.</p>
</li>
</ol>
<p>So my dataset will look like this:</p>
<pre><code>PregnancyID     MotherID    abdomCirc1st  abdomCirc2nd   abdomCirc3rd
1               1           200           315            350
2               2           156           248            NaN
</code></pre>
<p>This approach takes into account the time range of the measurement, but will result in a lot of NaNs in the new features, as many pregnancies do not have a measurement for each trimester. Also, the maximum may result in some statistical information being lost, unlike approach 1.</p>
<ol start=""3"">
<li>I initially thought about using a python list for these features. However, I do not know if a machine learning model can handle this data type, and again, the time each measurement was taken is neglected in this approach.</li>
</ol>
<p>So my data will look something like this:</p>
<pre><code>PregnancyID     maternalObesity    abdomcirc
1               Yes                [200, 240, 294]
2               No                 [156, 248]
</code></pre>
<p>In conclusion, I need some guidance as I have found a lack of examples and resources out there about this issue. So please advise what the best approach is in this case and if there are any detailed examples out there that address this issue I would appreciate it.</p>
",1,86268,,0,99648,99648,2020-12-07T12:54:42.730,2020-12-07T12:54:42.730,1,2,,
8540,1,2015-10-21T11:57:51.553,2,514,<classification><python><svm><scikit-learn><multilabel-classification>,One multilabel classifier or one for each type of label?,"<p>Let's say I need to classify addresses with scikit-learn, so if I want my classifier to be able to classify addresses by the street name, and post/zip code, should I do a OneVsRest classifier, or separate them into two different classifiers (for the same training set)?</p>

<p>I have tried both, and it seems like having multiple classifiers might be a better choice, as it feels faster to train multiple smaller classifiers. Is this how it is supposed to be done?</p>
",1,8566,,2,13562,13562,2018-01-31T15:27:01.020,2015-10-21T12:03:43.703,1,2,,
67009,1,2020-01-24T18:30:21.403,4,14461,<python><jupyter>,Practical way to convert jupyter notebook to MS Word document?,"<p>What would be a practical way to convert a Jupyter Notebook to a Word document (.doc) ? I am asking this in a professional context, so I'd like to avoid manual solutions, do it in an efficient way (fast), avoid third parties... etc. Something that works like Rmarkdown to produce .doc would be very welcome. </p>
",1,67023,,4,303,,2022-02-03T10:36:47.777,,2,2,,
72949,1,2020-04-24T23:27:13.677,1,71,<python><pca><jupyter>,PCA - what do I do with its results?,"<p>I have a data set with more than 20 features, and I applied PCA:</p>

<pre><code>M.fit_transform(all_data)
variance = M.explained_variance_ratio_
var = np.cumsum(np.round(M.explained_variance_ratio_, decimals=3)*100)
plt.ylabel('% Variance Explained')
plt.xlabel('# of Features')
plt.title('PCA Analysis')
plt.ylim(30,102.5)
plt.plot(var, marker=""s"")
plt.show()
</code></pre>

<p>Printing the <code>var</code> variable, I get</p>

<pre><code>array([ 89., 100., 100., 100., 100., 100., 100., 100., 100., 100.])
</code></pre>

<p>I understand this tells us that the variance is explained by 2 features. </p>

<p>So I calculated it again, now the 2 components:</p>

<pre><code>from sklearn.decomposition import PCA
M = PCA(n_components = 2)
X = M.fit_transform(all_data)
plt.scatter(X[:,0],X[:,1])
</code></pre>

<p>And this gives a ""random looking plot"". I understand that the data was changed during the PCA process.</p>

<p>What can I do with this information? How will this help me understand the data?</p>

<p>Is it useful per se? Is it useful as a preparation method for other methods? Which ones can I try?</p>
",1,72957,,1,95247,95247,2020-04-25T13:26:12.050,2020-04-25T13:26:12.050,1,2,,
10432,1,2016-02-27T19:14:08.533,6,151,<machine-learning><python><svm><supervised-learning><discriminant-analysis>,How are Hyperplane Heatmaps created and how should they be interpreted?,"<p>For nonlinear data, when we are using Support Vector Machines, we can use kernels such as Gaussian RBF, Polynomial, etc to achieve linearity in a different (potentially unknown to us) feature space and <em>the algorithm learns a maximal separating hyperplane in that feature space</em>.</p>

<p>My question is how do we create heatmaps such as the one seen in the image below to show this max. separating hyperplane in our original space and how should it be interpreted?</p>

<p><a href=""https://i.stack.imgur.com/tZYnK.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/tZYnK.png"" alt=""enter image description here""></a></p>
",1,10442,,6,11044,,2016-02-29T08:39:00.030,,1,1,,
20199,1,2017-07-06T05:17:55.947,52,421293,<python><scikit-learn><sampling>,train_test_split() error: Found input variables with inconsistent numbers of samples,"<p>Fairly new to Python but building out my first RF model based on some classification data. I've converted all of the labels into int64 numerical data and loaded into X and Y as a numpy array, but I am hitting an error when I am trying to train the models. </p>

<p>Here is what my arrays look like:</p>

<pre><code>&gt;&gt;&gt; X = np.array([[df.tran_cityname, df.tran_signupos, df.tran_signupchannel, df.tran_vmake, df.tran_vmodel, df.tran_vyear]])

&gt;&gt;&gt; Y = np.array(df['completed_trip_status'].values.tolist())

&gt;&gt;&gt; X
array([[[   1,    1,    2,    3,    1,    1,    1,    1,    1,    3,    1,
            3,    1,    1,    1,    1,    2,    1,    3,    1,    3,    3,
            2,    3,    3,    1,    1,    1,    1],
        [   0,    5,    5,    1,    1,    1,    2,    2,    0,    2,    2,
            3,    1,    2,    5,    5,    2,    1,    2,    2,    2,    2,
            2,    4,    3,    5,    1,    0,    1],
        [   2,    2,    1,    3,    3,    3,    2,    3,    3,    2,    3,
            2,    3,    2,    2,    3,    2,    2,    1,    1,    2,    1,
            2,    2,    1,    2,    3,    1,    1],
        [   0,    0,    0,   42,   17,    8,   42,    0,    0,    0,   22,
            0,   22,    0,    0,   42,    0,    0,    0,    0,   11,    0,
            0,    0,    0,    0,   28,   17,   18],
        [   0,    0,    0,   70,  291,   88,  234,    0,    0,    0,  222,
            0,  222,    0,    0,  234,    0,    0,    0,    0,   89,    0,
            0,    0,    0,    0,   40,  291,  131],
        [   0,    0,    0, 2016, 2016, 2006, 2014,    0,    0,    0, 2015,
            0, 2015,    0,    0, 2015,    0,    0,    0,    0, 2015,    0,
            0,    0,    0,    0, 2016, 2016, 2010]]])

&gt;&gt;&gt; Y
array(['NO', 'NO', 'NO', 'YES', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'NO',
       'NO', 'YES', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO',
       'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO'], 
      dtype='|S3')

&gt;&gt;&gt; X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)
</code></pre>

<blockquote>
  <p>Traceback (most recent call last):</p>

<pre><code>  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/Library/Python/2.7/site-packages/sklearn/cross_validation.py"", line
</code></pre>
  
  <p>2039, in train_test_split
          arrays = indexable(*arrays)
        File ""/Library/Python/2.7/site-packages/sklearn/utils/validation.py"", line
  206, in indexable
          check_consistent_length(*result)
        File ""/Library/Python/2.7/site-packages/sklearn/utils/validation.py"", line
  181, in check_consistent_length
          "" samples: %r"" % [int(l) for l in lengths])</p>

<pre><code>ValueError: Found input variables with inconsistent numbers of samples: [1, 29]
</code></pre>
</blockquote>
",1,20203,,52,34253,67971,2019-09-09T20:22:03.303,2019-03-26T06:42:28.280,2,1,,
106703,1,2022-01-04T15:46:50.040,1,1121,<python>,Can a Transformers be used for a classification problem?,"<p>I want to perform binary classification on a sequential data. I want to leverage the PyTorch nn.TransformerEncoder module, is there a way I can do this?
If not, are Transformers only used NLP?
If yes, how can I format the inputs and what tutorial can help me do this as quick as possible</p>
",1,106814,,1,130965,,2022-01-07T19:21:34.573,,1,1,,
26103,1,2017-12-29T08:12:48.523,45,71595,<machine-learning><python><deep-learning><keras><tensorflow>,Merging two different models in Keras,"<p>I am trying to merge two Keras models into a single model and I am unable to accomplish this.</p>

<p>For example in the attached Figure, I would like to fetch the middle layer $A2$ of dimension 8, and use this as input to the layer $B1$ (of dimension 8 again) in Model $B$ and then combine both Model $A$ and Model $B$ as a single model.</p>

<p>I am using the functional module to create Model $A$ and Model $B$ independently.  How can I accomplish this task?</p>

<p><strong>Note</strong>: $A1$ is the input layer to model $A$ and $B1$ is the input layer to model $B$.</p>

<p><a href=""https://i.stack.imgur.com/Chgpo.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Chgpo.jpg"" alt=""See Picture""></a></p>
",1,26119,,45,43921,61023,2022-06-12T12:26:59.970,2019-01-29T20:45:58.467,2,1,,
85330,1,2020-11-13T02:01:35.640,1,472,<machine-learning><python><r><clustering><visualization>,Coloring clusters so that nearby clusters have different colors,"<p>I have clustered a large number of points (~3000) into (~400) clusters.  I want to plot the data and visualize the clusters.  I want to make sure that nearby clusters have different colors.  Can anyone recommend an approach to coloring the clusters?</p>
<p>This is a conceptual question, but I'm most interested in solutions in python or R.</p>
",1,85332,,1,69518,69518,2020-11-16T03:16:18.833,2020-11-13T19:41:31.027,2,1,,
82742,1,2020-10-08T14:01:56.163,3,42,<machine-learning><python><classification><predictive-modeling><text-classification>,Predictive output with your own model built,"<p>I would need to better understand how can be created a machine learning algorithm from scratch using an own model developed based on boolean values, for example # of words in a text, # of punctuation, # of capital letters, and so on, to determine if a text is formal or informal.
For instance: I have</p>
<pre><code>Text
there is a new major in this town
WTF?!?
you're a great person. Really glad to have met you
I don't know what to say
BYE BYE BABY
</code></pre>
<p>I created some rules to assign a label on this (small) train dataset, but I would need to understand how to apply these rules to a new dataset (test):</p>
<ul>
<li>if there is an upper case word then I;</li>
<li>if there is a short expression, like don't, 'm ,'s, ... , then I;</li>
<li>if there are two symbols (punctuation) close to each other, then I;</li>
<li>if a word is in list of extra words, then I;</li>
<li>otherwise F.</li>
</ul>
<p>Suppose that I have a dataframe to test and to assign these labels (I or F):</p>
<pre><code>FREEDOM!!! I don't need to go to school anymore
What are u thinking?
Hey men!
I am glad to hear that. 
</code></pre>
<p>how could I apply my model to this new dataset, adding labels?</p>
<pre><code>Test                                                  Output
FREEDOM!!! I don't need to go to school anymore       I
What are u thinking?                                  I
Hey men!                                              I
I am glad to hear that.                               F
</code></pre>
<p>Update after mnm's comment:</p>
<p>Would it be considered a machine learning problem the following one?</p>
<pre><code>import pandas as pd
import numpy as np
data = { &quot;ID&quot;:[1,2,3,4],
        &quot;Text&quot;:[&quot;FREEDOM!!! I don't need to go to school anymore&quot;,
    &quot;What are u thinking?&quot;,
    &quot;Hey men!&quot;,&quot;
    I am glad to hear that.&quot;]}

# here there should be the part of modelling
df['upper'] = # if there is an upper case word then &quot;I&quot;
df['short_exp'] = # if there is a short exp then &quot;I&quot;
df['two_cons'] = # if there are two consecutive symbols then &quot;I&quot;

list_extra=['u','hey']
df['extra'] = # if row contains at least one of the word included in list_extra then 'I'



# append cols to original dataframe
df_new = df
df_new['upper'] = df1['upper']
df_new['short_exp'] = df1['short_exp']
# and similar for others
</code></pre>
<p>It is not clear, however, the latest part, that one based on condition. How can I predict the new values for the other texts?</p>
",1,82751,,3,96922,96922,2020-10-08T23:58:46.737,2020-10-08T14:31:56.677,1,2,,
15962,1,2016-12-27T22:50:17.103,11,8801,<machine-learning><python><tensorflow><optimization><gradient-descent>,Why is learning rate causing my neural network's weights to skyrocket?,"<p>I am using tensorflow to write simple neural networks for a bit of research and I have had many problems with 'nan' weights while training. I tried many different solutions like changing the optimizer, changing the loss, the data size, etc. but with no avail. Finally, I noticed that a change in the learning rate made an unbelievable difference in my weights.</p>

<p>Using a learning rate of .001 (which I thought was pretty conservative), the minimize function would actually exponentially raise the loss. After one epoch the loss could jump from a number in the thousands to a trillion and then to infinity ('nan'). When I lowered the learning rate to .0001, everything worked fine.</p>

<p>1) Why does a single order of magnitude have such an effect?</p>

<p>2) Why does the minimize function literally perform the opposite of its function and maximize the loss? It seems to me that that shouldn't occur, no matter the learning rate.</p>
",1,15976,,11,27420,27420,2019-04-17T19:21:46.580,2019-04-17T19:21:46.580,2,2,,
5606,1,2015-04-25T01:48:19.270,2,290,<python><decision-trees>,Question on decision tree in the book Programming Collective Intelligence,"<p>I'm currently studying Chapter 7 (""Modeling with Decision Trees"") of the book ""Programming Collective intelligence"". </p>

<p>I find the output of the function <code>mdclassify()</code> p.157 confusing. The function deals with missing data. The explanation provided is:</p>

<blockquote>
  <p>In the basic decision tree, everything has an implied weight of 1,
  meaning that the observations count fully for the probability that an
  item fits into a certain category. If you are following multiple
  branches instead, you can give each branch a weight equal to the
  fraction of all the other rows that are on that side.</p>
</blockquote>

<p>From what I understand, an instance is then split between branches.</p>

<p>Hence, I simply don't understand how we can obtain:</p>

<pre><code>{'None': 0.125, 'Premium': 2.25, 'Basic': 0.125}
</code></pre>

<p>as <code>0.125+0.125+2.25</code> does not sum to 1 nor even an integer. How was the new observation split?</p>

<p>The code is here:</p>

<p><a href=""https://github.com/arthur-e/Programming-Collective-Intelligence/blob/master/chapter7/treepredict.py"" rel=""nofollow noreferrer"">https://github.com/arthur-e/Programming-Collective-Intelligence/blob/master/chapter7/treepredict.py</a></p>

<p>Using the original dataset, I obtain the tree shown here: </p>

<p><a href=""https://i.stack.imgur.com/zT39z.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zT39z.jpg"" alt=""screenshot""></a></p>

<p>Can anyone please explain me precisely what the numbers precisely mean and how they were exactly obtained?</p>

<p>PS : The 1st example of the book is wrong as described on their errata page but just explaining the second example (mentioned above) would be nice.</p>
",1,5616,,2,9296,29575,2018-06-26T04:28:19.580,2018-06-26T04:28:19.580,1,3,,
12918,1,2016-07-21T18:34:09.517,0,2688,<python><visualization><ggplot2>,Python: ggplot geom_histogram() binwidth or bin parameter missing?,"<p>I am unable to change number of bins when using geom_histogram() function. There is nothing in the documention, except some examples where binwidth=X is used (which is how R:ggplot2 uses it). However, this parameter seems to have no effect on the actual output.</p>

<p>Version: ggplot 0.10.4, Python 3.5 64bit</p>

<p>So for example: </p>

<pre><code>import matplotlib.pyplot as plt
plt.figure()
dataframe['column'].plot.hist(bins=30)
plt.show()
</code></pre>

<p>works as expected and draws 30 bins. Meanwhile: </p>

<pre><code>from ggplot import *
gg = ggplot(dataframe, aes(x='column')) + geom_histogram(binwidth=300)
print(gg)
</code></pre>

<p>does not change number of bins (I understand that binwidth sets interval for one bin), and have tried multiple values and/or datasets</p>
",1,13134,,0,21692,,2016-08-01T18:47:12.830,,1,2,,
77803,1,2020-07-16T11:26:10.827,1,87,<python><neural-network><keras><numpy>,Why can't I specify the correct NumPy size?,"<p>In the network (model of Keras, Sequential), the input layer must have 4 neurons. The input must be 1 list, the length of which is 4, each element is a number.</p>
<pre><code>print(&quot;SHAPE:&quot;, np.array([1, 1, 1, 1]).shape)

self.model.fit(np.array([1, 1, 1, 1]),
self.rightAnswer, 
epochs = 1,
batch_size = 1)
</code></pre>
<p>Here is the conclusion:</p>
<pre><code>SHAPE: (4,)

ValueError: Error when checking input: expected dense_1_input to have shape (4,) but got array with shape (1,)
</code></pre>
<p>Why is this happening, and how can I fix it?</p>
",1,77809,,1,100857,100857,2020-07-16T13:08:46.540,2020-07-16T12:08:39.683,1,4,2020-07-20T14:29:43.313,
24615,1,2017-11-12T03:11:08.080,0,79,<python><data><class-imbalance>,Imbalanced class with same rows?,"<p>In my dataset i have 3 classes-> 0,1,2. 
0(72k),1(13k)and 2(13K) in brackets are there count.
So whenever i try to predict them with any algorithm ,i observed that almost all the ""2""'s are predicted as ""0"".
On little exploration i found that there are some rows where attributes of 0 and 2 are exactly same.
Any technique to tackle this issue?</p>
",1,24627,,0,41491,41491,2017-11-13T10:17:20.197,2017-11-12T03:21:33.840,2,3,2017-11-16T13:14:17.627,
20442,1,2017-07-14T19:53:45.710,4,7723,<python><neural-network><time-series><keras><rnn>,Recurrent neural network producing same predictions,"<p>I am trying to train a recurrent neural network that I built in keras on timeseries data to predict number of sales for next 10 days. For this, I've created my dataset as -</p>

<pre><code>var(t) -&gt; var(t+1)
var(t+1) -&gt; var(t+2)
var(t+2) -&gt; var(t+3)
var(t+3) -&gt; var(t+4) and so on 
</code></pre>

<p>I did Min-Max scaling on this data and the RNN code is as follows - </p>

<pre><code>model = Sequential()
model.add(LSTM(20, input_shape=(1, look_back),activation='tanh',bias_initializer='ones'))
model.add(Dense(1, activation='linear',bias_initializer='ones'))
opt=adam(lr=0.1)
model.compile(loss='mean_squared_error',optimizer=opt)
model.fit(xtrain, ytrain, epochs=100, batch_size=1, verbose=2)
</code></pre>

<p>But the plot I am getting is when I did predictions on xtrain (green = ytrain, blue =  ypred) - </p>

<p><a href=""https://i.stack.imgur.com/790ph.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/790ph.png"" alt=""Observed vs expected signals""></a></p>

<p>The rnn isn't learning anything at all. Its producing same results for each dataset. I've tried adding hidden layers, increasing number of neurons, changing parameters (learning rate, momentum), optimizers (sgd, adam, adagrad, rmsprop), lstm activation fxn (tanh, softsign). I got little fluctuations in some cases in the graph. But the output is mostly constant.
Also, I've only 200 datasets. </p>

<p>Can someone please guide me what I am doing wrong here. What else I can try. Will small sized data not work using RNN at all ? If so, is there any other way to solve this problem (except ARIMA model) ?  </p>

<p>EDIT - Increased batch size to 100 and epochs to 1000. Received some better results. Also, I did mean normalization [(x-mean)/std_dev] instead of MinMax scaling.</p>

<p><a href=""https://i.stack.imgur.com/ONRfh.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ONRfh.png"" alt=""enter image description here""></a></p>
",1,20490,,4,23138,23138,2017-07-17T16:32:46.710,2017-07-14T20:26:24.040,1,3,,
50985,1,2019-04-26T14:04:32.473,1,1472,<python><keras><tensorflow>,Interpretation of Keras training and improving accuracy/consistency,"<p>I have finished my first NN (pretty exciting) and have started tweaking in hopes of improving results.</p>

<pre><code>Epoch 1/10
30/30 [==============================] - 0s 9ms/step - loss: 69.2138 - acc: 
0.2937 - val_loss: 62.3838 - val_acc: 0.6250
Epoch 2/10
30/30 [==============================] - 0s 1ms/step - loss: 66.8716 - acc: 
0.3167 - val_loss: 64.4628 - val_acc: 0.1875
Epoch 3/10
30/30 [==============================] - 0s 1ms/step - loss: 65.6411 - acc: 
0.2750 - val_loss: 96.1742 - val_acc: 0.1250
Epoch 4/10
30/30 [==============================] - 0s 1ms/step - loss: 70.4931 - acc: 
0.2875 - val_loss: 91.4954 - val_acc: 0.2031
Epoch 5/10
30/30 [==============================] - 0s 1ms/step - loss: 68.8988 - acc: 
0.1813 - val_loss: 75.3798 - val_acc: 0.0000e+00
Epoch 6/10
30/30 [==============================] - 0s 1ms/step - loss: 69.1241 - acc: 
0.0000e+00 - val_loss: 77.7191 - val_acc: 0.0000e+00
Epoch 7/10
30/30 [==============================] - 0s 1ms/step - loss: 64.7226 - acc: 
0.3479 - val_loss: 74.3400 - val_acc: 0.5156
Epoch 8/10
30/30 [==============================] - 0s 1ms/step - loss: 68.5523 - acc: 
0.1719 - val_loss: 69.1414 - val_acc: 1.0000
Epoch 9/10
30/30 [==============================] - 0s 1ms/step - loss: 66.1609 - acc: 
0.7917 - val_loss: 70.9609 - val_acc: 0.8438
Epoch 10/10
30/30 [==============================] - 0s 1ms/step - loss: 68.6736 - acc: 
0.7552 - val_loss: 68.3616 - val_acc: 0.7344

Test-Accuracy: 0.4234375
</code></pre>

<p>What confuses me is how scattered and inconsistent my val_acc values are. Is this due to bad data or bad modeling?</p>

<p>Here is a snipit of my training data (It is syslog that i have parsed into key values)</p>

<pre><code>syslog_data = [
[0.110002,0.4,0.2,0,0,0,5], [0.110002,0.4,0.2,0,0,0,5], [0.110002,0.4,0.1,0,0,0,5], [0.110002,0.4,0.2,0,0,0,5],
[0.302014,0,0,0,0.0,0,1], [0.302014,0,0,0,0.0,0,1], [0.302014,0,0,0,0.0,0,1], [0.302014,0,0,0,0.0,0,1],
[0.302014,0,0,0,0.0,0,1], [0.302014,0,0,0,0.0,0,1], [0.302014,0,0,0,0.0,0,1], [0.302014,0,0,0,0.0,0,1],
[0.419002,0.2,0.1,0,0,0,6], [0.419002,0.2,0.1,0,0,0,6], [0.419002,0.2,0.1,0,0,0,6], [0.419002,0.2,0.1,0,0,0,6],
[0.110002,0.4,0,0,0,0,5], [0.110002,0.4,0,0,0,0,5], [0.110002,0.4,0.1,0,0,0,5], [0.110002,0.4,0.2,0,0,0,5],
[0.305013,0.5,0,0,0,0,4], [0.305013,0.5,0,0,0,0,4], [0.305013,0.5,0,0,0,0,4], [0.305013,0.5,0,0,0,0,4],
[0.710003,0.1,0.1,0,0,0,8], [0.710003,0.1,0.1,0,0,0,8], [0.710003,0.1,0.1,0,0,0,8], [0.710003,0.1,0.1,0,0,0,8],
[0.302014,0,0,0,0.03,0.3,2], [0.302014,0,0,0,0.03,0.3,2], [0.302014,0,0,0,0.03,0.3,2], [0.302014,0,0,0,0.03,0.3,2],
</code></pre>

<p>And here is the code behind my NN</p>

<pre><code>import tensorflow as tf
import numpy as np
from tensorflow.keras import layers
from syslog import syslog_data, syslog_eval, syslog_pred

print(tf.VERSION)
print(tf.keras.__version__)

x = np.array([arr[:-1] for arr in syslog_data], dtype=np.float32)
y = np.array([arr[-1:] for arr in syslog_data], dtype=np.float32)

x_ev = np.array([arr[:-1] for arr in syslog_eval], dtype=np.float32)
y_ev = np.array([arr[-1:] for arr in syslog_eval], dtype=np.float32)

model = tf.keras.Sequential()
# Adds a densely-connected layer with x units to the model:
model.add(layers.Dense(10, activation='relu', input_shape=(6,)))
# Add another:
model.add(layers.Dense(32, activation='relu'))
# Add another:
model.add(layers.Dense(32, activation='relu'))
# Add another:
model.add(layers.Dense(10, activation='relu'))
# Add a softmax layer with 8 output units:
model.add(layers.Dense(8, activation='softmax'))

dataset = tf.data.Dataset.from_tensor_slices((x, y))
dataset = dataset.batch(32).repeat()

val_dataset = tf.data.Dataset.from_tensor_slices((x_ev, y_ev))
val_dataset = val_dataset.batch(32).repeat()

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

results = model.fit(dataset, epochs=10, steps_per_epoch=30,
          validation_data=val_dataset,
          validation_steps=2)

x = np.array([arr[:-1] for arr in syslog_pred], dtype=np.float32)
dataset = tf.data.Dataset.from_tensor_slices(x)

y = model.predict(x)
print(y)
print(""Test-Accuracy:"", np.mean(results.history[""val_acc""]))
</code></pre>

<p>EDIT:</p>

<p>I have expanded my batch size to 2000 and get the following results:</p>

<pre><code>Epoch 1/10
30/30 [==============================] - 1s 18ms/step - loss: 67.8644 - acc: 
0.1418 - val_loss: 62.3833 - val_acc: 0.0000e+00
Epoch 2/10
30/30 [==============================] - 0s 7ms/step - loss: 67.8003 - acc: 
0.0894 - val_loss: 64.4627 - val_acc: 0.0000e+00
Epoch 3/10
30/30 [==============================] - 0s 7ms/step - loss: 67.8639 - acc: 
0.2535 - val_loss: 96.1742 - val_acc: 1.0000
Epoch 4/10
30/30 [==============================] - 0s 7ms/step - loss: 67.8003 - acc: 
0.4979 - val_loss: 91.4954 - val_acc: 1.0000
Epoch 5/10
30/30 [==============================] - 0s 6ms/step - loss: 67.8639 - acc: 
0.1995 - val_loss: 75.3798 - val_acc: 0.0000e+00
Epoch 6/10
30/30 [==============================] - 0s 7ms/step - loss: 67.8003 - acc: 
0.4316 - val_loss: 77.7191 - val_acc: 0.0000e+00
Epoch 7/10
30/30 [==============================] - 0s 7ms/step - loss: 67.8639 - acc: 
0.4328 - val_loss: 74.3400 - val_acc: 0.0000e+00
Epoch 8/10
30/30 [==============================] - 0s 7ms/step - loss: 67.8002 - acc: 
0.7325 - val_loss: 69.1414 - val_acc: 0.0000e+00
Epoch 9/10
30/30 [==============================] - 0s 7ms/step - loss: 67.8639 - acc: 
0.8989 - val_loss: 70.9609 - val_acc: 1.0000
Epoch 10/10
30/30 [==============================] - 0s 7ms/step - loss: 67.8002 - acc: 
0.9663 - val_loss: 68.3616 - val_acc: 1.0000
[[0.12500003 0.12500003 0.12500001 0.12500003 0.125      0.12499999
  0.12499997 0.12499999]]
Test-Accuracy: 0.4
</code></pre>
",1,50994,,1,73150,73150,2019-04-26T16:27:33.610,2019-04-26T14:23:45.740,1,6,,
109153,1,2022-03-18T09:01:09.397,0,20,<python><dataset><pandas><correlation><wikipedia>,What correlation measure for Wikipedia translated pages vs number of in links?,"<p>I'm trying to find a correlation measure for the number of Wikipedia pages an entity (an article) has been translated to vs number of links that point to that page (both measures that can point to the popularity of a page). Is it possible to correlate them?</p>
<p>For instance I have</p>
<pre><code>Work, links, wikipediaTranslatedPages
The name of the rose, 500, 53
</code></pre>
",1,109155,,0,133609,,2022-03-18T10:47:21.890,,1,2,,
52968,1,2019-05-31T11:28:33.917,2,1180,<python><pandas><dataframe>,Change values of a particular column to value_count(),"<p>Suppose i have the following data set. I need to replace the value of a particular column by the value_count(). I saw few posts where it is done for the entire data set. I need to do it for a particular column.</p>

<pre><code>data = pd.DataFrame({'Item 1': ['apple', 'potato', 'cheese', 'banana', 'cheese', 'banana', 'cheese', 'potato', 'egg'],
          'Item 2': [1,5,2,7,8,4,9,0,3],
          'Item 3': ['a','b','a','c','d','c','e','e','e']})
</code></pre>

<p>How do i replace the values of column 'Item 1' by the value_counts()?</p>

<p>I tried the following code.</p>

<pre><code>data.apply(lambda x: x.map(x.value_counts()))
</code></pre>

<p>But this is applying to whole data. I need to do it for one column.</p>

<p>The resulting value should be of the form - </p>

<p>'Cheese':3</p>

<p>'Potato':2</p>
",1,52970,,2,38091,38091,2019-05-31T12:50:49.623,2019-05-31T11:52:15.700,1,2,,
38540,1,2018-09-20T13:34:22.520,16,7645,<python><nlp><language-model>,Are there any good out-of-the-box language models for python?,"<p>I'm prototyping an application and I need a language model to compute perplexity on some generated sentences.</p>

<p>Is there any trained language model in python I can readily use? Something simple like</p>

<pre><code>model = LanguageModel('en')
p1 = model.perplexity('This is a well constructed sentence')
p2 = model.perplexity('Bunny lamp robert junior pancake')
assert p1 &lt; p2
</code></pre>

<p>I've looked at some frameworks but couldn't find what I want. I know I can use something like:</p>

<pre><code>from nltk.model.ngram import NgramModel
lm = NgramModel(3, brown.words(categories='news'))
</code></pre>

<p>This uses a good turing probability distribution on Brown Corpus, but I was looking for some well-crafted model on some big dataset, like the 1b words dataset. Something that I can actually trust the results for a general domain (not only news)</p>
",1,52901,,16,59385,,2021-04-26T02:18:56.463,,5,6,,
27888,1,2018-02-16T11:09:56.917,9,1709,<machine-learning><python><classification><scikit-learn><multiclass-classification>,Imbalanced data causing mis-classification on multiclass dataset,"<p>I am working on text classification where I have 39 categories/classes and 8.5 million records. (In future data and categories will increase).</p>

<p>Structure or format of my data is as follows.</p>

<pre><code>----------------------------------------------------------------------------------------
| product_title          | Key_value_pairs                               | taxonomy_id |
----------------------------------------------------------------------------------------
  Samsung S7 Edge        | Color:black,Display Size:5.5 inch,Internal    | 211 
                          Storage:128 GB, RAM:4 GB,Primary Camera:12 MP  

  Case cover Honor 8     | Color:transparent,Height:15 mm,width:22 mm    | 212 

  Ruggers Men's T-Shirt  | Size:L,ideal for:men,fit:regular,             | 111
                          sleeve:half sleeve

  Optimum Nutrition Gold | Flavor:chocolate,form:powder,size:34 gm       | 311
  Standard Whey Protein  
</code></pre>

<p>Data distribution is not normal; it is highly imbalanced:</p>

<pre><code>-------------------------
| taxonomy_id |   count |
-------------------------
          111 |  851750 
          112 |  355592
          113 |  379433
          114 |   23138
          115 |  117735
          116 |  145757
          117 | 1339471
          121 |  394026
          122 |  193433
          123 |   78299
          124 |  111962
          131 |    1776
          132 |    4425
          133 |     908
          134 |   23062
          141 |   22713
          142 |   42073
          211 |    7892
          212 | 1574744
          221 |    1047
          222 |  397515
          223 |   53009
          231 |    1227
          232 |    7683
          251 |     739
          252 |     327
          253 |   38974
          254 |      25
          311 |    2901
          321 |    7126
          412 |     856
          421 |  697802
          422 |  414855
          423 |   17750
          425 |    1240
          427 |     658
          429 |    1058
          431 |   20760
          441 |     257       
</code></pre>

<p>As you can see they are highly imbalanced and leading to mis-classifications.</p>

<p>Steps I have performed till now</p>

<p><strong>1) Merge product_title and key_value_pairs column and remove stop words and special characters and perform stemming.</strong></p>

<p><strong>2) I have used pipeline for TFIDFvectorizer(), LinearSVC()</strong></p>

<pre><code>vectorizerPipe = Pipeline([
                 ('tfidf', TfidfVectorizer(lowercase=True, stop_words='english')),
                 ('classification', OneVsRestClassifier(LinearSVC(penalty='l2', loss='hinge'))),
                 ])
</code></pre>

<p>After this I have fit pipeline and stored the classifier in pickle</p>

<pre><code>prd = vectorizerPipe.fit(df.loc[:, 'description'], df.loc[:, 'taxonomy_id'])
</code></pre>

<p><strong>On Testing side I have repeated step 1 as mentioned above and then load the pickle and use predict function</strong></p>

<pre><code>pd = cl.predict([testData])
</code></pre>

<p>Issues I am facing </p>

<ol>
<li><p>A lot of products are being mis-classified into some other categories</p>

<p>Example: Ultimate Nutrition Prostar 100% Whey Protein should be classified into category 311 but my classifier is classifying it as 222 which is completely wrong.</p></li>
<li><p>I am not sure whether to use TFidfVectorizer() or Hashingvectorizer(), can you guys help me in selecting one of this along with  their parameters?</p></li>
<li><p>Algorithm I am using is LinearSVC, is it a good choice for multi-class classification problems with large amount of data? Or should I use different algorithms?</p></li>
<li><p>As my data is highly imbalanced I tried random undersampling. The results were improved but  they were still not up to the mark.
Also I am not sure whether this is the right approach to perform random undersampling:</p>

<pre><code>pipe = make_pipeline_imb(
    HashingVectorizer(lowercase=True),
    RandomUnderSampler(ratio={111: 405805, 112: 170431, 113: 241709, 114: 8341, 115: 50328, 116: 89445, 117: 650020, 121: 320803, 122: 162557, 123: 66156, 124: 36276, 131: 1196, 132: 3365, 133: 818, 134: 15001, 141: 6145, 142: 31783, 211: 24728, 212: 100000, 221: 791, 222: 8000, 223: 35406, 231: 785, 232: 3000, 251: 477, 252: 127, 253: 29563, 254: 33, 311: 2072, 321: 5370, 412: 652, 421: 520973, 422: 99171, 423: 16786, 425: 730, 427: 198, 429: 1249, 431: 13793, 441: 160},random_state=1), 
    OneVsRestClassifier(LinearSVC(penalty='l2', loss='hinge')))
</code></pre></li>
<li><p>I am new in machine learning so I have used this approach for text classification. If my approach is wrong then please correct me with right one.</p></li>
</ol>

<p>(It would be great if you give suggestion or solution with examples as it will help me understand better).</p>

<p>***EDIT-1****</p>

<pre><code>RndmFrst = RandomForestClassifier(n_estimators=100, max_depth=20, max_features=5000,n_jobs=-1)
LogReg = LogisticRegression()
voting = VotingClassifier(estimators=[('LogReg ', LogReg), ('RndmFrst', RndmFrst)], voting='soft', n_jobs=-1)

pipe = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,4), max_features=50000)), ('clf', voting)])

pipe = pipe.fit(df.loc[:,'description'], df.loc[:,'taxonomy_id'])
Preds = pipe.predict(test_data)
</code></pre>
",1,27891,,9,46356,69822,2019-03-20T11:48:12.147,2019-03-19T17:00:47.510,1,1,,
30603,1,2018-04-21T06:52:13.553,2,181,<machine-learning><python><neural-network><deep-learning><mlp>,Neural Network Hidden Layer Selection,"<p>I am trying to build an <code>MLP</code> classifier model on a dataset containing 30000 samples and 23 features. 
What are the standards I need to consider while selecting the number of hidden layers and number of nodes in each hidden layer?</p>
",1,30608,,2,50146,28175,2018-04-21T14:53:45.480,2018-04-21T14:53:45.480,2,1,,
81328,1,2020-09-07T09:18:43.070,2,870,<machine-learning><python><supervised-learning><naive-bayes-classifier><naive-bayes-algorithim>,How to improve results from a Naive Bayes algorithm?,"<p>I am having some difficulties in improving results from running a Naive Bayes algorithm.
My dataset consists of 39 columns (some categorical, some numerical).
However I only considered the main variable, i.e. Text, which contains all the spam and ham messages.</p>
<p>Since it is a spam filtering, I think that this field can be good.
So I used countvectorizer and fit transform using them after removing stopwords.</p>
<p>I am getting a 60% of accuracy which is very very low!
What do you think may cause this low result? Is there anything that I can do to improve it?</p>
<p>These are the columns out of 39 that I am considering:</p>
<pre><code>Index(['Date', 'Username', 'Subject', 'Target',  'Country', 'Website','Text', 'Capital', 'Punctuation'],
      dtype='object')
</code></pre>
<p><code>Date</code> is in date format (e.g. <code>2018-02-06</code>)
<code>Username</code> is a string (e.g. <code>Math</code>)
<code>Subject</code> is a string (e.g. <code>I need your help</code>)
<code>Target</code> is a binary variable (<code>1</code> -spam or <code>0</code>-not spam)
<code>Country</code> is a string (e.g. <code>US</code>)
<code>Website</code> is a string (e.g. <code>www.viagra.com</code>)
<code>Text</code> is the corpus of the email and it is a string (e.g. <code>I need your HELP!!</code>)
<code>Capital</code> is a string (e.g. <code>HELP</code>)
<code>Punctuation</code> is string (<code>!!</code>)</p>
<p>What I have done is the following:</p>
<ul>
<li><p>removing stopwords in Text:</p>
<p>def clean_text(text):</p>
<pre><code>  lim_pun = [char for char in string.punctuation if char in &quot;&amp;#^_&quot;]
  nopunc = [char for char in text if char not in lim_pun]

  nopunc = ''.join(nopunc)

  other_stop=['•','...in','...the','...you\'ve','–','—','-','⋆','...','C.','c','|','...The','...The','...When','...A','C','+','1','2','3','4','5','6','7','8','9','10', '2016',  'speak','also', 'seen','[5].',  'using', 'get',  'instead',  &quot;that's&quot;,  '......','may', 'e', '...it', 'puts', '...over', '[✯]','happens', &quot;they're&quot;,'hwo',  '...a', 'called',  '50s','c;', '20',  'per', 'however,','it,', 'yet', 'one', 'bs,', 'ms,', 'sr.',  '...taking',  'may', '...of', 'course,', 'get', 'likely', 'no,']

  ext_stopwords=stopwords.words('english')+other_stop

  clean_words = [word for word in nopunc.split() if word.lower() not in ext_stopwords]
  return clean_words
</code></pre>
</li>
</ul>
<p>Then applying these changes to my dataset:</p>
<pre><code>from sklearn.feature_extraction.text import CountVectorizer
import string
from nltk.corpus import stopwords

df=df.dropna(subset=['Subject', 'Text']) 
df['Corpus']=df['Subject']+df['Text']
mex = CountVectorizer(analyzer=clean_text).fit_transform(df['Corpus'].str.lower())
</code></pre>
<p>and split my dataset into train and test:</p>
<pre><code>X_train, X_test, y_train, y_test = train_test_split(mex, df['Target'], test_size = 0.80, random_state = 0)
</code></pre>
<p><code>df</code> includes 1110 emails with 322 spam emails.</p>
<p>Then I consider my classifier:</p>
<pre><code># Multinomial Naive Bayes 

from sklearn.naive_bayes import MultinomialNB

classifier = MultinomialNB()
classifier.fit(X_train, y_train)

print(classifier.predict(X_train))

print(y_train.values)

# Train data set

    from sklearn.metrics import classification_report,confusion_matrix, accuracy_score
    from sklearn.metrics import accuracy_score
    
    pred = classifier.predict(X_train)
    
    print(classification_report(y_train ,pred ))
    print('Confusion Matrix: \n',confusion_matrix(y_train,pred))
    print()
    
    print(&quot;MNB Accuracy Score -&gt; &quot;,accuracy_score(y_train, pred)*100)
    
    print('Predicted value: ',classifier.predict(X_test))
    
    print('Actual value: ',y_test.values)
</code></pre>
<p>and evaluate the model on the test set:</p>
<pre><code>from sklearn.metrics import classification_report,confusion_matrix, accuracy_score

pred = classifier.predict(X_test)

print(classification_report(y_test ,pred ))
print('Confusion Matrix: \n', confusion_matrix(y_test,pred))
print()
print(&quot;MNB Accuracy Score -&gt; &quot;,accuracy_score(y_test, pred)*100)
</code></pre>
<p>getting approx 60%, which is not good at all.
Output:</p>
<pre><code>  precision    recall  f1-score   support

         0.0       0.77      0.34      0.47       192
         1.0       0.53      0.88      0.66       164

    accuracy                           0.59       356
   macro avg       0.65      0.61      0.57       356
weighted avg       0.66      0.59      0.56       356

Confusion Matrix: 
 [[ 66 126]
 [ 20 144]]
</code></pre>
<p>I do not know if the problem are the stopwords or the fact that I am considering only Text or Corpus as column (it would be also good to consider Capital letters and punctuation as variables in the model).</p>
",1,81331,,2,96815,96815,2020-09-07T12:13:02.363,2020-09-07T11:35:46.070,1,2,,
54515,1,2019-06-26T06:30:32.113,1,219,<machine-learning><python><classification><model-selection><classifier>,"Building document classifier based on keywords, what would be the steps?","<p>I have a requirement of classifying documents(<code>.doc</code> files) based on the profiles. I have a <code>csv</code> file with data:</p>

<pre><code>label          keyWords
Web developer  [""html"",""css"",""php""]
Developer      [""core"",""java"",""python""]
Embedded Dev   [""ARM"", ""CORTEX"", ""C""]
</code></pre>

<p>Now I want to classify the <code>.doc</code> files.</p>

<p>Also please do tell me what <code>model</code> to use ? or broad steps for proceeding (like building dataframe-> then splitting data and so on...)</p>

<p><strong>EDIT:</strong><br>Any pointers on how to proceed with document classifier ?</p>
",1,54555,,1,76674,76674,2019-06-28T09:39:21.223,2019-06-28T09:39:21.223,1,7,,
32627,1,2018-06-04T19:18:00.397,0,2750,<machine-learning><python><time-series><anomaly-detection><ipython>,"Python: Detect if data of a time series stays constant, increases or decreases","<p>i need to analyse and later try to improve (integrate a filter) for measurement data that i compare to accurate reference data with python.</p>

<p>First i want to calculate the mean offset and the standard deviation of the measurement data overall, during halt, increasing and decreasing state.</p>

<p>How can i automatically detect and mark sections in which the reference system data stays constant, increases or decreases and use this information later for the statistical analysis. </p>

<p>I already tried to write a simple algorithm myself but the problem is though the reference data is given precise enough so you can calculate the difference of two neighbouring data points and it is zero if no change takes place this case is also in the majority during sections of change (increase, decrease). So the algorithm can't really mark the state of the data points reliable.</p>

<p>I already researched a little bit and here are some keywords that seemed interesting for my problem: time series analysis, anomaly detection, novelty detection, change point detection, structural changes, One-Class Support Vector Machines</p>

<p>So my question would be if sb. could give me a pointer towards the right direction (correct method, python package, tutorial, example) so i can solve this problem myself.</p>
",1,32635,,0,53148,53148,2018-06-04T21:05:05.737,2018-06-04T19:26:41.697,1,1,,
16653,1,2017-01-31T17:15:04.190,1,14953,<python><pandas><json>,Unable to open .json file in pandas,"<p><a href=""https://i.stack.imgur.com/nw5lt.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nw5lt.jpg"" alt=""enter image description here""></a></p>

<p>I want to convert a json file into a dataframe in pandas (Python). I tried with <code>read_json()</code> but got the error:</p>

<pre><code>UnicodeDecodeError:'charmap' codec can't decode byte 0x81 in position 21596351:character maps to &lt;undefined&gt; 
</code></pre>

<p>I think I have some unwanted data in the json file like noise. The data is server generated.</p>

<p>This is a collection from the json file:</p>

<pre><code>{""_id"":{""$oid"":""57a30ce368fd0809ec4d1b41""},""session"":{""start_timestamp"":{""$numberLong"":""1470151881189""},""session_id"":""8356bd90-20160802-153121189""},""metrics"":{},""arrival_timestamp"":{""$numberLong"":""1470152028294""},""event_type"":""OfferViewed"",""event_timestamp"":{""$numberLong"":""1470151943271""},""event_version"":""3.0"",""application"":{""package_name"":""com.think.vito"",""title"":""Vito"",""version_code"":""5"",""app_id"":""7ffa58dab3c646cea642e961ff8a8070"",""cognito_identity_pool_id"":""us-east-1:4d9cf803-0487-44ec-be27-1e160d15df74"",""version_name"":""2.0.0.0"",""sdk"":{""version"":""2.2.2"",""name"":""aws-sdk-android""}},""client"":{""cognito_id"":""us-east-1:1d507b8f-857c-42a4-a705-8db07d46bc8f"",""client_id"":""aa092911-b9a7-498a-82da-76318356bd90""},""device"":{""locale"":{""country"":""US"",""code"":""en_US"",""language"":""en""},""platform"":{""version"":""5.1.1"",""name"":""ANDROID""},""make"":""Xiaomi"",""model"":""Redmi Note 3""},""attributes"":{""Category"":""90000"",""CustomerID"":""4077"",""OfferID"":""11846""}}
</code></pre>
",1,16662,,1,28344,25157,2017-02-01T16:45:20.843,2017-02-01T16:19:02.260,3,3,,
51429,1,2019-05-05T12:24:56.560,2,2363,<python><deep-learning><keras><cnn><computer-vision>,memory error while converting images into an array,"<p>I am working on a facial recognition use case. I have 57k jpg images and am converting them into an array. While executing the program, I am getting a  memory error.</p>

<p>The function I am using:</p>

<pre><code>def image_array(l):
    features = []
    for pgm in l:
        pic = image.load_img(pgm, target_size=(224, 224))
        x = image.img_to_array(pic)
        x = np.expand_dims(x, axis=0)
        x = preprocess_input(x)
        features.append(x)
    npfeatures = np.array(features)
    img_dt = np.rollaxis(npfeatures, 1, 0)
    return img_dt[0]
</code></pre>

<p>The input for this function is a list which looks like:</p>

<p><code>l =['/home/user/image1.jpg','/home/user/image2.jpg','/home/user/image3.jpg'......]</code></p>

<p>The error that I am getting: </p>

<pre><code>Traceback (most recent call last):
  File ""FR.py"", line 145, in &lt;module&gt;
    vec_image1 = image_array(final_df['image1'].values.tolist())
  File ""FR.py"", line 140, in image_array
    npfeatures = np.array(features)
MemoryError
</code></pre>

<p>The imports that I used for above function are:</p>

<pre><code>&gt; from keras.preprocessing import image 
&gt; from keras.applications.vgg16 import preprocess_input
</code></pre>
",1,51433,,2,73678,29169,2019-05-05T22:30:39.867,2019-05-05T22:30:39.867,1,2,,
34181,1,2018-07-09T09:09:46.713,1,5773,<python><deep-learning><numpy>,Appending to numpy array for creating dataset,"<p>I want to create a dataset from three numpy matrices - train1 = (204,), train2 = (204,) and train3 = (204,). Basically all sets are of same length. I am applying a sliding window function on each of window 4. Each set become of shape =(201,4) I want a new array in which all these values are appended row wise. Like for first train1 then train2 then train3. And final output set is of size =(603,4). </p>

<p>This is a sliding window function which converts array of shape (204,) to (201,4)</p>

<pre><code>def moving_window(x, length, step=1):
    streams = it.tee(x, length) 
    return zip(*[it.islice(stream, i, None, step) for stream, i in zip(streams, it.count(step=step))]) 
</code></pre>

<p>Create dataset fucntion is:</p>

<pre><code>def create_dataset(dataset1,dataset2):
    dataX=[]       
    x=list(moving_window(dataset1,4))
    x=np.asarray(x) 
    dataX.append(x)
    y=list(moving_window(dataset2,4)) 
    y=np.asarray(y) 
    dataX.append(y) 
    return np.array(dataX)

data_new=create_dataset(train1,train2)
</code></pre>

<p>It is returning a dataset of shape 0(2,201,4). I think this is appending differently, but I want row wise appending. so that the new _dataset is of shape= (402,4) with two sets and (603,4) with three sets. I want to generalize as well like if I want for 10 training sets or twenty training sets. How can I do that?</p>
",1,34195,,1,53283,29575,2018-07-09T13:13:55.463,2018-07-09T12:55:45.937,1,2,,
89778,1,2021-02-23T04:56:00.007,0,297,<python><keras><tensorflow><nlp>,to generate consistent encoding for words in Keras using tf.keras.preprocessing.text.one_hot,"<p>I am using keras(tensorflow) to convert text into encodings using <code>tensorflow.keras.preprocessing.text.one_hot</code></p>
<p>I have used it for training dataset as below</p>
<pre><code>from tensorflow.keras.preprocessing.text import one_hot

corpus = ['nice app']
onehot_repr = [one_hot(words, 10000) for words in corpus]

print(onehot_repr)
# [5779, 2969]
</code></pre>
<p>It's ok upto this point.</p>
<p>But when I use the <code>one_hot</code> for my testing set it generates different encoding.</p>
<p>I have created a Flask API to test, So how can use same encoding for both train and test set</p>
<p>Result from API is :</p>
<p><code>[[5129, 4965]]</code> for same text <code>['nice app']</code></p>
",1,90160,,0,44083,,2021-03-02T17:49:44.993,,1,1,,
80305,1,2020-08-14T18:13:21.483,1,248,<machine-learning><python><random-forest><cross-validation><machine-learning-model>,"High Cross Validation Score on Training Set, High Score on Test Set, But Low Score on Kaggle?","<p>I've been trying to complete this regression task on Kaggle. As usual they gave a train.csv(with response variable) and a test.csv (without response variable) file for us to train the model and compute our predictions, respectively.</p>
<p>I further split the train.csv file into a train_set and test_set. I use this subsequent train_set to train a list of models which I will then shortlist to one model only based on 10-fold cross validation scores (RMSLE) and after hyperparameter tuning.  Now I have one best model, which is Random Forest (with best hyperparameters) with an average RMSLE score of 0.55. At this point I have NOT touched the test_set.</p>
<p>Consequently, when I train the same exact model on train_set data, but evaluate its result on test_set (in order to avoid overfitting the hyperparameters I have tuned), it yields an RMSLE score of 0.54. This is when I get suspicious, because my score on test_set are slightly better than the average score of the train_set (test_set results are supposed to be slightly worse, since the model hasn't seen the test_set data, right?).</p>
<p>Finally, I proceed to submit my results using the same model but with the test.csv file (without response variable). But then Kaggle gave me an RMSLE score of 0.77, which is considerably worse than my cross validation scores and my test_set scores!</p>
<p>I am very frustrated and confused as to why this would happen, since I believe I've taken every measure to anticipate overfitting my model. Please give a detailed but simple explanation, I'm still a beginner so I might not understand overly technical terms.</p>
",1,80315,,1,103358,,2020-08-15T07:24:20.970,,2,5,,
20170,1,2017-07-04T15:50:47.963,7,754,<machine-learning><python><logistic-regression><accuracy>,Coursera ML - Does the choice of optimization algorithm affect the accuracy of multiclass logistic regression?,"<p>I recently completed <a href=""https://github.com/kohaugustine/Machine-Learning-Coursera/blob/master/machine-learning-ex3/Programming%20Exercise%203%20-%20Multi-class%20Classification%20and%20Neural%20Networks.ipynb"" rel=""noreferrer"">exercise 3 of Andrew Ng's Machine Learning on Coursera using Python</a>.</p>

<p>When initially completing parts 1.4 to 1.4.1 of the exercise, I ran into difficulties ensuring that my trained model has the accuracy that matches the expected 94.9%. Even after debugging and ensuring that my cost and gradient functions were bug free, and that my predictor code was working correctly, I was still getting only 90.3% accuracy. I was using the conjugate gradient (CG) algorithm in <code>scipy.optimize.minimize</code>.</p>

<p>Out of curiosity, I decided to try another algorithm, and used Broyden–Fletcher–Goldfarb–Shannon (BFGS). To my surprise, the accuracy improved drastically to 96.5% and thus exceeded the expectation. The comparison of these two different results between CG and BFGS can be viewed in my <a href=""https://github.com/kohaugustine/Machine-Learning-Coursera/blob/master/machine-learning-ex3/Programming%20Exercise%203%20-%20Multi-class%20Classification%20and%20Neural%20Networks.ipynb"" rel=""noreferrer"">notebook</a> under the header <strong>Difference in accuracy due to different optimization algorithms</strong>.</p>

<p>Is the reason for this difference in accuracy due to the different choice of optimization algorithm? If yes, then could someone explain why?</p>

<p>Also, I would greatly appreciate any review of my code just to make sure that there isn't a bug in any of my functions that is causing this.</p>

<p>Thank you.</p>

<p><strong>EDIT:</strong> Here below I added the code involved in the question, on the request in the comments that I do so in this page rather than refer readers to the links to my Jupyter notebooks.</p>

<p>Model cost functions:</p>

<pre><code>def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def compute_cost_regularized(theta, X, y, lda):
    reg =lda/(2*len(y)) * np.sum(theta[1:]**2) 
    return 1/len(y) * np.sum(-y @ np.log(sigmoid(X@theta)) 
                             - (1-y) @ np.log(1-sigmoid(X@theta))) + reg

def compute_gradient_regularized(theta, X, y, lda):
    gradient = np.zeros(len(theta))
    XT = X.T
    beta = sigmoid(X@theta) - y
    regterm = lda/len(y) * theta
    # theta_0 does not get regularized, so a 0 is substituted in its place
    regterm[0] = 0 
    gradient = (1/len(y) * XT@beta).T + regterm
    return gradient
</code></pre>

<p>Function that implements one-vs-all classification training:</p>

<pre><code>from scipy.optimize import minimize

def train_one_vs_all(X, y, opt_method):
    theta_all = np.zeros((y.max()-y.min()+1, X.shape[1]))
    for k in range(y.min(),y.max()+1):
        grdtruth = np.where(y==k, 1,0)
        results = minimize(compute_cost_regularized, theta_all[k-1,:], 
                           args = (X,grdtruth,0.1),
                           method = opt_method, 
                           jac = compute_gradient_regularized)
        # optimized parameters are accessible through the x attribute
        theta_optimized = results.x
        # Assign thetheta_optimized vector to the appropriate row in the 
        # theta_all matrix
        theta_all[k-1,:] = theta_optimized
    return theta_all
</code></pre>

<p>Called the function to train the model with different optimization methods:</p>

<pre><code>theta_all_optimized_cg = train_one_vs_all(X_bias, y, 'CG')  # Optimization performed using Conjugate Gradient
theta_all_optimized_bfgs = train_one_vs_all(X_bias, y, 'BFGS') # optimization performed using Broyden–Fletcher–Goldfarb–Shanno
</code></pre>

<p>We see that prediction results differ based on the algorithm used:</p>

<pre><code>def predict_one_vs_all(X, theta):
    return np.mean(np.argmax(sigmoid(X@theta.T), axis=1)+1 == y)*100

In[16]: predict_one_vs_all(X_bias, theta_all_optimized_cg)
Out[16]: 90.319999999999993

In[17]: predict_one_vs_all(X_bias, theta_all_optimized_bfgs)
Out[17]: 96.480000000000004
</code></pre>

<p>For anyone wanting to get any data to try the code, they can find it in my Github as linked in this post. </p>
",1,20259,,7,33716,33716,2017-07-11T12:07:47.747,2017-07-06T15:06:52.373,2,8,,
81034,1,2020-08-31T14:00:28.347,1,301,<machine-learning><python><nlp><nltk>,How to properly compare these two confusion matrix?,"<p>I have used Vader, a sentiment analysis tool for social media, on a database of movie reviews. These two confusion matrices differ in the vader.py algorithm, as the first one is from nltk:</p>
<p><a href=""https://i.stack.imgur.com/YuSdn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YuSdn.png"" alt=""enter image description here"" /></a></p>
<p>The second one is deriving from Vader's original code on github and includes fixes to negation words, etc.</p>
<p><a href=""https://i.stack.imgur.com/0XYa7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0XYa7.png"" alt=""enter image description here"" /></a></p>
<p>I was wondering how could I properly compare the two, as I'm not really able to read them. It seems there is not a big difference between them and I don't understand what could be the sources of the errors here.</p>
",1,81114,,1,104104,104104,2020-09-02T10:05:17.187,2020-09-01T14:31:59.037,1,9,,
22177,1,2017-08-11T11:20:38.073,10,7332,<python><tensorflow><keras><rnn><lstm>,How to use Embedding() with 3D tensor in Keras?,"<p>I have a list of stock price sequences with 20 timesteps each. That's a 2D array of shape <code>(total_seq, 20)</code>. I can reshape it into <code>(total_seq, 20, 1)</code> for concatenation to other features.</p>
<p>I also have news title with 10 words for each timestep. So I have 3D array of shape <code>(total_seq, 20, 10)</code> of the news' tokens from <code>Tokenizer.texts_to_sequences()</code> and <code>sequence.pad_sequences()</code>.</p>
<p>I want to concatenate the news embedding to the stock price and make predictions.</p>
<blockquote>
<p>My idea is that the news embedding should return tensor of shape
<code>(total_seq, 20, embed_size)</code> so that I can concatenate it with the
stock price of shape <code>(total_seq, 20, 1)</code> then connect it to LSTM layers.</p>
</blockquote>
<p>To do that, I should convert news embedding of shape <code>(total_seq, 20, 10)</code> to
<code>(total_seq, 20, 10, embed_size)</code> by using <code>Embedding()</code> function.</p>
<blockquote>
</blockquote>
<p>But in Keras, the <code>Embedding()</code> function takes a 2D tensor instead of 3D tensor. How do I get around with this problem?</p>
<p>Assume that <code>Embedding()</code> accepts 3D tensor, then after I get 4D tensor as output, I would remove the 3rd dimension by using LSTM to return last word's embedding only, so output of shape <code>(total_seq, 20, 10, embed_size)</code> would be converted to <code>(total_seq, 20, embed_size)</code></p>
<blockquote>
<p>But I would encounter another problem again, LSTM accepts 3D tensor not 4D so</p>
</blockquote>
<p>How do I get around with Embedding and LSTM not accepting my inputs?</p>
",1,22183,,10,37814,98307,2020-08-02T10:28:43.933,2020-08-02T10:28:43.933,1,6,,
58656,1,2019-09-04T10:06:06.823,0,1868,<machine-learning><python><hyperparameter><gridsearchcv><lightgbm>,"How to choose the model parameters (RandomizedSearchCV, .GridSearchCV) or manually","<p>Faced with the task of selecting parameters for the lightgbm model, the question accordingly arises, what is the best way to select them? I used the RandomizedSearchCV method, within 10 hours the parameters were selected, but there was no sense in it, the accuracy was the same as when manually entering the parameters at random. +/- the meaning of the parameters is clear, which ones are responsible for retraining, which ones are for the accuracy and speed of training, but it’s not entirely clear if you select manually one at a time or in pairs, or even more options?</p>

<p>Below is an example of how I implemented the selection of parameters:</p>

<pre><code>SEED = 4 
NFOLDS = 2
kf = KFold(n_splits= NFOLDS, shuffle=False)

    parameters = {
          'num_leaves': np.arange(100,500,100),
          'min_child_weight': np.arange(0.01,1,0.01),
          'feature_fraction': np.arange(0.1,0.4,0.01),
          'bagging_fraction':np.arange(0.3,0.5,0.01),
          'min_data_in_leaf': np.arange(100,1500,10),
          'objective': ['binary'],
          'max_depth': [-1],
          'learning_rate':np.arange(0.001,0.02,0.001),
          ""boosting_type"": ['gbdt'],
          ""bagging_seed"": np.arange(10,42,5),
          ""metric"": ['auc'],
          ""verbosity"": [1],
          'reg_alpha': np.arange(0.3,1,0.2),
          'reg_lambda':  np.arange(0.37,0.39,0.001),
          'random_state': [425],
          'n_estimators': [500]}

model = lightgbm.LGBMClassifier()
RSCV = RandomizedSearchCV(model,parameters,scoring='roc_auc',cv=kf.split(train),n_iter=30,verbose=50)
RSCV.fit(train,label)
</code></pre>
",1,58676,,0,80647,,2019-09-04T14:46:51.303,,1,3,,
9670,1,2016-01-07T10:04:14.607,3,431,<python><nlp><nltk>,Python: validating the existence of NLTK data with database search,"<p>I need to pull the names of companies out of resumes. Thousands of them. I was thinking of using NLTK to create a list of possible companies, and then cross-referencing the list of strings with something like SEC.gov.</p>

<p>I've already been able to successfully pull the candidate's name, and contact info off of the resumes with some RegEx, but this one has me quite stumped.</p>

<p>What I'm thinking is that I could use NLTK to create a list of strings of proper nouns from the resume's, and then search SEC.gov, or some other database.</p>

<p>This is a link to the SEC page I would be searching: SEC company search page</p>

<pre><code>Read Resume1
Get all potential company names as list of strings potentialCompanies
    IF searching for string1 in SEC gets result, THEN add to candidateCompanies
        ELSE remove from potentialCompanies, go to next string
</code></pre>

<p>My Questions</p>

<p>To people that have used NLTK, would there be a better way of getting the potential companies from the text besides using proper nouns?</p>

<p>Would there be a better place to search for companies than the SEC site?</p>

<p>I have never done any web scraping before, and don't really know where to start if it is needed.</p>

<p>(I had posted this on Stack Overflow but they told me that it might be better suited for here...)</p>
",1,9671,,3,15233,11097,2016-01-07T10:14:52.510,2016-01-07T10:06:46.510,1,2,,
65980,1,2020-01-06T19:14:02.980,2,215,<python><classification><categorical-data><supervised-learning>,Classification when variables are in ranges,"<p>I want to classify my data and some of my variables are ranges.</p>

<p>I classify location so for example, school, the hours that people are at school are from 7:00 to 14:00, some of my variables are categorical (working day) and some of them numerics(frequency of visiting in a month).</p>

<p>I thought using LDA but how can I declare a range as one variable? </p>

<p>btw, I use Python</p>

<p>Example:</p>

<pre><code>place         visiting time    frequency    workday
school         8:00-14:00        18-20           1
restaurant    13:00-21:00        0-3            both
bank          8:00-17:00         0-4             1
night club     21:00-2:00        0-4            both
</code></pre>

<p>The algorithm should be supervised because I insert the ground truth (the place) by myself.</p>

<p>TIA </p>
",1,65985,,2,82276,82276,2020-01-06T20:34:43.970,2020-01-06T20:04:12.820,2,2,,
8625,1,2015-10-28T02:21:19.663,19,33531,<python><regression><library><software-recommendation>,Multivariate linear regression in Python,"<p>I'm looking for a Python package that implements multivariate linear regression.</p>

<p>(Terminological note: <em>multivariate</em> regression deals with the case where there are more than one dependent variables while <em>multiple</em> regression deals with the case where there is one dependent variable but more than one independent variables.)</p>
",1,8632,,19,843,843,2017-08-28T23:07:58.010,2015-10-30T03:30:28.643,2,1,,
93501,1,2021-04-24T19:33:07.107,1,22,<python><dataset><pandas><data-table>,Pandas: Group by Single Column Entries,"<p><a href=""https://i.stack.imgur.com/RD5ag.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RD5ag.png"" alt=""enter image description here"" /></a></p>
<p>So have this table above. I'm trying to aggregate the occupations such that the table results in:</p>
<p><a href=""https://i.stack.imgur.com/9EULv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9EULv.png"" alt=""enter image description here"" /></a></p>
<p>I've tried using <code>df.groupby(['Occupation'])</code> but I get an error.
All I know is that my final step would be to set the index to &quot;Occupation&quot;. But I still don't know how to group via entries in the single Occupation column here.</p>
<p>Also, what type of table would the final table be name/called?</p>
<p>I know it's not called a mutiindex table because there is only one index that the results are being grouped by.</p>
",1,93506,,1,116594,43000,2021-04-24T23:26:19.417,2021-04-24T22:25:08.130,1,1,2021-04-25T12:37:03.560,
47628,1,2019-03-19T15:45:40.363,1,8244,<python><clustering><unsupervised-learning>,Clustering based on distance between points,"<p>I am trying to cluster geographical locations in such a way that all the locations inside each cluster are at max within 25 miles of each other. For this, I am using Agglomerative clustering. I am using a custom distance function to calculate the distances between each location. I do not want to specify the number of clusters. Instead, I want the model to cluster until all the locations within each cluster are within 25 miles of each other. I have tried doing this in both Scipy and Sklearn but haven't made any progress. Below is the approach that I have tried. It only gives me one cluster. Please help. Thanks in advance.</p>

<pre><code>from scipy.cluster.hierarchy import fclusterdata 
max_dist = 25
# dist is a custom function that calculates the distance (in miles) between two locations using the geographical coordinates

fclusterdata(locations_in_RI[['Latitude', 'Longitude']].values, t=max_dist, metric=dist, criterion='distance')
</code></pre>
",1,47635,,1,59627,,2019-03-19T19:02:39.427,,1,2,2019-03-20T11:25:44.167,
46943,1,2019-03-08T15:47:15.917,2,5971,<python><deep-learning><keras><scikit-learn><tensorflow>,n_jobs = -1 equivalent in keras,"<p>I have recently started learning deep learning. In machine learning using sklearn library with n_jobs = -1 all my cpu cores are used and this speeds the grid search. Now I am trying to fit an rnn model on training data, which is taking a lot of time. Is there a way I can speed up the training?</p>

<pre><code># Initialising the RNN
regressor = Sequential()

# Adding the first LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 7)))
regressor.add(Dropout(0.2))

# Adding a second LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(0.2))

# Adding a third LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(0.2))

# Adding a fourth LSTM layer and some Dropout regularisation
regressor.add(LSTM(units = 50))
regressor.add(Dropout(0.2))

# Adding the output layer
regressor.add(Dense(units = 1))

# Compiling the RNN
regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')

# Fitting the RNN to the Training set
regressor.fit(X_train, y_train, epochs = 100, batch_size = 32,shuffle=False)
</code></pre>
",1,46970,,2,67537,,2019-03-09T20:12:59.890,,1,1,,
44219,1,2019-01-18T20:08:23.250,3,1353,<python><scikit-learn><imbalanced-learn><smotenc>,How to use SMOTENC inside the Pipeline?,"<p>I would greatly appreciate if you could let me know how to use <a href=""https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTENC.html"" rel=""nofollow noreferrer"">SMOTENC</a>.  I wrote: </p>

<pre><code>num_indices1 = list(X.iloc[:,np.r_[0:94,95,97,100:123]].columns.values)
cat_indices1 = list(X.iloc[:,np.r_[94,96,98,99,123:160]].columns.values)
print(len(num_indices1))
print(len(cat_indices1))

pipeline=Pipeline(steps= [
    # Categorical features
    ('feature_processing', FeatureUnion(transformer_list = [
            ('categorical', MultiColumn(cat_indices1)),

            #numeric
            ('numeric', Pipeline(steps = [
                ('select', MultiColumn(num_indices1)),
                ('scale', StandardScaler())
                        ]))
        ])),
    ('clf', rg)
    ]
)
</code></pre>

<p>Therefore, as it is indicated I have 5 categorical features. Really, indices 123 to 160 are related to one categorical feature with 37 possible values which is converted into 37 columns using <code>get_dummies</code>.</p>

<p>I think <code>SMOTENC</code> should be inserted before the classifier <code>('clf', reg)</code> but I don't know how to define ""<code>categorical_features</code>"" in <code>SMOTENC</code>. Besides, could you please let me know where to use <a href=""https://imbalanced-learn.readthedocs.io/en/stable/api.html#module-imblearn.pipeline"" rel=""nofollow noreferrer"">imblearn.pipeline</a>? </p>

<p>Thanks in advance.</p>
",1,62220,,3,26019,,2019-10-25T14:43:20.500,,1,6,,
17695,1,2017-03-19T17:17:02.720,3,5108,<python><dataset><regression>,How to treat outliers in a time series dataset?,"<p>I've read the following article about how to treat outliers in a dataset: <a href=""http://napitupulu-jon.appspot.com/posts/outliers-ud120.html"" rel=""nofollow noreferrer"">http://napitupulu-jon.appspot.com/posts/outliers-ud120.html</a></p>

<p>Basically, he removes all the y which has a huge difference with the majority:</p>

<pre><code>def outlierCleaner(predictions, ages, net_worths):
    """"""
        clean away the 10% of points that have the largest
        residual errors (different between the prediction
        and the actual net worth)

        return a list of tuples named cleaned_data where 
        each tuple is of the form (age, net_worth, error)
    """"""

    #calculate the error,make it descend sort, and fetch 90% of the data

    errors = (net_worths-predictions)**2
    cleaned_data =zip(ages,net_worths,errors)
    cleaned_data = sorted(cleaned_data,key=lambda x:x[2][0], reverse=True)
    limit = int(len(net_worths)*0.1)


    return cleaned_data[limit:]
</code></pre>

<p>But how may I apply this technique to a time series dataset if its rows are correlative?</p>
",1,17742,,3,30149,30149,2018-04-16T03:36:03.650,2017-03-19T20:56:27.267,1,2,,
11347,1,2016-04-21T18:49:50.497,11,92311,<python><statistics><pandas><ipython>,How to group identical values and count their frequency in Python?,"<p>Newbie to analytics with Python so please be gentle :-) I couldn't find the answer to this question - apologies if it is already answered elsewhere in a different format.</p>

<p>I have a dataset of transaction data for a retail outlet. Variables along with explanation are:</p>

<ul>
<li>section: the section of the store, a str;</li>
<li>prod_name: name of the product, a str;</li>
<li>receipt: the number of the invoice, an int;</li>
<li>cashier, the number of the cashier, an int;</li>
<li>cost: the cost of the item, a float;</li>
<li>date, in format MM/DD/YY, a str;</li>
<li>time, in format HH:MM:SS, a str;</li>
</ul>

<p>Receipt has the same value for all the products purchased in a single transaction, thus it can be used to determine the average number of purchases made in a single transaction.</p>

<p>What is the best way to go about this? I essentially want to use <code>groupby()</code> to group the receipt variable by its own identical occurrences so that I can create a histogram.</p>

<p>Working with the data in a pandas DataFrame.</p>

<p><strong>EDIT:</strong></p>

<p>Here is some sample data with header (prod_name is actually a hex number):</p>

<pre><code> section,prod_name,receipt,cashier,cost,date,time 
 electronics,b46f23e7,102856,5,70.50,05/20/15,9:08:20 
 womenswear,74558d0d,102857,8,20.00,05/20/15,9:12:46 
 womenswear,031f36b7,102857,8,30.00,05/20/15,9:12:47 
 menswear,1d52cd9d,102858,3,65.00,05/20/15,9:08:20 
</code></pre>

<p>From this sample set I would expect a histogram of receipt that shows two occurrences of receipt 102857 (since that person bought two items in one transaction) and one occurrence respectively of receipt 102856 and of receipt 102858. Note: my dataset is not huge, about 1 million rows.</p>
",1,11373,,11,18058,381,2020-07-31T15:36:13.737,2016-04-22T17:32:34.170,3,1,,
94594,1,2021-05-18T09:28:03.233,2,315,<python><neural-network><keras><tensorflow><reinforcement-learning>,"Slow keras fit method with 100x100 array, how can I make it faster?","<p>how can I make this training faster ?
when I call the fit method on a 100 x 100 matrix goes very slow</p>
<p>my model it's a sequential</p>
<pre><code>h = self.model.fit(
        inputs,
        targets,
        epochs=epochs,
        batch_size=16,
        verbose=1,
)
</code></pre>
<p>this is my matrix</p>
<pre><code>def build(n):
    mat=np.ones(N*N)
    return mat.reshape((N,N))
</code></pre>
<p>this is the of my Qtraining</p>
<pre><code>qt = Qtraining(model,
               env,
               n_epoch=200,
               max_memory=500,
               data_size=100,
               name='model100')
</code></pre>
<p>This is the experience method</p>
<pre><code>def get_data(self, data_size=10):
        env_size = self.memory[0][0].shape[1]  # env_state 1d size (1st element of episode)
        mem_size = len(self.memory)
        data_size = min(mem_size, data_size)
        inputs = np.zeros((data_size, env_size)) # metti Nsize righe di 0 , e envSize elementi 0
        targets = np.zeros((data_size, self.num_actions))#
        for i, j in enumerate(np.random.choice(range(mem_size), data_size, replace=False)):
            env_state, action, reward, next_env_state, game_over = self.memory[j]
            inputs[i] = env_state
            # There should be no target values for actions not taken.
            # Thou shalt not correct actions not taken #deep (quote by Eder Santana)
            targets[i] = self.predict(env_state)
            # Q_sa = derived policy = max quality env/action = max_a' Q(s', a')
            Q_sa = np.max(self.predict(next_env_state))
            if game_over:
                targets[i, action] = reward
            else:
                # reward + gamma * max_a' Q(s', a')
                targets[i, action] = reward + self.discount * Q_sa
       
        return inputs, targets
</code></pre>
<hr />
<p>using a 50 x 50 matrix I get 2500 cells, and in the construction of the neural network I have a 2500x2500 parameters + 2500 for a total of 6252500.
I think that slows down operations.
and there are only 3 Danse layers, the last one is size 4 because of the possible actions that are 4.
Is it possible to reduce the time of operation by adding more Danse layers?</p>
<p>this is my model</p>
<pre><code>def build_model(env, **opt):
loss = opt.get('loss', 'mse')
a = opt.get('alpha', 0.24)
model = Sequential()
esize = env.maze.size
model.add(Dense(esize, input_shape=(esize,)))
model.add(LeakyReLU(alpha=a))
model.add(Dense(esize))
model.add(LeakyReLU(alpha=a))
model.add(Dense(num_actions))
model.compile(optimizer='adam', loss='mse')
return model
</code></pre>
",1,107813,,2,117892,29575,2022-02-03T20:27:27.847,2022-01-13T13:44:15.563,2,3,,
89605,1,2021-02-19T13:54:23.977,0,510,<python><scikit-learn><pandas><evaluation><wikipedia>,IterativeImputer Evaluation,"<p>I am having a hard time evaluating my model of <strong>imputation</strong>.</p>
<p>I used an iterative imputer model to fill in the missing values in all four columns.</p>
<p>For the model on the iterative imputer, I am using a Random forest model, here is my code for imputing:</p>
<pre><code>imp_mean = IterativeImputer(estimator=RandomForestRegressor(), random_state=0)
imp_mean.fit(my_data)
my_data_filled=  pd.DataFrame(imp_mean.transform(my_data))
my_data_filled.head()
</code></pre>
<p>My problem is how can I evaluate my model. How can I know if the filled values are right?</p>
<p>I used a describe function before and after filling in the missing values it gives me nearly the same mean and std. Also, the correlation between variables stayed nearly the same with slight changes.</p>
",1,89622,,0,112137,,2022-05-31T09:53:56.970,,2,1,,
10857,1,2016-03-23T19:47:30.083,10,44668,<python><pandas><scraping>,How to scrape a table from a webpage?,"<p>I need to scrape a table off of a webpage and put it into a pandas data frame. But I am not being able to do it. Let me first give you a hint of how the table is encoded into html document. </p>

<pre><code>&lt;tbody&gt;
&lt;tr&gt;
&lt;th colspan=""2""&gt;United States Total&lt;strong&gt;**&lt;/strong&gt;&lt;/th&gt;
&lt;td&gt;&lt;strong&gt;15,069.0&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;14,575.0&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;100.0&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;th colspan=""7""&gt;Arizona&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pinal Energy, LLC&lt;/td&gt;
&lt;td&gt;Maricopa, AZ&lt;/td&gt;
&lt;td&gt;50.0&lt;/td&gt;
&lt;td&gt;50.0&lt;/td&gt;
&lt;td&gt;NA&lt;/td&gt;
&lt;td&gt;2012-07-01&lt;/td&gt;
&lt;td&gt;2014-03&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=""2""&gt;&lt;strong&gt;Arizona Total&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;50.0&lt;/td&gt;
&lt;td&gt;50.0&lt;/td&gt;
&lt;td&gt;NA&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
</code></pre>

<p>The body of the table begins with <code>&lt;tbody&gt;....&lt;/tbody&gt;</code>. Each <code>&lt;tr&gt;....&lt;/tr&gt;</code> is a row of the table.Within each row, that is within each pair of <code>&lt;tr&gt;....&lt;/tr&gt;</code>, each column is given by <code>&lt;td&gt;50.0&lt;/td&gt;</code>. </p>

<p>Here are my questions: </p>

<p>1) How do I scrape it ? I am using <code>BeautifulSoup</code> and <code>requests</code> for this purpose as well as <code>pandas</code> module. I tried the following:</p>

<pre><code>r = requests.get(url)
bs = BeautifulSoup(r.text)
info = bs.findALL('tr','td')
  ....
  ....
</code></pre>

<p>But it is giving me this error: </p>

<pre><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-24-32d9483e2c59&gt; in &lt;module&gt;()
      1 bs = BeautifulSoup(r.text)
----&gt; 2 info = bs.findALL('tr','td')
      3 #print bs

TypeError: 'NoneType' object is not callable
</code></pre>

<p>2) I need to skip some of the rows based on the text in it. For example I don't want to read in the row in which the word 'Total' appears (as in<code>&lt;th colspan=""2""&gt;United States Total&lt;strong&gt;**&lt;/strong&gt;&lt;/th&gt;</code>). How do I do that ? Although, it is not extremely important as I can get rid off it later, but skipping these rows while reading the data is ideally what I need.</p>

<p>I know it is a long post, but if someone can help me with it, i would greatly appreciate it. Please let me know if more information is needed. </p>

<p>Thanks much.</p>
",1,10937,,10,3314,,2019-07-06T21:17:56.320,,1,2,,
5561,1,2015-04-20T17:04:42.813,1,1843,<data-mining><python>,Can someone explain the following error in my python code?,"<p>I am analyzing a dataset in Python for strictly learning purpose.
In the code below that I wrote, I am getting some errors which I cannot get rid off. Here is the code first:</p>

<pre><code>plt.plot(decade_mean.index, decade_mean.values, 'o-',color='r',lw=3,label = 'Decade Average')
plt.scatter(movieDF.year, movieDF.rating, color='k', alpha = 0.3, lw=2)
plt.xlabel('Year')
plt.ylabel('Rating')
remove_border()
</code></pre>

<p>I am getting the following errors:</p>

<pre><code>1. TypeError: 'str' object is not callable
2. NameError: name 'remove_border' is not defined
</code></pre>

<p>Also, the label='Decade Average' is not showing up in the plot.</p>

<p>What confuses me most is the fact that in a separate  code snippet for plots (see below), I didn't get the 1st error above, although <code>remove_border</code> was still a problem.</p>

<pre><code>plt.hist(movieDF.rating, bins = 5, color = 'blue', alpha = 0.3)
plt.xlabel('Rating')
</code></pre>

<p>Any explanations of all or some of the errors would be greatly appreciated. Thanks</p>

<p>Following the comments, I am posting the data and the traceback below:
decade_mean is given below.</p>

<pre><code>year
1970    8.925000
1980    8.650000
1990    8.615789
2000    8.378947
2010    8.233333
Name: rating, dtype: float64
</code></pre>

<p>traceback:</p>

<pre><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-361-a6efc7e46c45&gt; in &lt;module&gt;()
      1 plt.plot(decade_mean.index, decade_mean.values, 'o-',color='r',lw=3,label = 'Decade Average')
      2 plt.scatter(movieDF.year, movieDF.rating, color='k', alpha = 0.3, lw=2)
----&gt; 3 plt.xlabel('Year')
      4 plt.ylabel('Rating')
      5 remove_border()

TypeError: 'str' object is not callable
</code></pre>

<p>I have solved remove_border problem. It was a stupid mistake I made. But I couldn't figure out the problem with the 'str'.</p>
",1,5571,,1,3314,3314,2023-01-09T22:04:46.273,2015-04-21T13:59:30.500,2,2,,
66710,1,2020-01-19T15:55:17.103,1,260,<python><pandas><excel>,Comparing excel data sets in Pandas,"<p>Pretty new to Python, but as an SEO I'm looking at the benefits of using notebooks in my workflow. </p>

<p>I've got two excel files which I've cleaned and imported into a new notebook using pandas. </p>

<p>I'm trying to compare position changes and create a new dataframe with new columns to show previous, new, and changes in positions. </p>

<p>Have a look at the screengrabs[! of the data below. Thanks in advance.</p>

<p><a href=""https://i.stack.imgur.com/N6dMJ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/N6dMJ.png"" alt=""Dataframe1""></a>
<a href=""https://i.stack.imgur.com/TsK25.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/TsK25.png"" alt=""Dataframe2""></a></p>
",1,66711,,1,88601,,2020-01-19T19:58:36.443,,1,1,,
36447,1,2018-08-04T05:27:37.990,8,23773,<machine-learning><python><text-mining><topic-model>,Resume Parsing - extracting skills from resume using Machine Learning,"<p>I am trying to extract a skill set of an employee from his/her resume. I have resumes stored as plain text in Database. I do not have predefined skills in this case. How should I approach this problem?</p>

<p>I can think of two ways:</p>

<ol>
<li><p>Using <strong>unsupervised approach</strong> as I do not have predefined skillset with me.
I will extract the skills from the resume using <strong>topic modelling</strong> but if I'm not wrong Topic Modelling uses <strong>BOW</strong> approach which may not be useful in this case as those skills will appear hardly one or two times. (I would appreciate if you enlighten me more about topic modelling).</p></li>
<li><p>Another approach is manually labeling the skills for resume and making it <strong>supervised learning</strong> problem. But I have around 500 resumes, manual labeling will be very tedious and very time consuming. </p></li>
</ol>

<p>Any suggestions are welcome.</p>

<p>Thanks.</p>
",1,36456,,8,44083,44083,2019-11-05T12:57:48.417,2018-08-04T05:58:35.493,1,3,,
60955,1,2019-09-28T14:59:18.617,8,20882,<python><pandas><data-cleaning><numpy>,how to check all values in particular column has same data type or not?,"<p>I have column 'ABC' which has 5000 rows. Currently, dtype of column is object. Mostly it has string values but some values dtype is not string, I want to find all those rows and modify those rows. Column is as following:</p>

<pre><code>1 abc
2 def
3 ghi
4 23
5 mno
6 null
7 qwe
8 12-11-2019
...
...
...
4900 ert
5000 tyu
</code></pre>

<p>In above case, I can use for loop to find out rows which do not have desired dtype. I just wanted to know, is their better way to solve this issue.</p>

<p>Note: I am using Pandas.</p>
",1,60957,,8,82577,,2019-09-28T15:58:07.210,,1,3,,
13409,1,2016-08-13T17:18:57.950,0,2588,<python><categorical-data>,How to assign a new level to many levels of a categorical variable,"<p>I have a model which has many categorical variables. For each categorical variable there are many levels, like 50~. But not all of them have significant counts. I got these counts using the function <code>value_counts()</code> in Python:</p>

<pre><code>A                 50 
B                 38
C                 26
D                 18
E                 10
...
T                 1
X                 1
Z                 1
</code></pre>

<p>How can I change the levels with count (say) less than 5 to a new level ""others""?</p>

<pre><code>for x in data.class:
    if x.value_counts() &lt;30:
        x = ""others""
</code></pre>
",1,13527,,0,23208,381,2016-08-18T19:12:31.513,2016-08-13T22:35:48.043,2,1,,
23895,1,2017-10-18T20:30:52.027,43,56391,<python><deep-learning><tensorflow><keras><gpu>,Multi GPU in Keras,"<p>How we can program in the Keras library (or TensorFlow) to partition training on multiple GPUs? Let's say that you are in an Amazon ec2 instance that has 8 GPUs and you would like to use all of them to train faster, but your code is just for a single CPU or GPU.</p>
",1,25737,,43,40665,85045,2021-01-01T06:18:06.760,2021-01-01T06:18:06.760,4,7,,
106885,1,2022-01-09T18:24:03.507,0,441,<machine-learning><python><random-forest><decision-trees><data-science-model>,Interpreting 'values' of a Decision Tree,"<p>I am trying to interpret my decision tree here which was resulted as a part of pre-pruning-
<a href=""https://i.stack.imgur.com/yW28u.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yW28u.png"" alt=""enter image description here"" /></a></p>
<p>I am trying to understand why the values in my nodes are in decimal places. Ideally, they should represent the #observations that belong to a particular class in my binary classifier, they should have been absolute numbers
they are not percentages as well since they don't add up to 100.</p>
<p>this is the code I used to plot this tree-</p>
<pre><code>plt.figure(figsize=(15, 10))

out = tree.plot_tree(
    best_model2,
    feature_names=feature_names,
    filled=True,
    fontsize=9,
    node_ids=False,
    class_names=None,
)
for o in out:
    arrow = o.arrow_patch
    if arrow is not None:
        arrow.set_edgecolor(&quot;black&quot;)
        arrow.set_linewidth(1)
plt.show()

</code></pre>
<p>This tree was a post pruned tree with code as -</p>
<pre><code>best_model2 = DecisionTreeClassifier(
    ccp_alpha=0.002, class_weight={0: 0.15, 1: 0.85}, random_state=1
)
best_model2.fit(X_train, y_train)
</code></pre>
",1,106926,,0,130032,,2022-01-11T18:21:47.770,,1,3,,
17550,1,2017-03-13T12:22:43.720,3,1857,<python><neural-network><keras><theano><convolution>,CNN for classification giving extreme result probabilities,"<p>I'm having issues with my CNN, using Keras with Theano backend.
Basically, I need to classify 340x340 grayscale images into 6 categories. The problem is my CNN gives too ""hard"" probabilities, for instance it will rarely give predictions with some uncertainty, and always tries to push for a 90%+ for one class. The problem is that for my coursework, the penalty used is very harsh for complete miss classification, and uncertainty is much preferred. ( so having a prediction like [0.6, 0.3, 0.2, ...] is much better than having [0.9,0.03,0.02,..].</p>

<p>I'm unsure why this is happening. My dataset consists of 2400 images,
which are from different CCTV, and task is about recognising possible objects. Only 800 of the samples are actually from the data, the other 1600 have been generated through data augmentation. 
Note that it is therefore extremely likely a that some pictures are either identical, or extremely similar (e.g. the same scene, one second later) </p>

<pre><code>model = Sequential()
#1 
# Few filter to take big stuff out
# Also, first layer is not conv so that I can reuse that layer separately
model.add(Dropout(0.1, input_shape=(1,340,340)))
model.add(Convolution2D(64, 4, 4, border_mode='same'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=""th""))   

#2
model.add(Dropout(0.1))
model.add(Convolution2D(128, 4, 4, border_mode='same'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=""th""))   

#3
model.add(Dropout(0.1))
model.add(Convolution2D(256, 4, 4, border_mode='same'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=""th""))   

#4
model.add(Flatten())
model.add(Dense(1024))
model.add(Activation('relu'))
#5
model.add(Dense(512))
model.add(Activation('relu'))
#6
model.add(Dense(6))
model.add(Activation('softmax'))

opt = SGD(lr=0.001)
model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])

print ""Training..""


filepath = ""log/weights-improvement-{epoch:02d}---{val_acc:.2f}.hdf5""
checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint] 
model.fit(X_t, y_t, validation_split=0.1, nb_epoch=500, batch_size=32, callbacks=callbacks_list)
</code></pre>

<p>How do you suggest I fix this? 
Thank you in advance!</p>
",1,17563,,3,29914,29914,2017-03-13T20:27:29.780,2017-03-13T16:30:13.537,1,6,,
6715,1,2015-08-06T20:58:57.380,35,59456,<python><clustering><anomaly-detection>,Is it necessary to standardize your data before clustering?,"<p>Is it necessary to standardize your data before cluster?  In the example from <code>scikit learn</code> about DBSCAN, <a href=""http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html#example-cluster-plot-dbscan-py"">here</a> they do this in the line:</p>

<pre><code>X = StandardScaler().fit_transform(X)
</code></pre>

<p>But I do not understand why it is necessary.  After all, clustering does not assume any particular distribution of data - it is an unsupervised learning method so its objective is to explore the data.  </p>

<p>Why would it be necessary to transform the data?  </p>
",1,6718,,35,10512,,2021-04-17T05:28:30.623,,5,1,,
25184,1,2017-11-28T17:01:09.673,0,248,<python><pandas>,How would you optimize this python/pandas code?,"<pre><code>In [1]: df.head()
Out[1]: 

   uf    city
0  mg    araguari
1  mg    uberlandia
2  sp    sao-paulo
3  go    goiania
4  mg    belo-horizonte

In [2]: len(df)
Out[2]: 

982

In [3]: indicators.head()
Out[3]: 

     city               uf         population
 0   abadia-goias       go         6876
 1   abadia-dourados    mg         6704
 2   araguari           mg         19000
 3   abaete             mg         22690
 4   uberlandia         mg         700000


In [4]: len(indicators)
Out[4]: 

5554
</code></pre>

<p>Now here I'm trying to include 'population' in df, using the corresponding uf and city. But this next code is too slow.</p>

<pre><code>df['population'] = np.nan

for city, uf, index in zip(df.city.values, \
    df.uf.values, df.index):

    df['population'].iloc[index] = \
    indicators.population[indicators.uf == uf] \
    [indicators.city == city].values[0]
</code></pre>
",1,25200,,0,9988,9988,2017-11-30T08:55:14.487,2017-11-30T07:40:54.643,1,4,2017-11-29T16:20:44.633,
61391,1,2019-10-07T17:36:27.730,2,36,<python><neural-network><prediction><ensemble-learning>,Neural Network Multiple | Averging predictions,"<p>I am training multiple neural networks with various parameters. I am trying to average their <strong>predictions</strong>, but I am not really sure what that means, I am confused about <strong><em>what</em></strong> to average exactly. Here is what I mean: For a single observation in binary classification for example, the final node will give <code>p</code> a value between 0 and 1 (or -1 and 1 if you're using hyperbolic tangent Activation Function), then this <code>p</code> will be rounded to 1 or 0 if it's > 0.5, depending on your decision boundary.</p>

<p>Now, here is what I don't understand, should average <code>p1</code>, <code>p2</code> and <code>p3</code> produced by the models before rounding, or I should round the values to <strong>True/False</strong> responses and then compute the average? and how does that work exactly ?</p>
",1,61393,,2,54115,,2019-10-07T17:53:07.850,,1,1,,
61114,1,2019-10-01T20:54:40.737,1,3205,<python><accuracy><confusion-matrix>,Confusion matrix - determine the values of FP FN TP and TN,"<p>After running my code ,I get the values of accuracy, precision and recall and I want t determine the values of FP FN TP and TN from these metrics. I tried to calculate it using the formula of each metric but I couldn't. Is there any way to do this?</p>
",1,61157,,1,52755,43000,2020-11-02T19:06:14.780,2019-10-02T03:12:29.357,4,1,,
18956,1,2017-05-14T14:47:40.710,4,15690,<python><pandas><categorical-data>,Different number of features in train vs test,"<p>I'm doing the titanic exercise on kaggle and there is a categorical Cabin attribute that has a lot of different strings: C41, C11, B20 etc. (about 100).</p>

<p>To be able to train my model I'm converting it to numerical attributes (using pandas get_dummies()). So in the end I get 100+ attributes.</p>

<p>On the test dataset however, there are less cabins, so I'll end up with fewer attributes.</p>

<p>I did something like this to make them equal (create columns that are in the training set and delete those that aren't):</p>

<pre><code>for column in X.columns:
    if column not in X_test.columns:
        X_test[column] = 0

for column in X_test.columns:
    if column not in X.columns:
        X_test.drop([column], axis=1, inplace=True)
</code></pre>

<p>but I know it is not a good thing. So how else should I approach it?</p>

<p>I tried removing the cabin column altogether but my model performs better on test data with that column. </p>
",1,18958,,4,32164,,2022-03-30T21:08:10.933,,6,1,,
58302,1,2019-08-28T06:36:11.287,0,379,<machine-learning><python><scikit-learn><naive-bayes-classifier>,Multinomial Naive bayes giving wrong result,"<pre><code>from sklearn.naive_bayes import GaussianNB,MultinomialNB
xx = [[1],[1],[1],[2],[2],[3]]
yy = [1,1,1,0,0,0]
clf = GaussianNB()
# clf = MultinomialNB()
clf.fit(xx,yy)
clf.predict(xx)
</code></pre>

<p>The expected result is [1,1,1,0,0,0]
but code output is [0,0,0,0,0,0].</p>
",1,58590,,0,80244,,2019-09-04T12:50:26.670,,1,2,,
43229,1,2018-12-28T03:51:03.007,3,653,<machine-learning><python><recommender-system><machine-learning-model>,Create recommendation system to recommend products to a customer on any e-commerce website,"<p>The recommendations should be based on the products consumer has searched on other sites like Google. </p>

<p>This basically means, that recommendations have to be made to the user based on his/her search history. No other information is available for a user.</p>

<p>Has this sort of thing already been implemented? (preferably in Python)</p>

<p>The approach I have thought of is removing stop words and extracting keywords from a search query, based on some criteria. I am falling short at the implementation.</p>
",1,43231,,3,54229,,2018-12-28T05:50:06.197,,1,1,,
38666,1,2018-09-23T06:50:27.273,11,3516,<machine-learning><python><scikit-learn><decision-trees><supervised-learning>,Is max_depth in scikit the equivalent of pruning in decision trees?,"<p>I was analyzing the classifier created using a decision tree. There is a tuning parameter called <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"" rel=""noreferrer"">max_depth</a> in scikit's decision tree. Is this equivalent of pruning a decision tree? If not, how could I prune a decision tree using scikit?</p>

<pre><code>dt_ap = tree.DecisionTreeClassifier(random_state=1, max_depth=13)
boosted_dt = AdaBoostClassifier(dt_ap, random_state=1)
boosted_dt.fit(X_train, Y_train)
</code></pre>
",1,38671,,11,47403,,2020-02-02T07:36:10.413,,2,2,,
42884,1,2018-12-19T15:38:02.633,1,1659,<python><plotting><confusion-matrix>,Confusion matrix plot with python,"<p>I'm for a function that can plot the following plot using python:</p>

<p><a href=""https://i.stack.imgur.com/tEO08.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tEO08.png"" alt=""enter image description here""></a></p>
",1,43627,,1,62052,,2020-05-01T09:56:57.550,,1,1,,
55961,1,2019-07-18T21:48:37.727,0,55,<python><dataset><pandas><dataframe>,How can I arrange data in different columns (for different constituents) from one?,"<p>I have a data file that has all the values for various constituents at different dates in same column. I want different constituents in different columns. Following is the example data format. I want Aluminium, Berrylium and other variables in that column to be in different columns. The data file is attached.</p>

<pre><code>SITE_NAME   SAMP_DATE_TIME      SAMPLE      Value   Units   METHOD_CATEGORY
SITE-7-1    10/04/1988 00:00:00 Aluminum    150     ug/L    INORGANIC
SITE-7-1    10/04/1988 00:00:00 Aluminum    150     ug/L    INORGANIC
SITE-7-1    10/04/1988 00:00:00 Beryllium   5       ug/L    INORGANIC
SITE-7-1    10/04/1988 00:00:00 Beryllium   5       ug/L    INORGANIC
</code></pre>

<p>Data : <a href=""https://drive.google.com/open?id=1SUhYd21U5iQmilABNwoaIXLfsc7Mo6dW"" rel=""nofollow noreferrer"">https://drive.google.com/open?id=1SUhYd21U5iQmilABNwoaIXLfsc7Mo6dW</a> </p>

<p>The output I am trying to get is:</p>

<pre><code>SITE_NAME   SAMP_DATE_TIME  Aluminum    Beryllium   Bromide Bromomethane    Chloride    Hexachlorobenzene   Isosafrole  Zinc
SITE-7-1    10/4/1988 0:00   150        5           10      7250            10          10                  75
SITE-7-1    12/29/1988 0:00  150        5           10      8100            10          10                  16
SITE-7-1    5/10/1989 0:00   150        5           1000    10              8100        10                  10          16
</code></pre>
",1,56347,,0,78015,74421,2019-07-30T02:50:18.690,2019-07-25T02:28:28.413,1,7,,
85488,1,2020-11-16T10:24:29.077,1,48,<python><scikit-learn><random-forest><encoding>,Encoding Tags for Random Forest,"<p>I have the following data set:
<a href=""https://i.stack.imgur.com/qtzRM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qtzRM.png"" alt=""enter image description here"" /></a></p>
<p>I want to use attributes <strong>Tags</strong> and <strong>Authors</strong> to classify each record into their respective <strong>Rating</strong>. In order to do so I want to use a <strong>random forest</strong> classifier. My concern is how to deal with <strong>Tags</strong> attribute. Each of the entry has an undetermined number of tags separated by a commas. There are a total of 4412 unique tags and the entry with more tags contains 20 tags. The first entry has tags [&quot;Rhode Island&quot;,&quot;Economy&quot;, &quot;Taxes&quot;, &quot;Lincoln Chafee&quot;].</p>
<p>How should I encode this attribute such that I can use <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"" rel=""nofollow noreferrer"">Random Forest Classifier</a> from sklearn?</p>
",1,85495,,1,107529,43000,2020-11-17T00:01:55.653,2020-11-17T00:01:55.653,1,1,,
52730,1,2019-05-27T21:24:22.733,0,229,<python><nlp><pandas><nltk>,Extracting email id gives error,"<p>I am extracting email ids and storing them into a new column variable, but I am getting the issue:</p>

<p><a href=""https://i.stack.imgur.com/CrHpP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/CrHpP.png"" alt=""enter image description here""></a></p>

<pre><code>    import re
    def email_extract(comments):
        comments1 =re.findall(r'[\w\.-]+@[\w\.-]+',comments)
       return comments1

   data[""email_id""] = data.COMMENTS.apply(lambda x: email_extract(x))
</code></pre>

<hr>

<blockquote>
<pre><code>--- TypeError                                 Traceback (most recent call
last) &lt;ipython-input-33-d9b73bdc4f8e&gt; in &lt;module&gt;()
----&gt; 1 data[""email_id""] = data.COMMENTS.apply(lambda x: email_extract(x))

C:\ProgramData\Anaconda4\lib\site-packages\pandas\core\series.py in
apply(self, func, convert_dtype, args, **kwds)    3192            
else:    3193                 values = self.astype(object).values
-&gt; 3194                 mapped = lib.map_infer(values, f, convert=convert_dtype)    
3195     3196         if len(mapped) and
isinstance(mapped[0], Series):

pandas/_libs/src\inference.pyx in pandas._libs.lib.map_infer()

&lt;ipython-input-33-d9b73bdc4f8e&gt; in &lt;lambda&gt;(x)
----&gt; 1 data[""email_id""] = data.COMMENTS.apply(lambda x: email_extract(x))

&lt;ipython-input-32-97f3705d1972&gt; in email_extract(comments)
      2 def email_extract(comments):
      3     #re_pattern = re.compile(r'[\w\.-]+@[\w\.-]+')
----&gt; 4     comments1 =re.findall(r'[\w\.-]+@[\w\.-]+',comments)
      5     return comments1

C:\ProgramData\Anaconda4\lib\re.py in findall(pattern, string, flags)
    221 
    222     Empty matches are included in the result.""""""
--&gt; 223     return _compile(pattern, flags).findall(string)
    224 
    225 def finditer(pattern, string, flags=0):

TypeError: expected string or bytes-like object
</code></pre>
</blockquote>

<p>How can I fix this issue?</p>
",1,52731,,0,74068,29575,2019-05-29T06:23:47.070,2019-05-28T04:39:58.203,1,1,,
47885,1,2019-03-24T08:37:24.027,1,77,<python>,Creating new columns based on 3 column and create new data frame,"<h1>Heading</h1>

<p>Consider my data frame 
rs123   T   C   0   0   1   1   0   0   1   0   0   1   0   0
rs124   T   C   0   0   1   0   0   1   0   0   1   0   0   1
rs125   A   A   1   0   0   1   0   0   1   0   0   1   0   0 </p>

<p>Similarity, i have total 93 columns excluding first three</p>

<p>I want to create my data as </p>

<p><a href=""https://i.stack.imgur.com/zi5GD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zi5GD.png"" alt=""enter image description here""></a></p>

<p>And then transform into new data frame as below</p>

<ol>
<li>For first row if 1 is present in column 1 then output should be TT</li>
<li>For first row if 1 is present in column 2 then output should be TC</li>
<li>For first row if 1 is present in column 3 then output should be CC</li>
</ol>

<p>For more detail you can refer below snip</p>

<p><a href=""https://i.stack.imgur.com/asLmp.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/asLmp.png"" alt=""enter image description here""></a></p>

<p>Kindly help me to find solution using python, Its very urgent</p>

<p>Thanks in Advance.</p>
",1,47887,,1,70117,,2019-03-24T09:34:37.500,,1,1,,
28676,1,2018-03-06T01:49:00.123,9,9907,<python><neural-network><keras><software-recommendation>,Are there neural networks packages that use complex numbers?,"<p>Can you build complex (in terms of complex numbers) neural networks in Keras or Tensorflow or something similar?</p>
<p>This would mean the inputs, weights, activation functions, and outputs would all potentially use complex numbers. I know this can be done in theory, but all the software packages I have come across seem to assume only real numbers are used for the weights and inputs.</p>
",1,30084,,9,47309,47309,2022-08-27T18:44:01.550,2022-08-27T18:44:01.550,2,3,,
10773,1,2016-03-18T10:34:45.107,19,83806,<python><scikit-learn>,How does SelectKBest work?,"<p>I am looking at this tutorial: <a href=""https://www.dataquest.io/mission/75/improving-your-submission"" rel=""noreferrer"">https://www.dataquest.io/mission/75/improving-your-submission</a></p>

<p>At section 8, finding the best features, it shows the following code.  </p>

<pre><code>import numpy as np
from sklearn.feature_selection import SelectKBest, f_classif

predictors = [""Pclass"", ""Sex"", ""Age"", ""SibSp"", ""Parch"", ""Fare"", ""Embarked"", ""FamilySize"", ""Title"", ""FamilyId""]

# Perform feature selection
selector = SelectKBest(f_classif, k=5)
selector.fit(titanic[predictors], titanic[""Survived""])

# Get the raw p-values for each feature, and transform from p-values into scores
scores = -np.log10(selector.pvalues_)

# Plot the scores.  See how ""Pclass"", ""Sex"", ""Title"", and ""Fare"" are the best?
plt.bar(range(len(predictors)), scores)
plt.xticks(range(len(predictors)), predictors, rotation='vertical')
plt.show()
</code></pre>

<p>What is k=5 doing, since it is never used (the graph still lists all of the features, whether I use k=1 or k=""all"")?
How does it determine the best features, are they independent of the method one wants to use (whether logistic regression, random forests, or whatever)?</p>
",1,10775,,19,13736,,2021-03-11T20:04:14.150,,2,1,,
74588,1,2020-05-21T12:06:23.110,1,675,<python><training><q-learning>,How to save and load a Q-Learning Agent,"<p>I know this may sound nooby, but how do I save a Deep Q-Learning agent's progress? I mean when I close at i.e. episode 500 when my agent is trained and I restart (in my case a pygame) my agent is going to load its data and it will continue with its progress ( does not start again very stupid :) ). How can it be done?</p>

<p>If you need more details/clarification, feel free to ask! :)</p>

<p>Thanks for any answer! I really do appreciate it!</p>
",1,74699,,1,97597,,2020-05-23T13:52:09.057,,1,2,,
61546,1,2019-10-10T09:06:55.300,1,627,<machine-learning><python><deep-learning><keras><convolutional-neural-network>,MobileNet and MobileNetV2: Bad Inference Results,"<p>unfortunately I am having subjectively bad results in inference with pre-trained models of both MobileNet v1 and v2:</p>

<pre><code>from keras.applications.mobilenet_v2 import MobileNetV2
ConvNet = MobileNetV2(input_shape = None, include_top = True, weights = 'imagenet', input_tensor = None, pooling = None, classes = 1000)
</code></pre>

<p>I have a local copy of these networks for the corresponding image size (224x224), depth multiplier 1.0 and weights trained for ImageNet.</p>

<p>After loading a model of MobileNetV2, I am exectuing a classification on random images from ImageNet or Google Images. Almost always the top-1 classification does not make any sense, for example very often I get the suggestions of a ""Shower Curtain"" or a ""Pillow"", although this is obviously not the case.</p>

<p>Testing with other models (VGG16, ResNet50) and changing only the model type (keeping the same parameters), I obtained correct or at least more understandable results that were also consistent among these two different models:</p>

<pre><code>ConvNet = VGG16(input_shape = None, include_top = True, weights = 'imagenet', input_tensor = None, pooling = None, classes = 1000)
</code></pre>

<p>Having correct results here with the other models, I assume that my script is working correctly.</p>

<p>My question is: Has anybody ever experienced these issues with inference with MobileNet or MobileNetV2? And/or do you have any idea why this error occurs and how to solve it?</p>

<p>I appreciate any answer, please also consider seemingly trivial solutions since I am still quite a newbie ;)</p>

<p>Thanks a lot,
Tim</p>
",1,61818,,1,83520,29169,2021-02-12T21:04:30.837,2021-02-12T21:04:30.837,1,1,,
48273,1,2019-03-30T19:19:46.507,2,110,<machine-learning><python><keras><tensorflow>,problem of entry format for a simple model in Keras,"<p>I apologize if this question is too elementary for this site. I am new in learning Keras and Tensorflow and I have the following type/shape problem on which I have already wasted too much time.</p>

<p>I entered this code (found on the web) to construct a keras model using sequential()</p>

<pre><code>from keras.models import Sequential
from keras.layers import Dense, Activation

model = Sequential()
model.add(Dense(32, activation='relu', input_dim=100))
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])
</code></pre>

<p>I then want to try the function model.evaluate(). But I can't find in the documentation nor in my trials and errors under what format the entry of evaluate should be. Among many other things, I have tried:</p>

<pre><code>import numpy as np
model.evaluate(np.random.random((100,)))
</code></pre>

<p>but I get a long error message ending in</p>

<p><strong>ValueError: Error when checking input: expected dense_1_input to have shape (100,) but got array with shape (1,)</strong></p>

<p>Anyone has an idea what is happening here? Just a simple line of code
creating a dummy entry that my <em>model</em> could <em>evaluate()</em> would unstuck me, I think.</p>
",1,48275,,2,17752,,2019-04-01T10:19:54.547,,1,1,,
40973,1,2018-11-09T17:58:06.707,5,2150,<python><nlp><algorithms><topic-model>,NLP algorithms for categorizing a list of words with specific topics,"<p>Currently I am using LDA to apply topic modeling to a corpus. Since LDA is unsupervised, it returns a set of words for a given 'topic' but doesn't necessarily specify the topic itself. I was wondering if there are any suggestions for algorithms that take a list of words and sees what topics it can be categorized to?</p>

<p>For example <code>[cat, dog, fish]</code> can be categorized to <code>animals</code> or <code>pets</code>.</p>

<p>One output for my model: </p>

<pre><code>['game', 'week', 'fantasy', 'sportsline', 'play', 'players', 'league', 'random', 'sunday', 'season', 'agent', 'elink', 'exercise', 'start', 'yards', 'free', 'injury', 'expected', 'practice', 'getbad', 'weekly', 'year', 'reports', 'starting', 'luck', 'nat', 'nfl', 'weeks', 'smith', 'fast']
</code></pre>

<p>Could be categorized to <code>football</code> or <code>sports</code>.</p>

<p>Any suggestions, specifically with Python models/packages would be much appreciated.</p>
",1,41097,,5,62295,,2022-11-22T08:58:08.843,,1,1,,
22605,1,2017-08-26T11:35:55.153,1,1048,<python><data-mining><scikit-learn>,"Affinity propagation fit, fit_predict and predict methods","<p>I am using sklearn affinity propagation algorithm as below.</p>

<pre><code>affprop = sklearn.cluster.AffinityPropagation(affinity=""precomputed"", damping=0.5)
</code></pre>

<p>I also have a similarity matrix created for the data I am using. Now I want to use my similarity matrix to use in the affinity propagation model.</p>

<p>In <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AffinityPropagation.html"" rel=""nofollow noreferrer"">sklearn</a> they have different methods for this such as fit, fit_predict, predict. So, I'm not sure what to use.</p>

<p>Is it correct if I use,</p>

<pre><code>affprop.fit(my similarity matrix)
</code></pre>
",1,23083,,1,38395,,2017-09-16T20:00:26.117,,1,1,,
16835,1,2017-02-08T10:26:16.887,27,9766,<python><deep-learning><tensorflow><pytorch>,PyTorch vs. Tensorflow Fold,"<p>Both <a href=""https://github.com/hughperkins/pytorch"" rel=""noreferrer"">PyTorch</a> and <a href=""https://github.com/tensorflow/fold"" rel=""noreferrer"">Tensorflow Fold</a> are deep learning frameworks meant to deal with situations where the input data has non-uniform length or dimensions (that is, situations where dynamic graphs are useful or needed).</p>

<p>I would like to know how they compare, in the sense of paradigms they rely on (e.g. dynamic batching) and their implications, things that can/cannot be implemented in each one, weaknesses/strengths, etc.</p>

<p>I intend to use this info to choose one of them to start exploring dynamic computation graphs, but I have no specific task in mind.</p>

<p>Note 1: other dynamic computation graph frameworks like <a href=""https://github.com/clab/dynet"" rel=""noreferrer"">DyNet</a> or <a href=""https://github.com/pfnet/chainer"" rel=""noreferrer"">Chainer</a> are also welcome in the comparison, but I'd like to focus on PyTorch and Tensorflow Fold because I think they are/will be the most used ones.</p>

<p>Note 2: I have found <a href=""https://news.ycombinator.com/item?id=13428098"" rel=""noreferrer"">this hackernews thread on PyTorch</a> with some sparse info, but  not much.</p>

<p>Note 3: Another relevant <a href=""https://news.ycombinator.com/item?id=13591578"" rel=""noreferrer"">hackernews thread</a>, about Tensorflow Fold, that contains some info about how they compare.</p>

<p>Note 4: relevant <a href=""https://www.reddit.com/r/MachineLearning/comments/5sn987/n_announcing_tensorflow_fold_deep_learning_with/"" rel=""noreferrer"">Reddit thread</a>.</p>

<p>Note 5: <a href=""https://github.com/tensorflow/fold/issues/8"" rel=""noreferrer"">relevant bug in Tensorflow Fold's github</a> that identifies an important limitation: impossibility to do conditional branching during evaluation.</p>

<p>Note 6: <a href=""https://discuss.pytorch.org/t/about-the-variable-length-input-in-rnn-scenario/345"" rel=""noreferrer"">discussion on pytorch forum</a> about variable length inputs in relation to the algorithms used (e.g. dynamic batching).</p>
",1,18073,,27,14675,14675,2017-05-03T12:43:48.440,2017-02-23T11:31:56.133,1,2,,
10103,1,2016-02-06T14:19:10.243,27,18900,<python><bigdata><nlp><scikit-learn><dimensionality-reduction>,Improve the speed of t-sne implementation in python for huge data,"<p>I would like to do dimensionality reduction on nearly 1 million vectors each with 200 dimensions(<code>doc2vec</code>). 
I am using <code>TSNE</code> implementation from <code>sklearn.manifold</code> module for it and the major problem is time complexity. Even with <code>method = barnes_hut</code>, the speed of computation is still low. Some time even it runs out of Memory.</p>

<p>I am running it on a 48 core processor with 130G RAM. Is there a method to run it parallely or make use of the plentiful resource to speed up the process. </p>
",1,28772,,27,16024,11097,2020-08-06T13:00:54.440,2016-02-06T14:23:23.533,5,8,,
19586,1,2017-06-09T12:06:36.027,1,11150,<python><scikit-learn><linear-regression><cross-validation>,Linear Regression and k-fold cross validation,"<p>I am totally new to the topic of Data Science. With the help of the following sources, I <em>think</em> I have managed to do a very <strong>simple and basic Linear regression</strong> on a <a href=""https://www.kaggle.com/c/house-prices-advanced-regression-techniques/download/train.csv"" rel=""nofollow noreferrer"">train dataset</a>:</p>

<ul>
<li><a href=""http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html"" rel=""nofollow noreferrer"">SkLearn documentation - Linear regression</a></li>
<li><a href=""https://www.kaggle.com/eliekawerk/regression-to-predict-house-prices"" rel=""nofollow noreferrer"">Some Kernel, that I percieved as intuitive</a></li>
<li><a href=""https://www.kaggle.com/c/house-prices-advanced-regression-techniques/download/test.csv"" rel=""nofollow noreferrer"">the test dataset</a></li>
</ul>

<p>My <strong>Python code</strong> (written as an iPython notebook) that actually does the computation looks like this:</p>

<pre><code>### Stage 0: ""Import some stuff""
%matplotlib inline
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn import datasets, linear_model
from sklearn.linear_model import LinearRegression

### Stage 1: ""Prepare train dataset""
my_train_dataset = pd.read_csv(""../train.csv"")

### remove categorical cols
only_numerical_train_dataset = my_train_dataset.loc[:, my_train_dataset.dtypes!=object]

### remove 'Id' and 'SalePrice' columns
my_train_dataset_X = only_numerical_train_dataset.drop(['Id','SalePrice'], axis = 1)

### insert median into cells with missing values
print(""Before: Number of cells with missing values in train data: "" + str(np.sum(np.sum(my_train_dataset_X.isnull()))))
null_values_per_col = np.sum(my_train_dataset_X.isnull(), axis=0)
cols_to_impute = []
for key in null_values_per_col.keys():
    if null_values_per_col.get(key) != 0: 
        cols_to_impute.append(key)
print(""Before: Need to replace values in the columns in train data: "" + str(cols_to_impute) + ""\n"")
imputation_val_for_na_cols = dict()
for col in cols_to_impute:
    if (my_train_dataset_X[col].dtype == 'float64' ) or  (my_train_dataset_X[col].dtype == 'int64'):
        #numerical col
        imputation_val_for_na_cols[col] = np.nanmedian(my_train_dataset_X[col]) #with median
for key, val in imputation_val_for_na_cols.items():
    my_train_dataset_X[key].fillna(value= val, inplace = True)
print(""After: Number of cells with missing values in train data: "" + str(np.sum(np.sum(my_train_dataset_X.isnull()))))
null_values_per_col = np.sum(my_train_dataset_X.isnull(), axis=0)
cols_to_impute = []
for key in null_values_per_col.keys():
    if null_values_per_col.get(key) != 0: 
        cols_to_impute.append(key)
print(""After: Need to replace values in the columns in train data: "" + str(cols_to_impute) + ""\n"")

### Stage 2: ""Sanity Check - the better the quality, the higher the price?""
plt.scatter(my_train_dataset.OverallQual, my_train_dataset.SalePrice)
plt.xlabel(""Overall Quality of the house"")
plt.ylabel(""Price of the house"")
plt.title(""Relationship between Price and Quality"")
plt.show()

### Stage 3: ""Prepare the test dataset""
my_test_dataset = pd.read_csv(""../test.csv"")

### remove categorical cols
only_numerical_test_dataset = my_test_dataset.loc[:, my_test_dataset.dtypes!=object]

### remove 'Id' column
my_test_dataset_X = only_numerical_test_dataset.drop(['Id'], axis = 1)

### insert median into cells with missing values
print(""Before: Number of cells with missing values in test data: "" + str(np.sum(np.sum(my_test_dataset_X.isnull()))))
null_values_per_col = np.sum(my_test_dataset_X.isnull(), axis=0)
cols_to_impute = []
for key in null_values_per_col.keys():
    if null_values_per_col.get(key) != 0: 
        cols_to_impute.append(key)
print(""Before: Need to replace values in the columns in test data: "" + str(cols_to_impute) + ""\n"")
imputation_val_for_na_cols = dict()
for col in cols_to_impute:
    if (my_test_dataset_X[col].dtype == 'float64' ) or  (my_test_dataset_X[col].dtype == 'int64'):
        #numerical col
        imputation_val_for_na_cols[col] = np.nanmedian(my_test_dataset_X[col]) #with median
for key, val in imputation_val_for_na_cols.items():
    my_test_dataset_X[key].fillna(value= val, inplace = True)
print(""After: Number of cells with missing values in test data: "" + str(np.sum(np.sum(my_test_dataset_X.isnull()))))
null_values_per_col = np.sum(my_test_dataset_X.isnull(), axis=0)
cols_to_impute = []
for key in null_values_per_col.keys():
    if null_values_per_col.get(key) != 0: 
        cols_to_impute.append(key)
print(""After: Need to replace values in the columns in test data: "" + str(cols_to_impute) + ""\n"")

### Stage 4: ""Apply the model""
lm = LinearRegression()
lm.fit(my_train_dataset_X, my_train_dataset.SalePrice)

### Stage 5: ""Sanity Check - the better the quality, the higher the predicted SalesPrice?""
plt.scatter(my_test_dataset.OverallQual, lm.predict(my_test_dataset_X))
plt.xlabel(""Overall Quality of the house in test data"")
plt.ylabel(""Price of the house in test data"")
plt.title(""Relationship between Price and Quality in test data"")
plt.show()

### Stage 6: ""Check the performance of the Prediction""
from sklearn.model_selection import cross_val_score
scores = cross_val_score(lm, my_train_dataset_X,  lm.predict(my_test_dataset_X), cv=10)
print(""scores = "" + str(scores))
</code></pre>

<h2>My questions are:</h2>

<p><strong>1. Why am I getting an error in Stage 6 and how to fix it?</strong></p>

<hr>

<pre><code>ValueError Traceback (most recent call last)
&lt;ipython-input-2-700c31f0d410&gt; in &lt;module&gt;()
     85 ### test the performance of the model
     86 from sklearn.model_selection import cross_val_score
---&gt; 87 scores = cross_val_score(lm, my_train_dataset_X,  lm.predict(my_test_dataset_X), cv=10)
     88 print(""scores = "" + str(scores))
     89 
ValueError: Found input variables with inconsistent numbers of samples: [1460, 1459]
</code></pre>

<p><strong>2. Is there something <em>fundamentally wrong</em> with my approach to a simple and basic Linear Regression?</strong></p>

<hr>

<h2>Edits for comments:</h2>

<p><strong>@CalZ - First comment:</strong></p>

<pre><code>my_test_dataset_X.shape = (1459, 36)
my_train_dataset_X.shape = (1460, 36)
</code></pre>

<p><strong>@CalZ - Second comment:</strong>
I will consider refactoring the code as soon as I am sure that my approach is not fundamentally wrong.</p>

<hr>
",1,19590,,1,33221,33266,2017-06-11T17:21:36.377,2017-06-11T17:21:36.377,1,3,,
20289,1,2017-07-10T06:24:39.933,1,1979,<python><nlp>,Python - Check if text is sentences?,"<p>So I have a scraper that gets articles. However, it doesn't always work properly. I want to get better at checking when it doesn't work. For example, the following is something like I want it to scrape: </p>

<blockquote>
  <p>Hello. This is a sequence of sentences that are put together. They don't have to follow this exact format, but something very close to this would be nice! Just basically stuff like this put together with the occasional weird formatting, which depends on what is scraped. </p>
</blockquote>

<p>But I might also get something that is obviously not text: </p>

<blockquote>
  <p>REGISTER | LOGIN | LOGOUT | Sign in to your account Forgot your password?  {* #signInForm *}.... </p>
</blockquote>

<p>Is there any python library that checks the general format of strings? Basically, I am scraping articles and want to see if the text scraped is article-y. If there isn't a python library, would the best way to go be some sort of regex matching? Is this possible to do reasonably well? </p>

<p>Any help would be greatly appreciated, thanks!! </p>
",1,20312,,1,35399,,2017-07-10T17:14:38.357,,1,2,,
62002,1,2019-10-20T17:51:26.093,2,253,<python><scikit-learn><feature-extraction>,What to do with large number of collinear variables?,"<p>I have this time-series dataset that has 63 features, out of which 57 were manually engineered. While checking for collinearity, I get this correlation matrix:
<a href=""https://i.stack.imgur.com/ziyLX.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ziyLX.png"" alt=""collinear plot"" /></a>
As can be seen there are a number of variables that are correlated/collinear. The ones that are deep red certainly need to be removed, but what about the ones on the bluer range? How do such variables (on the negative range of collinearity) effect regression models?</p>
<p>Also, I ran a recursive feature extraction process from <code>sklearn.feature_extraction</code> module and it has recommended me 39 features to be the best (at default settings). Is RFE the best strategy while dealing with such features?</p>
",1,62004,,2,29430,-1,2020-11-14T00:08:10.793,2020-06-16T11:08:43.077,1,1,,
5485,1,2015-04-09T08:24:04.600,1,112,<machine-learning><data-mining><statistics><python><correlation>,Correlations - Get values in the way we want,"<p>I have :</p>

<ul>
<li><p>a matrix X with N lines</p></li>
<li><p>a vector Y</p></li>
</ul>

<p>I've computed the Euclidean distance with Y for each line of X.</p>

<p>What I get is a vector of distances.</p>

<p>What I want is a vector of scores between 0 and 1, 1 meaning ""very"" high correlation, 0 meaning ""no"" correlation.</p>

<p>Here what I did :</p>

<p>I divided the vector of distances by the max distance inside it.
I get vector D. </p>

<p><em>1 - D</em> is the final result with values between 0 and 1.</p>

<p>The problem is that I get many values (75%) too close to 1.
Do you think what I did is correct ?</p>

<p>How would you get a better result ?
(Between 0 and 1 but not everything too close to 1)</p>

<p>For now, I tried to take the square of the result. (To stay between 0 and 1 but to minimize the values)</p>

<p>Here a picture of the distance values I want to turn in a score
<img src=""https://i.stack.imgur.com/36LDh.png"" alt=""distance values I want to turn in a score""></p>
",1,5507,,1,2586,2586,2015-04-27T07:29:06.110,2015-04-13T09:59:45.020,2,1,,
20168,1,2017-07-04T14:09:23.730,0,4337,<machine-learning><python><data-mining>,Issues with NLTK lemmatizer (WordNet),"<p>I want to lemmatize set of plural keywords automatically such as 'Web based technologies', 'Information systems' etc. I want to transform them to to 'Web based technology', 'Information system' respectively.</p>

<p>I tried NLTK as follows</p>

<pre><code>from nltk.stem import WordNetLemmatizer

lemmatizer = WordNetLemmatizer()

print(lemmatizer.lemmatize(""Web based technologies""))
</code></pre>

<p>Even though this perform fine for words such as 'cats' to 'cat', for the keywords I have mentioned I get the same plural form. Any idea how to solve this? Or are there any other tools/APIs that I can make use of?</p>

<p>P.S. Given the keywords I only want to get the singular term of it</p>
",1,20171,,0,33838,,2017-07-04T15:56:00.770,,1,1,2017-07-09T19:15:19.687,
22957,1,2017-09-11T18:03:47.500,8,45557,<python><statistics><pandas>,Am I doing a log transformation of data correctly?,"<p>I'm doing some exploratory data analysis on some data and I get these histograms:</p>

<p><a href=""https://i.stack.imgur.com/KnXhq.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/KnXhq.png"" alt=""enter image description here""></a></p>

<p>That looks like a candidate for a log transformation on the data, so I run the following Python code to transform the data:</p>

<pre><code>df[""abv""].apply(np.log).hist()
df[""ibu""].apply(np.log).hist()
plt.show()
</code></pre>

<p>And I get this new plot of the transformed histograms:</p>

<p><a href=""https://i.stack.imgur.com/UjbHZ.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/UjbHZ.png"" alt=""enter image description here""></a></p>

<p>Am I correct that a log transform was ok to do in this case, and if so, what's the best way to interpret the results?</p>
",1,22978,,8,33510,,2017-09-12T17:12:31.240,,1,1,,
61576,1,2019-10-10T19:21:02.047,1,292,<python><neural-network><ensemble-modeling><activation-function>,Combining multiple neural networks with different activation functions,"<p>I have 3 neural networks where each has as a different activation function: Sigmoid, Tanh and Softmax. I am planning to average their final predictions, but as we know the functions doesn't have the same range values. </p>

<pre><code>P = (P1 + P2 + P3)/3 
</code></pre>

<p>Where <code>0 &lt; P1 &lt; 1, -1 &lt; P2 &lt; 1, 0 &lt; P3 &lt; 1</code></p>

<p>Can I directly average the predictions or I need to perform a normalization to have all prediction fall into the same interval ?</p>
",1,61593,,1,54115,,2019-10-11T10:14:50.373,,1,4,,
14355,1,2016-10-04T13:54:26.537,0,921,<python><scikit-learn><k-means>,Quick start using python and sklearn kmeans?,"<p>I started tinkering with sklearn kmeans last night out of curiosity with the goal of clustering users into groups to see what kind of user groups I can derive.  I am lost when it comes to plotting the results as most examples have nice (x,y) coordinates.  For example, the iris data set has pedal width and pedal length.  From my experimentation, I don't seem to have anything that displays very nice.  Is this assumption correct / does anyone have tips, pointers, learning resources that they could offer?</p>

<pre><code>import pandas as pd
import pprint
import numpy as np
from sklearn.preprocessing import normalize
from sklearn.preprocessing import LabelEncoder
from sklearn.cluster import KMeans
from collections import defaultdict
import matplotlib.pyplot as plt
from matplotlib import style
style.use('ggplot')
</code></pre>

<p>I normalized the data as it had a wide variance...again, not sure if this is a correct assumption to make</p>

<pre><code>X = np.array(normalize(data, axis=0, copy=False))

kmeans = KMeans(n_clusters=3)
pred = kmeans.fit_predict(X)
labels = kmeans.labels_
cent = kmeans.cluster_centers_

plt.scatter(X[:, [4]], X[:, [6]])
plt.scatter(cent[:, [4]], cent[:, [6]], marker=""x"", s=150, linewidths=5, zorder=10)
plt.ylabel('Count')
plt.xlabel('Department')
plt.show()
</code></pre>

<p>Any pointers are appreciated, I will include sample data below.  Thanks!</p>

<p>Sample Data:</p>

<pre><code>emp_type,title,work_country,director_userid,dept_name,business_unit_name,UserCNT
0,9,7,29,20,2,2
0,13,7,8,14,6,5
0,4,3,56,29,8,3
0,15,3,36,32,2,3
0,4,3,32,16,2,0
0,4,1,40,13,6,0
0,4,3,62,12,4,1
0,13,7,61,5,13,4
2,1,3,70,35,15,2
0,4,3,64,4,13,0
2,1,3,43,43,2,0
0,13,7,50,17,16,0
2,1,3,31,26,2,1
2,1,3,65,58,17,0
0,4,3,57,63,12,0
2,1,6,7,45,18,2
2,1,3,43,42,2,0
1,1,7,65,58,17,0
2,1,3,32,16,2,0
2,1,3,29,20,2,0
0,4,0,50,17,16,2
0,5,3,20,23,9,0
0,9,3,32,16,2,2
0,4,3,5,51,12,0
2,1,7,51,53,7,0
0,13,7,37,55,12,0
2,1,4,19,62,13,0
</code></pre>

<p>Example clustering using entire data set:</p>

<p><a href=""https://i.stack.imgur.com/yPe9e.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yPe9e.png"" alt=""enter image description here""></a></p>
",1,14366,,0,24930,24930,2016-10-05T16:51:29.967,2016-10-04T17:53:47.880,1,3,,
19476,1,2017-06-05T10:30:41.437,3,360,<machine-learning><python><pandas><feature-extraction>,Extracting sub features from inside a df cell?,"<p>I have a dataframe containing several features of form:</p>

<pre><code>Id, Acol,                   Bcol,   Ccol,           Dcol,
1,  X:0232,Y:10332,Z:23891, E:1222, F:12912,G:1292, V:1281
2,  X:432,W:2932            R:2392, T:292,U:29203   Q:2392
3,  Y:29320,W:2392          R:2932, G:239,T:2392    Q:2391

...about 10,000 Id's
</code></pre>

<ul>
<li>where 1,2,3 are the Id's.</li>
<li>Acol, Bcol, Ccol, and Dcol are the feature columns,</li>
<li>X, Y, Z, W are sub-features of feature ""Acol"" and so on...</li>
</ul>

<p>How can I extract the sub-features/features from this sort of dataframe?</p>
",1,19491,,3,33020,29575,2017-06-05T22:18:04.500,2017-06-05T22:18:04.500,1,1,,
89285,1,2021-02-12T13:06:04.067,1,28,<python><pandas>,How to Iterate over rows in a dataframe,"<p>So I've been trying to iterate over rows of my dataframe and my goal is to find matching rows based on two particular columns (say C and P). Then i need to do some manipulations as well in the data for the rows. I've read quite a few answers here telling to use <strong>iterrows()</strong> or <strong>itertuples()</strong> but that doesnt serve my purpose because I cannot manipulate my data using them. Same goes for functions like groupby since it only allows manipulation on the whole groups not elements of those groups(correct me if I am wrong here because thats what I have seen in the articles on <strong>groupby()</strong>. What approach should I use to match rows in my data frame to each other based on columns and then manipulate them.</p>
",1,89291,,1,107760,,2021-02-12T15:10:22.950,,1,1,2021-02-13T16:32:30.957,
106626,1,2022-01-02T12:48:33.833,0,256,<machine-learning><python><classification><cross-validation><pipelines>,Custom vectorizer transformer in sklearn with cross validation,"<p>I created a custom transformer class called <code>Vectorizer()</code> that inherits from <code>sklearn</code>'s <code>BaseEstimator</code> and <code>TransformerMixin</code> classes. The purpose of this class is to provide vectorizer-specific hyperparameters (e.g.: <code>ngram_range</code>, vectorizer type: <code>CountVectorizer</code> or <code>TfidfVectorizer</code>) for the <code>GridSearchCV</code> or <code>RandomizedSearchCV</code>, to avoid having to manually rewrite the pipeline every time we believe a vectorizer of a different type or settings could work better.</p>
<p>The custom transformer class looks like this:</p>
<pre><code>class Vectorizer(BaseEstimator, TransformerMixin):
    def __init__(self, vectorizer:Callable=CountVectorizer(), ngram_range:tuple=(1,1)) -&gt; None:
        super().__init__()
        self.vectorizer = vectorizer
        self.ngram_range = ngram_range
    def fit(self, X, y=None):
        print(f&quot;&gt;&gt;&gt; Vectorizer.fit() called with vectorizer={self.vectorizer} and ngram_range={self.ngram_range}.&quot;)
        return self 
    def transform(self, X, y=None):
        print(f&quot;&gt;&gt;&gt; Vectorizer.transform() called with vectorizer={self.vectorizer} and ngram_range={self.ngram_range}.&quot;)
        X_ = X.copy()
        X_vect_ = self.vectorizer.fit_transform(X_)  # problem is in this line! 
        X_vect_ = X_vect_.toarray()
        # print(X_vect_.shape)
        # print(self.vectorizer.vocabulary_)
        # time.sleep(5)
        return X_vect_
</code></pre>
<p>(Side note: <code>time.sleep(5)</code> was merely added to make debugging easier by preventing debug info overflowing on one another.)</p>
<p>I intend to use the custom vectorizer in the following way, with a pipeline and a hyperparameter tuning step:</p>
<pre><code>pipe = Pipeline([
    ('column_transformer', ColumnTransformer([
        ('ltype_encode', OneHotEncoder(handle_unknown='ignore'), ['Type']),
        ('text_vectorizer', Vectorizer(), 'Text')],
        remainder='drop')
    ),
    ('model', LogisticRegression())
])

param_dict = {
    'column_transformer__text_vectorizer__vectorizer': [CountVectorizer(), TfidfVectorizer()]
}

randsearch = GridSearchCV(pipe, param_dict, cv=2, scoring='f1').fit(X_train, y_train)
</code></pre>
<p>Now as I was debugging, I have a guess of the problem in my code: the above <code>GridSearchCV</code> uses a 2-fold cross validation. First, it takes half of the data to train the model and reserves the other half for evaluation. However, the <code>Vectorizer()</code> class's <code>transform()</code> method will try to call <code>fit_transform()</code> on the evaluation dataset again, even though when testing/evaluating, we would want to use the previously fit vectorizer without a refit.</p>
<p>Question is: how could I rectify this problem?</p>
<p>Imports:</p>
<pre><code>import time
import pandas as pd 
from typing import Callable
import sklearn
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.model_selection import GridSearchCV
</code></pre>
<p>and sample data in semicolon-separated format:</p>
<pre><code>Src;Text;Type;Target
A99;hi i love python very much;c;1
B07;which programming language should i learn;b;0
A12;what is the difference between python django flask;b;1
A21;i want to be a programmer one day;c;0
B11;should i learn java or python;b;1
C01;how much can i earn as a programmer with python;a;0
c01;hello &lt;FLAG&gt; &lt;FLAG&gt; I m from france i enjoyed this lecture thank u very much HEAVY BLACK HEART HEAVY BLACK HEART HEAVY BLACK HEART HEAVY BLACK HEART;b;1
ssa;hi hola salut &lt;FOREIGN&gt; &lt;FOREIGN&gt; &lt;FOREIGN&gt; &lt;FOREIGN&gt; SMILING FACE WITH HALO HEAVY BLACK HEART CLINKING GLASSES &lt;FLAG&gt; &lt;FLAG&gt;;a;1
</code></pre>
",1,106638,,0,111822,111822,2022-01-02T19:33:38.910,2022-01-02T13:04:00.530,1,5,,
38226,1,2018-09-13T21:58:06.317,4,196,<python><r>,Which is better for a beginner: R or Python?,"<p>From what I can tell, R and Python are the two most popular languages for data science.</p>

<p>My question is which one would you recommend for someone just starting out in data science? Does any one have any clear advantages on the other? Is any one easier to learn or does any one have more potential?</p>

<p>Thanks a lot!</p>
",1,38229,,4,59073,,2018-09-14T06:44:55.953,,2,1,2018-09-14T07:08:34.730,
80462,1,2020-08-18T17:24:37.053,0,2949,<python><mathematics>,Python - accessing dictionary values for math operations,"<p>I have this dictionary:</p>
<pre><code>stocks = {'FB': 255, 'AAPL': 431, 'TSLA': 1700}
</code></pre>
<p>and this script:</p>
<pre><code>shares = input('How many shares? ')
stock = input('What\'s the stock? ')

for name in stocks.keys():
    ticker = (stocks[name])
    if name == stock:
        print('The price for', stock, 'is', ticker)
    
amount = int(ticker) * int(shares)
print(amount)
</code></pre>
<p>I wanted to access the value of the key when it is selected in the &quot;stock&quot; input and multiply the ticker chosen in the input, but it always multiplies 'TSLA' value 1700 by the number of shares selected, even if I choose FB as stock input.</p>
<p>The right output should be:</p>
<p>How many shares? 10</p>
<p>What's the stock? FB</p>
<p>2550</p>
<p>Instead I get 17000</p>
<p>I'd like to understand why.. thank you!</p>
",1,80463,,0,100262,103697,2020-08-22T16:01:19.783,2020-08-22T16:01:19.783,2,2,2020-08-28T10:42:58.720,
10960,1,2016-03-30T14:24:51.723,1,79,<r><python><visualization>,"Need some tips regarding starting out with the field's specific programming languages, with a heavy focus on data visualization","<p>I've got rather expansive development experience, but I'm new to data science. I have been trying to familiarize myself with the main concepts and deciding between R and Python to put my time into. </p>

<p>I know you can write Python in R and vice versa, but since data visualization in a beautiful manner would be a very high priority for me in the future and both Python and R use additional packages and libraries for data representation, I'm not entirely sure whether it's possible to use the additional libraries when integrating code into one another.</p>

<p>I would really appreciate it if someone could give me some advice regarding this and also provide me with some general tips about the best approaches, practices and tools when it comes to data visualization.</p>
",1,11162,,1,17450,,2016-04-12T12:24:35.793,,1,2,,
37413,1,2018-08-25T07:21:20.623,6,10506,<python><deep-learning><keras>,Why running the same code on the same data gives a different result every time?,"<p>I am using Keras in Jupyter Notebook.</p>

<p>I understood that for the same results, the random numbers should be produced from the same seed each time.</p>

<p>So, in the first of all my codes, I set <code>random.seed</code> as 1234 in a cell.</p>

<pre><code>np.random.seed(1234)
</code></pre>

<p>Then other cells are the code for my model and the fit and evaluate code. But each time that I run the model cells, the loss values are different!</p>

<p>Why does it happen? How can I solve it?</p>
",1,37418,,6,57545,29575,2018-08-25T15:51:42.817,2018-08-25T15:51:42.817,3,2,,
81914,1,2020-09-18T16:08:44.437,0,989,<machine-learning><python><scikit-learn><svm>,Why is the accuracy of a LinearSVC not the same as the SDGClassifier?,"<p>I'm fine tuning parameters for a linear support vector machine. There are multiple ways to do it, but I wanted to compare LinearSVC and SDGClassifier in terms of time. I expected the accuracy score to be the same but, even after fine tuning with GridSearchCV, the score of the LinearSVC is lower. I tried changing up parameters many times, but the maximum with LinearSVC I can get is 41.176 versus 41.503 of SDGClassifier. Why?</p>
<p>The code:</p>
<pre><code>    class SVMSentiment(Base):
&quot;&quot;&quot;Predict sentiment scores using a linear Support Vector Machine (SVM).
Uses a sklearn pipeline.
&quot;&quot;&quot;
def __init__(self, model_file: str=None) -&gt; None:
    super().__init__()
    # pip install sklearn
    from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer
    from sklearn.linear_model import SGDClassifier
    from sklearn.svm import SVC, LinearSVC
    from sklearn.pipeline import Pipeline


    self.pipeline = Pipeline(
        [
            ('vect', CountVectorizer()),
            ('tfidf', TfidfTransformer()),
            #('tfidf', TfidfVectorizer()),
            ('clf', LinearSVC( loss='hinge',
              penalty='l2', max_iter = 10,



             #SGDClassifier(
                #loss='hinge',
               # penalty='l2',
              #alpha=1e-3,
              #  random_state=42,
             #max_iter=100,
                #learning_rate = 'optimal',
                #tol=None



            )),
        ]
    )

def predict(self, train_file: str, test_file: str, lower_case: bool) -&gt; pd.DataFrame:
    &quot;Train model using sklearn pipeline&quot;
    from sklearn.model_selection import GridSearchCV
    from sklearn.svm import SVC
    from sklearn.linear_model import SGDClassifier
    from sklearn import svm
    from sklearn import preprocessing
    from sklearn.preprocessing import LabelEncoder, OneHotEncoder
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.svm import LinearSVC
    train_df = self.read_data(train_file, lower_case)
    param_range = [0.001, 0.01, 0.1, 1, 10, 100]
    parameters = {
        # 'vect__ngram_range': [(1, 1), (1, 2)],
        'tfidf__use_idf': (True, False),
        #'clf__alpha': [0.0001, 0.001, 0.01, 1, 10, 100],
        'clf__max_iter': [10, 100, 1000],
        'clf__tol': [0, 0.0001, 0.001, 0.01],
        'clf__loss':['hinge'],
        'clf__penalty': ['l2'],
        'clf__C': param_range

    }


    parameters1 = {'clf__C': param_range, 'clf__gamma': param_range, 'clf__kernel': ['linear'], 'clf__tol' : [0, 0.01]

                  }
    lr = LinearSVC()
    print(lr.get_params().keys())
    gs_clf = GridSearchCV(self.pipeline, parameters, cv=5, n_jobs=-1)
    gs_clf = gs_clf.fit(train_df['text'], train_df['truth'])
    print(gs_clf.best_score_)
    for param_name in sorted(parameters.keys()):
        print(&quot;%s: %r&quot; % (param_name, gs_clf.best_params_[param_name]))

    # estimator_svm.best_score

    learner = self.pipeline.fit(train_df['text'], train_df['truth'])
    # Fit the learner to the test data
    test_df = self.read_data(test_file, lower_case)

    test_df['pred'] = learner.predict(test_df['text'])
    return test_df
</code></pre>
",1,82196,,0,104104,104104,2020-09-25T01:45:51.720,2020-09-21T20:32:31.630,3,2,,
62794,1,2019-11-06T21:11:46.150,1,148,<python><predictive-modeling><feature-engineering><data-science-model><encoding>,Does the predict function in machine learning understand categorical data,"<p>I understand that before feature engineering one has to split the dataset into train and test data, so as to avoid bias in the analysis. I also understand that the machine learning model does not understand data apart from numerical data, thus encoding is required, which is a part of feature engineering. My question is, do I encode the test data separately or does the prediction function understand categorical data.</p>
",1,62812,,1,67275,71442,2019-11-07T09:14:31.620,2019-11-07T08:13:18.973,2,2,,
65585,1,2019-12-29T14:14:39.837,9,1586,<python><scikit-learn><decision-trees>,Decision tree with final decision being a linear regression,"<p>Question:
I want to implement a decision tree with each leaf being a linear regression, does such a model exist (preferable in sklearn)?</p>

<p><strong>Example case 1:</strong></p>

<p>Mockup data is generated using the formula:</p>

<pre><code>y = int(x) + x * 1.5
</code></pre>

<p>Which looks like:</p>

<p><a href=""https://i.stack.imgur.com/e9Nh2.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/e9Nh2.png"" alt=""enter image description here""></a></p>

<p>I want to solve this using a decision tree where the final decision results in a linear formula. Something like:</p>

<ol>
<li>0 &lt;= x &lt; 1 -> y = 0 + 1.5 * x</li>
<li>1 &lt;= x &lt; 2 -> y = 1 + 1.5 * x</li>
<li>2 &lt;= x &lt; 3 -> y = 2 + 1.5 * x</li>
<li>etc. </li>
</ol>

<p>Which I figured could best be done using a decision tree. I've done some googling and I thought the <code>DecisionTreeRegressor</code> from <code>sklearn.tree</code> could work, but that results in points being assigned a constant value in a range, as shown below:
<a href=""https://i.stack.imgur.com/tUVym.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/tUVym.png"" alt=""enter image description here""></a></p>

<p>Code:</p>

<pre><code>import matplotlib.pyplot as plt
import numpy as np
from sklearn.tree import DecisionTreeRegressor

x = np.linspace(0, 5, 100)
y = np.array([int(i) for i in x]) + x * 1.5

x_train = np.linspace(0, 5, 10)
y_train = np.array([int(i) for i in x_train]) + x_train * 1.5

clf = DecisionTreeRegressor()
clf.fit(x_train.reshape((len(x_train), 1)), y_train.reshape((len(x_train), 1)))

y_result = clf.predict(x.reshape(len(x), 1))
plt.plot(x, y, label='actual results')
plt.plot(x, y_result, label='model predicts')
plt.legend()
plt.show()
</code></pre>

<p><strong>Example case 2:</strong>
Instead of one input, there are two inputs: x1 and x2, output is computed by:</p>

<ol>
<li>x1 = 0 -> y = 1 * x2</li>
<li>x1 = 1 -> y = 3 * x2 + 5</li>
<li>x1 = 6 -> y = -1 * x2 -4</li>
<li>else -> y = x2 * 20 - 100</li>
</ol>

<p><a href=""https://i.stack.imgur.com/qdjnI.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/qdjnI.png"" alt=""enter image description here""></a></p>

<p>Code:</p>

<pre><code>import matplotlib.pyplot as plt
import random

def get_y(x1, x2):
    if x1 == 0:
        return x2
    if x1 == 1:
        return 3 * x2 + 5
    if x1 == 6:
        return - x2 - 4
    return x2 * 20 - 100

X_0 = [(0, random.random()) for _ in range(100)]
x2_0 = [i[1] for i in X_0]
y_0 = [get_y(i[0], i[1]) for i in X_0]
X_1 = [(1, random.random()) for _ in range(100)]
x2_1 = [i[1] for i in X_1]
y_1 = [get_y(i[0], i[1]) for i in X_1]
X_2 = [(6, random.random()) for _ in range(100)]
x2_2 = [i[1] for i in X_2]
y_2 = [get_y(i[0], i[1]) for i in X_2]
X_3 = [(random.randint(10, 100), random.random()) for _ in range(100)]
x2_3 = [i[1] for i in X_3]
y_3 = [get_y(i[0], i[1]) for i in X_3]
plt.scatter(x2_0, y_0, label='x1 = 0')
plt.scatter(x2_1, y_1, label='x1 = 1')
plt.scatter(x2_2, y_2, label='x1 = 6')
plt.scatter(x2_3, y_3, label='x1 not 0, 1 or 6')
plt.grid()
plt.xlabel('x2')
plt.ylabel('y')
plt.legend()
plt.show()
</code></pre>

<p>So my question is: does a decision tree with each leaf being a linear regression, exist?</p>
",1,94656,,9,87545,87545,2021-05-19T16:51:37.720,2019-12-30T10:33:44.273,5,6,,
33277,1,2018-06-17T15:49:32.363,4,714,<python><statistics>,Does central limit theorem work well for Pareto distribution?,"<p>I am new to Data Science. Recently I was studying a course about statistics. One of the tasks there was to check the central limit theorem in practice.</p>

<p>The idea was quite simple: take a continuous random variable; generate, say, 1000 samples from it, each of size <code>n</code>; draw a histogram of the samples. Then find the parameters of the normal distribution using the central limit theorem and draw the PDF of the distribution. As a result, the histogram and the PDF should be, roughly speaking, ""similar"" (and become more ""similar"" as <code>n</code> grows).</p>

<p>I chose <em>Pareto distribution</em> and, with this Python code,</p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as sts
from math import sqrt

n = 10

b = 3.0
random_value = sts.pareto(b)
mean = random_value.mean()
variance = random_value.var()

plt.hist(samples(random_value, n, 1000), bins=20, normed=True)

x = np.linspace(0, 6, 100)
pdf = sts.norm(mean, sqrt(variance / n)).pdf(x)
plt.plot(x, pdf, color='r', label='theoretical PDF')
</code></pre>

<p>where the <code>samples</code> function was like this</p>

<pre><code>def samples(random_value, sample_size, number_of_samples):
    result = np.asarray([])
    for i in range(number_of_samples):
        result = np.append(result, np.mean(random_value.rvs(sample_size)))
    return result
</code></pre>

<p>I got the next histogram and PDF as a result
<a href=""https://i.stack.imgur.com/MumXj.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MumXj.png"" alt=""Pareto distribution""></a></p>

<p>The result looked suspicious to me: there was no expected similarity. I checked the same code with another continuous distribution (with a uniform distribution), and the graphs looked much more similar.</p>

<p>Is it a feature of the Pareto distribution which makes it a bad choice to demonstrate how the central limit theorem works? Or something is wrong with the code itself (e.g., the parameters of the normal distribution are calculated in a wrong way)? Thank you in advance.</p>
",1,33280,,4,53789,53789,2018-06-19T11:34:10.843,2018-06-19T11:34:10.843,1,3,,
11655,1,2016-05-09T13:22:02.683,2,1774,<python><random-forest><pandas><class-imbalance><ensemble-modeling>,EasyEnsemble explaination,"<p>Could someone please explain how the EasyEnsemble algorithm works? Im using it for a prediction model for imbalanced minority class.</p>
<p>Please don't refer me to this paper, as it makes no sense to me.
<a href=""https://www.google.co.in/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=4&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwj47L32ic3MAhUEjo4KHaYIA3cQFggxMAM&amp;url=http%3A%2F%2Fcse.seu.edu.cn%2Fpeople%2Fxyliu%2Fpublication%2Ftsmcb09.pdf&amp;usg=AFQjCNEgDOnCfYdg7RFurxN-o5vc1HQMMA&amp;sig2=BuJH2l9w1M7d7hPVClxEMA&amp;bvm=bv.121421273,d.c2E"" rel=""nofollow noreferrer"">EasyEnsemble and Feature Selection for Imbalance Data Sets</a></p>
<p>Im using the algorithm in Pandas, with the UnbalancedDataset library which is on GitHub  <a href=""https://github.com/glemaitre/UnbalancedDataset"" rel=""nofollow noreferrer"">UnbalancedDataset</a></p>
<p>I get an array of matrices as O/P, I don't know how to use this in the end, to train with random forests.</p>
<p>Thanks</p>
",1,12411,,2,18098,-1,2016-06-26T00:11:54.507,2020-06-16T11:08:43.077,1,2,,
42730,1,2018-12-16T22:06:28.993,10,7099,<python><neural-network><keras><categorical-data><embeddings>,Confusion about Entity Embeddings of Categorical Variables - Working Example!,"<p><strong>Problem Statement:</strong> I have problem making the <strong>Entity Embedding of Categorical Variable</strong> works for a simple dataset. I have followed the original <a href=""https://github.com/entron/entity-embedding-rossmann"" rel=""noreferrer"">github</a>, or <a href=""https://arxiv.org/pdf/1604.06737.pdf"" rel=""noreferrer"">paper</a>, or other blogposts[<a href=""https://medium.com/@satnalikamayank12/on-learning-embeddings-for-categorical-data-using-keras-165ff2773fc9"" rel=""noreferrer"">1</a>,<a href=""https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526"" rel=""noreferrer"">2</a>,or this <a href=""https://towardsdatascience.com/decoded-entity-embeddings-of-categorical-variables-in-neural-networks-1d2468311635"" rel=""noreferrer"">3]</a>, or this Kaggle <a href=""https://www.kaggle.com/aquatic/entity-embedding-neural-net"" rel=""noreferrer"">kernel</a>; still not working.</p>

<p><strong>Data Part:</strong> I am using the <strong><a href=""https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data"" rel=""noreferrer"">Ames Housing</a></strong> dataset as was hosted in Kaggle. I'm loading it in pandas dataframe as:</p>

<pre><code>url = 'http://www.amstat.org/publications/jse/v19n3/decock/AmesHousing.xls'
# Load the file into a Pandas DataFrame
data_df = pd.read_excel(url)
</code></pre>

<p>For simplicity, out of 81 independent features, I am ONLY taking the <em>Neighborhood</em>, which is categorical, and the <em>Gr Liv Area</em>, which is numerical. And <em>SalePrice</em>, which is our target. I also split the data into train, and test and normalize the numerical variables.</p>

<pre><code>features = ['Neighborhood','Gr Liv Area']
target = ['SalePrice']
data_df=data_df[features + target]

X_train, y_train = data_df.iloc[:2000][features], data_df.iloc[:2000][target]
X_test = data_df.iloc[2000:][features]

X_train['Gr Liv Area']=StandardScaler().fit_transform(X_train['Gr Liv Area'].reshape(-1, 1)) 
y_train=StandardScaler().fit_transform(y_train) 
</code></pre>

<p><strong>Embedding Neural Net:</strong>
Here is the block of code where I am building the Entity Embedding Neural Net including both the categorical and numerical variables. In Entity Embedding, there is a particular hyperparamter that defines the embedding size (as we have in NLP). Here I am using of the <a href=""https://medium.com/@satnalikamayank12/on-learning-embeddings-for-categorical-data-using-keras-165ff2773fc9"" rel=""noreferrer"">above-mentioned blogpost</a> strategy to choose that.</p>

<pre><code>input_models=[]
output_embeddings=[]
numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']

for categorical_var in X_train.select_dtypes(include=['object']):

  #Name of the categorical variable that will be used in the Keras Embedding layer
  cat_emb_name= categorical_var.replace("" "", """")+'_Embedding'

  # Define the embedding_size
  no_of_unique_cat  = X_train[categorical_var].nunique()
  embedding_size = int(min(np.ceil((no_of_unique_cat)/2), 50 ))
  vocab  = no_of_unique_cat+1

  #One Embedding Layer for each categorical variable
  input_model = Input(shape=(1,))
  output_model = Embedding(vocab, embedding_size, name=cat_emb_name)(input_model)
  output_model = Reshape(target_shape=(embedding_size,))(output_model)    

  #Appending all the categorical inputs
  input_models.append(input_model)

  #Appending all the embeddings
  output_embeddings.append(output_model)

#Other non-categorical data columns (numerical). 
#I define single another network for the other columns and add them to our models list.
input_numeric = Input(shape=(len(X_train.select_dtypes(include=numerics).columns.tolist()),))
embedding_numeric = Dense(64)(input_numeric) 
input_models.append(input_numeric)
output_embeddings.append(embedding_numeric)

#At the end we concatenate altogther and add other Dense layers
output = Concatenate()(output_embeddings)
output = Dense(500, kernel_initializer=""uniform"")(output)
output = Activation('relu')(output)
output = Dense(256, kernel_initializer=""uniform"")(output)
output = Activation('relu')(output)
output = Dense(1, activation='sigmoid')(output)

model = Model(inputs=input_models, outputs=output)
model.compile(loss='mean_squared_error', optimizer='Adam',metrics=['mse','mape'])
</code></pre>

<p>At the end, the model looks like this:
<a href=""https://i.stack.imgur.com/q9S0S.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/q9S0S.png"" alt=""enter image description here""></a></p>

<p>This look OK to me, unless I'm missing sth. Anyway, when I'm training the model like below:</p>

<pre><code>history  =  model.fit(X_train,y_train  , epochs =  200 , batch_size = 16, verbose= 2)
</code></pre>

<p>I get a rather usual keras error: </p>

<pre><code>ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), but instead got the following list of 1 arrays: [array([['NAmes', 0.31507361227175135],
       ['NAmes', -1.2242024755540366],
       ['NAmes', -0.3472201781480285],
       ...,
</code></pre>

<p>Then I looked more carefully at the original github or that Kaggle kernel, I noticed one has to <em>convert</em> the data to list format to match the network structure (<strong>still I am not sure I fully understand WHY!</strong>, see the <strong><em>preproc function</em></strong> there). Anyway, I convert my data to the list format like: </p>

<pre><code>X_train_list = []

for i,column in enumerate(X_train.columns.tolist()):
  X_train_list.append(X_train.values[..., [i]])
</code></pre>

<p>Now when trying to train once again this time using the list format of the data i.e. <em>X_train_list</em>:</p>

<pre><code>history  =  model.fit(X_train_list,y_train  , epochs =  200 , batch_size = 16, verbose= 2)
</code></pre>

<p>This time it starts with the first Epoch, then immediately stops with the following error: </p>

<pre><code>ValueError: could not convert string to float: 'Mitchel'
</code></pre>

<p>It is rather obvious that it complains about one of the categories of the only <em>Neighborhood</em> variable that I have not encoded! Sure I have not, I thought that was the whole purpose of the <strong>Entity Embedding</strong> that the networks initiates a random embedding weights and learn the best embedding of that categorical variable during optimization of the target. Super confused!! Any help is much appreciated.</p>
",1,44639,,10,44456,,2019-01-27T12:00:26.673,,1,5,,
78551,1,2020-07-30T16:03:22.943,0,108,<python><statistics><data-science-model><data-analysis>,How to use historic data (granularity at day level) for ML modeling?,"<p>There is a scenario where I have to use historic data which is at the day level for the past 5 years.<br>Actually it is water flow data, what quantity of water was flown on that particular day. I have to use this feature along with a few other features like material, coating, etc,. for EDA and prediction. I tried averaging it out but not useful.<br></p>
<p>Data is like this flow1,flow2, and flow3 (including other features not shown here) for each day on that particular route id. This continues for 5 years for many routes.<br>
<a href=""https://i.stack.imgur.com/UqsLR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UqsLR.png"" alt=""enter image description here"" /></a>
<br> I am not able to figure out how to consolidate this data so that I can feed it to the model.
I am trying to predict the corrosion in the pipeline.
<br><br> Any guidance will be helpful. <br>
Thanks</p>
",1,79796,,0,101586,101586,2020-08-05T03:17:31.823,2020-07-30T17:23:35.770,1,4,,
72503,1,2020-04-17T17:34:21.143,0,32,<python><matplotlib><plotting>,Having and issue plotting horizontal chart,"<p>So for some weird reason I can't manage to fix the plotting issue</p>

<p>Any suggestions? </p>

<p><a href=""https://i.stack.imgur.com/aiCTA.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/aiCTA.jpg"" alt=""enter image description here""></a></p>

<pre><code>from sklearn.metrics import confusion_matrix

List = [] 
for i in range(len(model)):
  cm = confusion_matrix(Y_test, model[i].predict(X_test))

  TN = cm[0][0]
  TP = cm[1][1]
  FN = cm[1][0]
  FP = cm[0][1]

  List.append(((TP + TN) / (TP + TN + FN + FP))*100)

  print()

import numpy as np
import matplotlib.pyplot as plt

fig, ax = plt.subplots()
bars = ('Logistic', 'K Nearest Neighbor', 'K Nearest Neighbor', 'Support Vector Machine ', 'Support Vector Machine ','Support Vector Machine ','Support Vector Machine ' )
percentage = np.array([List[0], List[1], List[2], List[3],List[4],List[5],List[6]])


new_labels = [i+'  {:.2f}%'.format(j) for i, j in zip(bars, percentage)]

plt.barh(bars, percentage, color='lightskyblue', edgecolor='blue')
plt.yticks(range(len(bars)), new_labels)
# Show graphic
plt.show()
</code></pre>
",1,72512,,0,95092,,2020-04-17T19:51:11.837,,1,2,,
18667,1,2017-04-29T00:38:12.613,11,6211,<python><neural-network><keras><image-classification>,ReLU vs sigmoid in mnist example,"<p>PLEASE NOTE: I am not trying to improve on the following example. I know you can get over 99% accuracy. The whole code is in the question. When I tried this simple code I get around 95% accuracy, if I simply change the activation function from sigmoid to relu, it drops to less than 50%. Is there a theoretical reason why this happens?</p>

<p>I have found the following example online:</p>

<pre><code>from keras.datasets import mnist
from keras.models import Sequential 
from keras.layers.core import Dense, Activation
from keras.utils import np_utils

(X_train, Y_train), (X_test, Y_test) = mnist.load_data()

X_train = X_train.reshape(60000, 784)     
X_test = X_test.reshape(10000, 784)

Y_train = np_utils.to_categorical(Y_train, classes)     
Y_test = np_utils.to_categorical(Y_test, classes)

batch_size = 100      
epochs = 15

model = Sequential()     
model.add(Dense(100, input_dim=784)) 
model.add(Activation('sigmoid'))     
model.add(Dense(10)) 
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='sgd')

model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=1)

score = model.evaluate(X_test, Y_test, verbose=1)
print('Test accuracy:', score[1])
</code></pre>

<p>This gives about 95% accuracy, but if I change the sigmoid with the ReLU, I get less than 50% accuracy. Why is that? </p>
",1,41128,,11,13736,13736,2020-08-09T09:54:28.697,2018-03-17T19:17:30.677,3,6,,
18427,1,2017-04-18T16:28:16.577,2,682,<machine-learning><python><labels><active-learning><labelling>,Python package for machine-learning aided data labelling,"<p>In a lot of cases unlabelled data needs to be transformed to labelled data. The best solution is to use (multiple) human classifiers. However, going to all the data by hand (i.e. in text-mining or image-processing) is often a daunting task. Is there software that can combine human classifiers and machine-learning techniques in real time? I am especially interested in python packages. </p>

<p>To illustrate, classifying images from video streams is very repetitive. After 100 images (from different streams) a machine-learning algorithm could be used to predict the labels given by the human classifier. The machine classifier might be very confident about some (un)seen samples and very uncertain about others. The human classifier can then focus on the uncertain samples helping the machine classifier to learn better what is does not yet know.</p>
",1,18436,,2,20372,85045,2021-02-10T16:47:58.520,2021-02-10T16:47:58.520,1,3,,
5401,1,2015-03-27T07:20:28.740,0,1175,<data-mining><python><social-network-analysis>,Which book is the best for introduction to analysis social network using python3,"<p>I am a beginner studying <strong>social network analysis</strong>.
I installed python 3 just 2 weeks ago.
There are a lot of books for python and social network analysis.</p>

<p>I couldn't choose one of them.
I found one book named ""Mining the Social Web (Analyzing Data from Facebook, Twitter, Linkedln, and Other Social Media Sites)"" written by Matthhew A. Russell.
This book looks very interesting and fits in my purpose, but it is based on python 2. </p>

<p>Is there any good books with <strong>python 3</strong>? I usually use <strong>Twitter, Facebook, or Blog data</strong>.</p>

<p>In addition, could you recommend any good book for <strong>nodeXL and UCINET?</strong>  </p>
",1,5402,,0,8839,,2015-03-27T08:00:09.137,,1,3,2015-03-27T11:28:19.117,
73114,1,2020-04-27T22:06:01.273,1,56,<python><regression><multivariate-distribution>,How can I fix regression model interpretation of feature?,"<p>I'm building a regression model to predict the values of a feature <span class=""math-container"">$Y$</span> given a set of other features <span class=""math-container"">$X_{1}, X_{2}, X_{3}..X_{n}$</span>.</p>

<p>Onde of these other features, let's say <span class=""math-container"">$X_1$</span>, is known to be inversely proportional to <span class=""math-container"">$Y$</span> based on domain's knowledge. The problem is my model is interpreting his coefficient as positive, letting it directly proportional to <span class=""math-container"">$Y$</span>. I've tried plenty of different models to verify if I could get better interpretation, such as OLS, Linear Regression, and Logistic Regression, but every model I tried failed to interpret the <span class=""math-container"">$X_1$</span> coefficient.</p>

<p>What can I do to get a regression that better reflects the real-world behavior of this coefficient?</p>
",1,73128,,1,95905,95905,2020-04-29T09:56:31.757,2020-04-28T02:32:56.997,2,6,,
31545,1,2018-05-11T18:23:22.447,3,231,<python><classification><nlp><text-mining>,Build train data set for natural language text classification?,"<p>I have extracted <strong>~550 video scripts (subtitles)</strong> from 11 free courses on the Coursera platform. I have pre-processed them in terms of <strong>punctuation removal, stop words removal, tokenization, stemming and lemmatization</strong>. Now, I've been advised that for my task I can attempt to use a simple <strong>Bag of Words</strong>. However I am not sure how exactly would that help me towards classifying my text into <strong>one out of six categories</strong>. The categories are related to the intent a video material was created with and more precisely, which part explains a concept, which part discusses an example, which part gives practical advice etc. Below are my categories:</p>

<p><code>ConceptDescription</code>-> Explanation of the Main concept(s)<br>
<code>ConceptMention</code>-> Mentioning of a concept, related to the main concept<br>
<code>Methodology / Technique</code>-> To achieve something, what should one do<br>
<code>Summary</code>-> Summary of the discussed material or of the whole course<br>
<code>Application</code>-> Practical advise for the concept<br>
<code>Example</code>-> Concept example<br></p>

<p>By manually reading several files from 3 of the courses, I created a dictionary, containing spoken language words, that may help me identify which class a specific sentence/paragraph falls into. However <strong>I do NOT have a train dataset</strong> for a classifier. So my idea was to use that dictionary to label my data, e.g. sentence 1 as <code>Summary</code>, sentence 4 as <code>ConceptDescription</code> and sentence 12 as <code>Example</code> and then marking sentences 2 and 3 the same as 1, sentence 5-11 like sentence 4 etc.</p>

<p>My question is, is this idea too lame? And <strong>is there a way to create at least an average quality training dataset in a way that is not manual?</strong> Or <strong>if manual check is the only option, is there an option where I would need to do manual labeling on only a small fraction of the files</strong>, say 50 out of 550 and classification would still produce average to good result? I don't aim at perfect result, but I aim at something less time-consuming due to limited time.</p>

<p>I also played with tf-idf which outputs terms, but of course, not really what I need, so that was a bit random.</p>

<p>Thanks in advance for your help. <strong>Any specific ideas and algorithms would be very welcome.</strong></p>
",1,31654,,3,50625,,2018-05-14T18:56:47.197,,2,4,,
45767,1,2019-02-18T16:02:49.950,2,2399,<python><neural-network><cross-validation><sampling>,How to do k-folds in python whilst splitting into 3 sets?,"<p>Consider the following data:</p>

<pre><code>   import pandas as pd
    wine = pd.read_csv(r'wine_data.csv', names = [""Cultivator"", ""Alchol"", ""Malic_Acid"", ""Ash"", ""Alcalinity_of_Ash"", ""Magnesium"", ""Total_phenols"", ""Falvanoids"", ""Nonflavanoid_phenols"", ""Proanthocyanins"", ""Color_intensity"", ""Hue"", ""OD280"", ""Proline""])
    X = wine.drop('Cultivator',axis=1) #input
    y = wine['Cultivator'] #output
</code></pre>

<p>y is what i am trying to predict and X is the input and i will be using some sort of mlp classifier. What I want to do is split this data into test, training and validation and then apply K-folds. I'm struggling to see how you do this.. </p>

<p>I know that I can obtain validation, test and training by using the following: </p>

<pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)
</code></pre>

<p>But what I want to do now is apply k folds such that for each fold I have 3 sets: validation, testing , training rather than just 2 sets. </p>

<p>I know I can use the below for Kfolds:</p>

<pre><code>kf = KFold(n_splits = 5, shuffle = True, random_state = 2)
X_np=np.array(X)
y_np=np.array(y)
</code></pre>

<p>After converting to a numpy array I can then do this: </p>

<pre><code>for train_index, test_index in kf.split(X_np):
    print(""TRAIN:"", train_index, ""TEST:"", test_index)
    X_train, X_test = X_np[train_index], X_np[test_index]
    y_train, y_test = y_np[train_index], y_np[test_index]
</code></pre>

<p>But how do I get a 'validation_index'. In general the question is how do I use k-folds when I have 3 sets as opposed to just 2? </p>

<p>Also when do I normalize the data; do I normalize when i've split into X_train, X_test as above... or do I do it before? </p>

<p>Any help appreciated. </p>
",1,45792,,2,67931,29169,2020-07-13T13:01:40.163,2019-02-19T05:26:19.390,1,1,,
40813,1,2018-11-06T11:38:56.487,0,1469,<python><xgboost>,does xgb multi-class require one-hot encoding?,"<p>I was trying an xgboost from python with a multiclass single-label problem and assumed the label can be an integer indicating my class (as opposed to eg one-hot) . </p>

<pre><code>params = {'eta': 0.1,
#          'objective': 'binary:logistic', 
          'objective': 'multi:softmax', 
          'scale_pos_weight':9,
           'eval_metric': 'auc', 
           'nthread':25,
         'num_class':6}

dtrain = xgb.DMatrix(df_train_x,label= df_train_y)
dvalid = xgb.DMatrix(df_val_x,label= df_val_y)
watchlist = [(dtrain, 'train'), (dvalid, 'valid')]
model = xgb.train(params, dtrain, 500,watchlist, maximize=True, verbose_eval=50,early_stopping_rounds=20)
</code></pre>

<p>However I hit an error </p>

<pre><code>(1353150 vs. 225525) label size predict size not match
</code></pre>

<p>and I note that my sample size is 225525 , number of classes is 6 , and 6*225525 is 1353150 so it appears that xgb is looking for one-hot ... however when i use one hot I get an error hinting that one-hot can't be used - </p>

<pre><code>dtrain = xgb.DMatrix(df_train_x,label= df_train_y)
ValueError: DataFrame for label cannot have multiple columns
</code></pre>

<p>!!!</p>
",1,40823,,0,54188,,2018-11-06T14:18:36.833,,1,1,,
73485,1,2020-05-04T05:35:46.977,0,30,<machine-learning><python><data-mining><pandas><pattern-recognition>,Find the time between two events by customer id,"<p>I need to find a customer has bought P1, and after how many days customer will buy P2. 
I am unable to find the days between order of P1 and the next order of P2 by the same customer.</p>

<p>I have data as shown below. </p>

<pre><code>Customer ID   Order_Date   Product  
       C-87   11/20/2018        P2  
       C-87    7/25/2018        P1  
       C-87    7/19/2019        P1      
       C-87     8/2/2018        P2  
       C-87    12/9/2019        P1  
        ...          ...       ...
       C-22    9/22/2018        P2  
       C-22     9/4/2018        P2  
       C-22    1/15/2018        P1  
       C-22     9/5/2019        P2  
       C-22    3/20/2018        P1
</code></pre>
",1,73511,,0,96361,32492,2020-05-04T11:18:41.460,2020-05-04T07:20:25.900,1,3,2020-05-04T20:32:34.517,
33656,1,2018-06-26T06:51:52.417,2,1603,<python><visualization><matplotlib>,How to scatter plot with each dimension having its own color,"<p>I want to get insight for some values. I have two vectors of 300 dimensions, and want to compare them coordinate by coordinate. So I thought to plot each point with a different color, but the color for a dimension to be the same so that I would know which coordinates are lying where.</p>

<p>I have the below code, which I modeled on some results at stackoverflow.</p>

<pre><code>colors = itertools.cycle([""r"", ""g"", ""b""])

for d_in in inp_samples:
    clr = next(colors)
    plt.scatter(len(inp_samples), d_in, c=clr)

colors = itertools.cycle([""r"", ""g"", ""b""])

for d_out in out_samples:
    clr = next(colors)
    plt.scatter(len(out_samples), d_out, c=clr) 
</code></pre>

<p>But the plot I am getting is very weird. I was expecting it would be scattered but it is something like this:</p>

<p><a href=""https://i.stack.imgur.com/hkST3.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hkST3.png"" alt=""plot of the  two vectors""></a></p>

<p>I also tried this:</p>

<pre><code>colors = cm.jet(np.linspace(0, 1, 300))

for d_in, d_out, c in zip(inp_samples, out_samples, colors):
    plt.scatter(len(inp_samples), d_in, c=c)
    plt.scatter(len(out_samples), d_out, c=c)
</code></pre>

<p><a href=""https://i.stack.imgur.com/qriMn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/qriMn.png"" alt=""enter image description here""></a></p>

<p>Can anyone help in understanding what I am doing wrong?</p>
",1,33658,,2,53169,29575,2018-06-26T13:40:15.843,2018-06-26T13:40:15.843,1,1,,
43272,1,2018-12-29T07:19:29.213,2,1732,<python><keras><tensorflow><json>,Keras save model FailedPreconditionError,"<p>Model works and fits. After adding <code>model.save('model.h5')</code>. I am receiving
<code>tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value dense_11/bias[[Node: _retval_dense_11/bias_0_0 = _RetvalT=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]]
</code></p>

<p>I tried <code>model.save_weights('model.h5')</code>  saves the model but after trying to load the model I get: </p>

<p><code>KeyError: ""Unable to open object (object 'dense_12' doesn't exist)""</code></p>

<p>After saving model to json and then trying to load it i get <code>json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0).</code></p>

<p>What should I do?
Thanks for help!</p>
",1,43373,,2,58155,58155,2019-01-01T10:44:44.087,2018-12-29T07:25:23.723,1,2,,
37672,1,2018-09-01T02:21:43.670,2,192,<python><scraping>,Complex HTMLs Data Extraction with Python,"<p>Does anybody know a way of extracting data with python from more convoluted website structures? For example, I'm trying to extract data from the players in the <a href=""https://www.atpworldtour.com/en/players/rafael-nadal/n409/overview"" rel=""nofollow noreferrer"">ATP</a> profiles, but it's just so complicated I quit. I think they're pulling data from some database in the script and I suspect that even if I tried I wouldn't be able to get it.</p>

<p>I then started using a specialized software called <code>ParseHub</code>, which pulls the data somewhat visually. It's a pretty good software, but they make it slow on purpose just so you buy it, and it is particularly not cheap.</p>
",1,37681,,2,57429,,2018-09-12T16:57:41.637,,2,1,,
60126,1,2019-09-12T17:34:38.833,1,4618,<python><keras><reshape>,Data Reshaping for CNN using Keras,"<p>I'm a beginner in Keras. I've loaded MNIST dataset in Keras and checked it's dimension.
The code is</p>

<pre><code>from keras.datasets import mnist

# load data into train and test sets
(X_train, y_train), (X_test, y_test) = mnist.load_data()

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)
print(""Shape: "", X_train[0].shape)
</code></pre>

<p>And the output is</p>

<pre><code>(60000, 28, 28, 1)
(60000, 10, 2, 2, 2, 2)
(10000, 28, 28, 1)
(10000, 10, 2, 2)
Shape:  (28, 28, 1)
</code></pre>

<p>As X_train and X_test are already in the shape (#sample, width, height, #channel). Do we still need reshaping? Why?
The tutorial I'm following use the following reshaping code:</p>

<pre><code>X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')
X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')
</code></pre>

<p>My second question is that why is <code>.astype('float32')</code> is used in code? </p>

<p>Lastly, I could not understand the output of <code>print(y_train.shape)</code> and <code>print(y_test.shape)</code>.</p>

<p>Please suggest.
I've already read <a href=""https://datascience.stackexchange.com/questions/11704/reshaping-of-data-for-deep-learning-using-keras"">Reshaping of data for deep learning using Keras</a> however still my doubts are unclear.</p>
",1,60142,,1,25843,,2019-09-13T07:39:52.247,,2,7,,
96938,1,2021-06-22T00:21:26.247,1,874,<python><pandas>,How to convert float type nan in a dictionary value to 0.50?,"<p>I have a dictionary as below:</p>
<pre><code>{
   '$175000-199999': nan,
   '$698506': nan
}
</code></pre>
<p>I want to convert the nan to 0.50. I tried using dictionary comprehensions
<code>{k:v is 0.50 if v == nan else v for (k, v) in dictionary.items()}</code> but it throws an error saying nan is float. How do I fix this?</p>
",1,96973,,1,109295,109295,2021-06-23T01:17:03.550,2021-06-22T00:28:03.213,1,2,,
52956,1,2019-05-31T07:34:15.983,1,383,<python>,How to create a stacked bar chart with gaps between values of each variables in Python,"<p>I have a problem with creating a stacked bar chart in Python. I have data with 3 variables as below:</p>

<p><code>A=[3,5,7] 
B=[4,5,7]
C=[2,3,4,5,6,7]</code></p>

<p>I would like to create a bar chart with gaps of values of each variable as below bar chart with gaps between values of each variable :</p>

<p><a href=""https://i.stack.imgur.com/v8RUY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/v8RUY.png"" alt=""enter image description here""></a></p>

<p>Could anyone know how to create it in Python?
Thank you very much.</p>
",1,53086,,1,75147,,2019-06-02T13:43:34.100,,1,2,,
66244,1,2020-01-10T07:05:38.537,7,3536,<python><numpy>,Convert Numpy array with 'n' and 'y' into integer array of 0 and 1,"<p>I have a NumPy array of strings: 'n', 'y', wanna convert it into integer array of 0, 1, how to convert it?</p>

<pre class=""lang-py prettyprint-override""><code>imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
X = imp.fit_transform(X)

X

array([['n', 'y', 'n', ..., 'y', 'n', 'y'],
       ['n', 'y', 'n', ..., 'y', 'n', 'y'],
       ['n', 'y', 'y', ..., 'y', 'n', 'n'],
       ...,
       ['n', 'y', 'n', ..., 'y', 'n', 'y'],
       ['n', 'n', 'n', ..., 'y', 'n', 'y'],
       ['n', 'y', 'n', ..., 'y', 'n', 'n']], dtype=object)
</code></pre>
",1,66255,,7,87707,,2020-01-11T01:43:56.250,,4,2,,
38914,1,2018-09-28T14:41:38.027,3,4702,<python><dataset><pandas><data-cleaning><preprocessing>,"A single column has many values per row, separated by a comma. How to create an individual column for each of these?","<p>As you can see below, I have a column called <code>code</code> with multiple values per row, separated by a comma. How can I create a column for each of these codes and make them all binary values? </p>

<p>i.e. <code>code6254</code>, <code>code5854</code> etc...., where all these columns will be of binary value <code>0</code> or <code>1</code> depending on whether that row has the code or not? Thanks in advance :)</p>

<p><a href=""https://i.stack.imgur.com/A6an8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/A6an8.png"" alt=""enter image description here""></a></p>
",1,38916,,3,35386,,2019-10-03T17:21:46.807,,2,2,,
10842,1,2016-03-23T08:07:54.790,0,347,<python><pandas><correlation>,How/What Correlation for Position Ranking?,"<p>I'm newbie to Data Science. I'm trying to understand how to correlate the position of an app in the app store, e.g. 1-10, to the number of backlinks, e.g. #1 = 250 links, #8 = 50 links, to the app store listing page in Python.</p>

<p>I've manage to correlate both rows entirely, which obviously gives me a nonsense figure.</p>

<p>Could someone point me in the right direction to allow me to fill this knowledge gap. I'm not entirely sure of the correct terminology for this, making Googling it pretty impossible.</p>
",1,11871,,0,17248,,2016-06-21T17:48:51.127,,2,3,,
90103,1,2021-03-01T17:26:44.970,1,137,<machine-learning><python><algorithms>,How to select the best parameters for GridSearchCV?,"<p>I've created a couple of models during some assignments and hackathons using algorithms such as Random Forest and XGBoost and used GridSearchCV to find the best combination of parameters. But what I'm not able to understand is how to select those parameters for GridSearchCV. I randomly put the parameters such as</p>
<pre><code>params = {&quot;max_depth&quot; : [5, 7, 10, 15, 20, 25, 30, 40, 50,100],
         &quot;min_samples_leaf&quot; : [5, 10, 15, 20, 40, 50, 100, 200, 500, 1000,10000],
         &quot;criterion&quot;: [&quot;gini&quot;,&quot;entropy&quot;],
         &quot;n_estimators&quot; : [10, 15, 20, 40, 50, 75, 100,1000],
         &quot;max_features&quot; : [&quot;auto&quot;, &quot;sqrt&quot;,&quot;log2&quot;]}
</code></pre>
<p>But how do I decide if I could select better parameters which might be computationally better as well? I can't use the same above parameters for a Random Forest Classifier every single time surely?</p>
",1,90109,,1,112361,,2021-03-01T19:38:41.913,,1,1,,
88671,1,2021-01-29T14:43:11.680,0,270,<python><pandas><json>,Extract data from json format and paste to column using python,"<p>In my column with json data, I have this list I want to extract to column:</p>
<pre><code>&quot;list&quot;:[

{
    &quot;id&quot;:&quot;list&quot;,
    &quot;item&quot;:[
        {
            &quot;value&quot;:&quot;Hergestellt in Italien aus 100% reinem Platin-Flüssigsilikon&quot;
        },
        {
            &quot;value&quot;:&quot;Geruchs- und geschmacksneutral&quot;
        },
        {
            &quot;value&quot;:&quot;Kältebeständig bis -60°C&quot;
        },
        {
            &quot;value&quot;:&quot;Inklusive Rezeptbuch und 50 Eisstielen&quot;
        },
        {
            &quot;value&quot;:&quot;spülmaschinengeeignet&quot;
        }
    ],
    &quot;decorators&quot;:[
    ]
},
</code></pre>
<p>I have extracted other data using this code but the value was string and not a dictionary:</p>
<pre><code>if 'item' in item and item['item']:
                    if isinstance(item['item'], str):
                        cur_model_info[item['id']] = item['item']
                    elif isinstance(item['item'], list):
                        elements = [element['value'] for element in item['item']]
cur_model_info[item['id']] = ','.join(elements)
</code></pre>
<p>I tried to use this for the above format of data but I got this error:
TypeError: sequence item 0: expected str instance, dict found</p>
<p>What should I change in order to be able to export in a separate column the data having each element from the list in a new cell of that column?</p>
<p>expected output</p>
<p><a href=""https://i.stack.imgur.com/VE9eP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/VE9eP.png"" alt=""enter image description here"" /></a></p>
<p>Using the above code, the data is exported in this format</p>
<p><a href=""https://i.stack.imgur.com/rmBke.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/rmBke.png"" alt=""![enter image description here"" /></a></p>
",1,88686,,0,110996,110996,2021-01-29T22:19:35.713,2021-01-29T22:19:35.713,1,5,,
34357,1,2018-07-12T09:25:51.067,139,92661,<python><pandas><sql>,Why do people prefer Pandas to SQL?,"<p>I've been using SQL since 1996, so I may be biased. I've used MySQL and SQLite 3 extensively, but have also used Microsoft SQL Server and Oracle.</p>

<p>The vast majority of the operations I've seen done with Pandas can be done more easily with SQL. This includes filtering a dataset, selecting specific columns for display, applying a function to a values, and so on.</p>

<p>SQL has the advantage of having an optimizer and data persistence. SQL also has error messages that are clear and understandable. Pandas has a somewhat cryptic API, in which sometimes it's appropriate to use a single <code>[ stuff ]</code>, other times you need <code>[[ stuff ]]</code>, and sometimes you need a <code>.loc</code>. Part of the complexity of Pandas arises from the fact that there is so much overloading going on. </p>

<p>So I'm trying to understand why Pandas is so popular.</p>
",1,34366,,139,13672,103697,2021-05-16T12:14:26.633,2020-08-22T16:29:21.750,12,2,,2019-02-17T00:57:28.627
99688,1,2021-08-04T13:39:27.033,0,333,<python><nlp><bert><transformer>,Error to load a pre-trained BERT model,"<h2>Background</h2>
<p>I'm reading <a href=""https://blog.codecentric.de/en/2020/12/ner-with-little-data-transformers-to-the-rescue/"" rel=""nofollow noreferrer"">this article</a> about a natural language task, named entity recognition and trying to load a pre-trained BERT model on Google colaboratory.</p>
<p><strong>How can I fix an error to load a pre-trained BERT model?</strong></p>
<h2>Code</h2>
<pre class=""lang-py prettyprint-override""><code>from transformers import AutoConfig, TFAutoModelForTokenClassification
MODEL_NAME = 'bert-base-german-cased' 
config = AutoConfig.from_pretrained(MODEL_NAME, num_labels=len(schema))
model = TFAutoModelForTokenClassification.from_pretrained(MODEL_NAME, config=config)
model.summary()
</code></pre>
<h2>Error</h2>
<p>I can understand that schema is not defined before the line, but I cannot find a clew on the article to fix it.</p>
<pre><code>      1 from transformers import AutoConfig, TFAutoModelForTokenClassification
      2 MODEL_NAME = 'bert-base-german-cased'
----&gt; 3 config = AutoConfig.from_pretrained(MODEL_NAME, num_labels=len(schema))
      4 model = TFAutoModelForTokenClassification.from_pretrained(MODEL_NAME, config=config)
      5 model.summary()

NameError: name 'schema' is not defined
</code></pre>
<h2>What I tried</h2>
<p>I checked <a href=""https://blog.codecentric.de/en/2020/11/take-control-of-named-entity-recognition-with-you-own-keras-model/"" rel=""nofollow noreferrer"">previous blogpost</a> following the advice from a comment, and found one description.</p>
<p>However, I'm not sure where to insert it to the original code.</p>
<pre><code>For simplicity, we’ll truncate the sentences to a maximum length and pad shorter input sequences. But first, let us determine the set of all tags in the data and add an extra tag for the padding:

#code
schema = ['_'] + sorted({tag for sentence in samples for _, tag in sentence})
</code></pre>
<p>Is it correct understanding?</p>
<pre><code>def load_data(filename: str):
   with open(filename, 'r') as file:
     lines = [line[:-1].split() for line in file]
     samples, start = [], 0
     for end, parts in enumerate(lines):
       if not parts:
         sample = [(token, tag.split('-')[-1]) for token, tag in lines[start:end]]
         samples.append(sample)
         start = end + 1
     if start &lt; end:
       samples.append(lines[start:end])
     
     return samples

samples = load_data('data/01_raw/bag.conll')
train_samples = load_data('data/01_raw/bag.conll')
val_samples = load_data('data/01_raw/bgh.conll')
all_samples = train_samples + val_samples

schema = ['_'] + sorted({tag for sentence in samples for _, tag in sentence})
</code></pre>
<p>I checked the output.</p>
<pre><code>print(schema)
#result
['_', 'AN', 'EUN', 'GRT', 'GS', 'INN', 'LD', 'LDS', 'LIT', 'MRK', 'O', 'ORG', 'PER', 'RR', 'RS', 'ST', 'STR', 'UN', 'VO', 'VS', 'VT']
</code></pre>
",1,99736,,0,107687,107687,2021-08-05T13:56:37.953,2021-08-04T14:56:19.340,1,6,,
13465,1,2016-08-16T15:38:29.150,3,7688,<python><scikit-learn><decision-trees><error-handling>,First steps with Python and scikit-learn,"<p>I believe I have a simple if not trivial question. I have a background in statistics and I tend to use Stata and R quite a bit. I am interested in learning Python. I used it for a while now and recently came into contact with <a href=""http://scikit-learn.org/"" rel=""nofollow"">scikit-learn</a>. </p>

<p>I am trying to reproduce a simple example. </p>

<pre><code>from sklearn import tree
features = [[140, 1],[130, 1], [150, 0], [170, 0]]
labels = [0 , 0 , 1 , 1]
clf = tree.DecisionTreeClassifier()
clf = clf.fit(features, labels)
print clf.predict([[150, 0]])
</code></pre>

<p>As you can see, the tiny script tries to predict  - by the means of a decision tree - wether a object with the properties <code>[150, 0]</code> is likely a type <code>1</code> or <code>0</code>. </p>

<p>I run the script and get following error:</p>

<pre><code>File ""clf_decision_tree.py"", line 6
    print clf.predict([[150, 0]])
            ^
SyntaxError: invalid syntax
</code></pre>

<p>I realy don't get what is wrong... Can you help me out? Best /R</p>

<p>PS: I not sure if Cross Validated or Stackoverflow are better places to ask. Let me know. Thanks.</p>
",1,13466,,3,23452,23452,2017-08-14T10:21:16.280,2016-08-16T15:45:39.293,2,3,,
26093,1,2017-12-28T20:34:47.873,0,1460,<machine-learning><python><scikit-learn><data-cleaning><pandas>,Replacing the feature variables with encoded variables,"<p>I have several nominal variables which I've encoded using the <code>LabelEncoder()</code> function. Now I want to replace the encoded values in the place of the raw datas of the features in the dataframe. I tried <code>df.replace()</code> but no luck. Below is the code snippet.</p>

<pre><code>nominal_values = [
    'HouseStyle','ExterQual','BsmtQual','BsmtExposure','BsmtFinType1',
    'KitchenQual','GarageType','GarageFinish','GarageQual','GarageCond']
</code></pre>

<p>One of the column ""KitchenQual"" has values as follows:</p>

<p>{kitchenqual :['Ex','Gd','TA','Fa','Po']} representing ""Excellent"",""Good"",""Typical/Average"",""Fair"",""Poor"" respectively.</p>

<p>Another Feature ""BsmtFinType1"" has values as follows:</p>

<p>{BsmtFinType1: ['GLQ','ALQ','BLQ','Rec','LwQ','Unf','NA']} represeting</p>

<p>""Good Living Quarters"",""Average Liv. Quat."",""Below Avg.Liv.Quat,"",""Avg. rec room"", ""Low Quality"", ""Unfinished"",""No Basement"" respectively.</p>

<pre><code>from sklearn.preprocessing import LabelEncoder

lbe = LabelEncoder()
for noms in nominal_values:
    encode = lbe.fit_transform(cat_var[noms])
    cat_var.replace(to_replace=cat_var[noms],
                    value=pd.Series(encode),inplace=True)
</code></pre>

<p>I used <code>pd.Series(encode)</code> since the replace function will support only one of the following data structures</p>

<ul>
<li>Scalar</li>
<li>dict</li>
<li>Series</li>
</ul>
",1,26297,,0,43890,43890,2018-01-04T18:23:10.637,2017-12-31T11:33:25.417,1,3,,
117254,1,2022-12-22T18:55:04.773,0,79,<python><nlp><machine-translation>,How to translate text automatically using Google Translate API (or any other approach) in python,"<p>I have a dataset of reviews from TripAdvisor and I would like to translate non-English reviews into English.</p>
<p>The reviews are in many different languages: my dataset contains reviews in 44 different languages including English reviews which are around a quarter of the total, followed by Italian, German, Spanish and French reviews which are respectively 14%, 11% 6%, and 5.5% of the reviews.</p>
<p>I detect the different languages using the <a href=""https://pypi.org/project/langdetect/"" rel=""nofollow noreferrer""><code>langdetect</code> package</a>.</p>
<pre><code>from langdetect import detect

language = detect(title) 
        
</code></pre>
<p>Then I tried to use the package <a href=""https://pypi.org/project/googletrans/"" rel=""nofollow noreferrer"">googletrans</a> to translate the text.
However, when I tried to perform a small test I get the following error:</p>
<pre><code>from googletrans import Translator
translator = Translator()

translator.translate('Buongiorno mi chiamo Alberto')
</code></pre>
<p><a href=""https://i.stack.imgur.com/Il9IX.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Il9IX.png"" alt=""enter image description here"" /></a></p>
<p>Does anyone know a way to translate reviews (knowing or not the language ) to English using python
for a dataset of around 10k reviews?</p>
",1,117257,,0,140946,,2022-12-22T19:44:16.780,,1,1,,
71404,1,2020-03-29T12:00:41.113,13,2762,<python><pandas><matplotlib><tableau>,What do Python's pandas/matplotlib/seaborn bring to the table that Tableau does not?,"<p>I spent the past year learning Python. As a person who thought coding was impossible to learn for those outside of the CS/IT sphere, I was obviously gobsmacked by the power of a few lines of Python code!</p>

<p>Having arrived at an intermediate level overall, I was pretty proud of myself as it greatly expands my possibilities in data analysis and visualization compared to Excel (aside from the millions of other uses there are for Python).</p>

<p>Purely in terms of data analysis and visualization:</p>

<p><strong>what does approaching the same data set with</strong> <code>pandas/matplotlib/seaborn/numpy</code> <strong>bring to the table as opposed to using <em>Tableau</em>?</strong></p>

<p>(sidenote: I was greatly disappointed to see all my hard-earned Python data wrangling skills were available in such a user-friendly GUI... :'( )</p>
",1,71406,,13,92553,,2021-01-13T13:56:28.167,,3,1,,
53067,1,2019-06-01T20:33:21.643,2,49,<python><clustering>,Is there a scientific method for grouping continuous numbers for this problem,"<p>I use python, and I have a list of numbers that contains 19 elements and I would like to divide this list into 6 groups or fewer.  </p>

<p>The list could have numbers between 0 and 1. and it mustn't be ordered, I need to keep it on its form and getting cut-off   </p>

<p><strong>list:</strong></p>

<pre><code>Numbers :  [[ 0.867   - 0.808   - 0.740    - 0.746    - 0.674   - 0.669   -
              0.648   - 0.722   - 0.781    - 0.612    - 0.575   - 0.566   -
              0.500   - 0.555   - 0.818    - 0.800    - 0.500   - 0.500   - 0.666 ]]   
</code></pre>

<p>I would like to get clusters like :</p>

<pre><code>A: [[ 0.867   - 0.808   - 0.740    - 0.746 ]]

B: [[ 0.674   - 0.669   - 0.648 ]]

C: [[ 0.722   - 0.781 ]]

D: [[ 0.612   - 0.575   - 0.566    - 0.500    - 0.555  ]]

E: [[ 0.818   - 0.800 ]]

F: [[ 0.500   - 0.500    - 0.666 ]]
</code></pre>

<p>I make splitting by <strong>eyes</strong> and for that, I ask for a <strong>scientific method</strong> for getting my objective.</p>

<ul>
<li>Concerning how I defined these clusters :</li>
</ul>

<p>I have a value that is getting from an extra function, it is equal to 0.80. I need to compare each value on the list with 0.80 for knowing the difference.</p>

<p>After making a comparison I get the following table </p>

<pre><code>Numbers      Difference_0.80
0.867            +0.06 
0.808             0.0
0.740            -0.06
0.746            -0.06

0.674            -0.13
0.669            -0.14
0.648            -0.16

0.722            -0.08
0.781            -0.02

0.612            -0.19
0.575            -0.23
0.566            -0.24
0.500            -0.3
0.555            -0.25

0.818            +0.01
0.800             0.0

0.500            -0.3
0.500            -0.3
0.666            -0.14

</code></pre>

<p>when I tried clustering method (with n_clusters=2) I ve got : </p>

<pre><code>0   category_Kk-mean
0.867   0
0.808   0
0.740   0
0.746   0
0.674   1
0.669   1
0.648   1
0.722   0
0.781   0
0.612   1
0.575   1
0.566   1
0.500   1
0.555   1
0.818   0
0.800   0
0.500   1
0.500   1
0.666   1

</code></pre>

<p>But I want to know also that  this category (D) have a big decrease than a category (B):</p>

<pre><code>category D
0.612   1
0.575   1
0.566   1
0.500   1
0.555   1
</code></pre>

<pre><code>Category B

0.674   1
0.669   1
0.648   1
</code></pre>

<p>I tried with n_clusters=3 but I got a totaly bad result</p>

<p>Is there any method in the statistic or mathematic that can help me for getting that </p>
",1,53770,,2,73680,73680,2019-06-14T07:48:33.457,2019-06-01T22:43:47.633,1,5,,
97077,1,2021-06-25T07:32:03.170,4,1886,<machine-learning><python><deep-learning><scikit-learn>,can't understand the Architecture of Neural Network,"<p><a href=""https://i.stack.imgur.com/kmfMR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kmfMR.png"" alt=""enter image description here"" /></a></p>
<p>Please explain how Z1 is working I just want to know why  W is of shape (4,3) I understand that there are four Weights we are performing (4,3)*(3,1) + (4,1) but I don't understand what is 3 in (4,3)</p>
<p><strong>Just write the full equation of Z1 rest is self-explanatory.</strong></p>
<p>I New to This field so, please spare me its very common to forget basic concepts in beginnig</p>
",1,97081,,4,119761,119761,2021-06-25T20:10:16.413,2021-06-25T07:40:43.850,3,1,,
30181,1,2018-04-11T16:51:31.033,4,227,<machine-learning><python><nlp><cnn>,How to do give input to CNN when doing a text processing?,"<p>As a signal processing engineering and being new to NLP, I am confused with giving input to CNN network. </p>

<p>With my knowledge of <a href=""https://github.com/raady07/CNN-for-bearing-fault-diagnosis/blob/master/main_all.py"" rel=""nofollow noreferrer"">CNN</a>, I am trying to build a classifier for ethnicity with inputs as text (last name(LN), middle name(MN), first name(FN)).
I have a list of 8,000,000 samples with last, middle, first names and class information</p>

<pre><code>array = [['person1_LN','person1_MN','person1_FN','Person1_class'],
         ['person1_LN','person1_MN','person1_FN','Person2_class'], 
         ....]
</code></pre>

<p>I want to apply conv layer (CL) followed by Pooling Layer(PL) on LN,MN,FN respectively. </p>

<p><a href=""https://github.com/dennybritz/cnn-text-classification-tf/blob/master/text_cnn.py"" rel=""nofollow noreferrer"">Text processing</a> example demonstrates with the sentences to convert to word embedding. I am trying to understand this code snippet </p>

<pre><code>W = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0), name='W')
self.embedded_chars = tf.nn.embedding_lookup(W, self.input_x)
self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)
</code></pre>

<p>This <a href=""https://rare-technologies.com/word2vec-tutorial/"" rel=""nofollow noreferrer"">tutorial</a> says training to be done using word2vec.
Reading these two blogs I could understand nothing. In Either of the cases, my data is not a sentence, moreover in the second case on what things I have to train?</p>

<p>Will the CL operate if I directly give the input of words without word embeddings? 
If not any example on how to embed the words in my case to give the input to CNN?</p>
",1,77741,,4,49268,49268,2020-08-14T19:05:40.593,2018-04-12T13:43:48.157,1,2,,
71636,1,2020-04-02T18:12:43.810,0,53,<python><dataset><data><data-cleaning><pca>,Standardizing features by one specific feature,"<p>I am working on a project with a dataset that looks something like the following:</p>

<pre><code>      velocity   accel_amp         f_vert   tau_vert      f_pitch_filt   tau
0    3.778595      -5.796777     2.400000  32.753227      1.600000   27.844535
1    1.970611      -6.087134     2.272727  32.638705      1.704545   30.639998
2    3.581163      -6.241817     2.400000  32.850969      1.600000   30.449256
3    4.735210      -6.109532     1.400000  28.809865      1.000000  127.749313
4    5.340568      -6.614317     1.400000  20.249699      1.000000  124.549628
</code></pre>

<p>I was suggested to standardize the last 5 features by velocity in order to improve my PCA.
Does this simply mean to take each element in these last 5 columns, subtract the mean of the velocity column, and then divide by the standard deviation of the velocity column? </p>

<p>That is how I interpreted this suggestion. Is there a functionality in Python for doing this? Any suggestions or clarification would be appreciated.</p>

<p>Thanks.</p>
",1,71648,,0,93899,,2021-01-09T16:08:35.887,,1,2,,
22233,1,2017-08-14T09:42:39.843,3,6056,<python>,Calculating the Standard Deviation by category using Python,"<p>I have a datset with Scores and Categories and I would like to calculate the Standard Deviation of these scores, per category. The data look something like this:</p>

<pre><code>Category    Score    
AAAA        1
AAAA        3
AAAA        1
BBBB        1
BBBB        100
BBBB        159
CCCC        -10
CCCC        9
</code></pre>

<p>What I would then like is the Standard Deviation of each Category. I know that with numpy I can use the following:</p>

<pre><code>numpy.std(a)
</code></pre>

<p>But the example I can find only have this relating to a list and not a range of different categories in a DataFame.</p>
",1,22235,,3,37059,8432,2019-11-25T13:44:03.973,2017-08-14T12:58:01.440,2,2,,
18071,1,2017-04-03T10:53:31.840,1,1367,<python><neural-network><deep-learning><tensorflow>,MNIST Deep Neural Network using TensorFlow,"<p>I have been working on this code for a while and it gave me a lot of headache before I got it to work. It basically tries to use the mnist dataset to classify handwritten digits. I am not using the prepackaged mnist in TensorFlow because I want to learn preprocessing the data myself and for deeper understanding of TensorFlow. </p>

<p>Its finally working but I would love it if someone with expertise could take a look at it and tell me what they think and if the results its producing are actually real stats or if its overfitting or not learning at all. </p>

<p>It's giving me accuracy between 83% and 91% from the test dataset. </p>

<p>the dataset I'm using is from <a href=""https://pjreddie.com/projects/mnist-in-csv/"" rel=""nofollow noreferrer"">https://pjreddie.com/projects/mnist-in-csv/</a> basically the two links on top of the page.</p>

<p>here is the code:</p>

<pre><code>import numpy as np
import tensorflow as tf
sess = tf.Session()
from sklearn import preprocessing
import matplotlib.pyplot as plt
with tf.Session() as sess:
    # lets load the file
    train_file = 'mnist_train.csv'
    test_file = 'mnist_test.csv'
    #train_file = 'mnist_train_small.csv'
    #test_file = 'mnist_test_small.csv'

    train = np.loadtxt(train_file, delimiter=',')
    test = np.loadtxt(test_file, delimiter=',')

    x_train = train[:,1:785]
    y_train = train[:,:1]

    x_test = test[:,1:785]
    y_test = test[:,:1]
    print(x_test.shape)

    # lets normalize the data
    def normalize(input_data):
        minimum = input_data.min(axis=0)
        maximum = input_data.max(axis=0)
        #normalized = (input_data - minimum) / ( maximum - minimum )
        normalized = preprocessing.normalize(input_data, norm='l2')
        return normalized

    # convert to a onehot array 
    def one_hot(input_data):
        one_hot = []
        for item in input_data:
            if item == 0.:
                one_h = [1.,0.,0.,0.,0.,0.,0.,0.,0.,0.]
            elif item == 1.:
                one_h = [0.,1.,0.,0.,0.,0.,0.,0.,0.,0.]
            elif item == 2.:
                one_h = [0.,0.,1.,0.,0.,0.,0.,0.,0.,0.]
            elif item == 3.:
                one_h = [0.,0.,0.,1.,0.,0.,0.,0.,0.,0.]
            elif item == 4.:
                one_h = [0.,0.,0.,0.,1.,0.,0.,0.,0.,0.]
            elif item == 5.:
                one_h = [0.,0.,0.,0.,0.,1.,0.,0.,0.,0.]
            elif item == 6.:
                one_h = [0.,0.,0.,0.,0.,0.,1.,0.,0.,0.]
            elif item == 7.:
                one_h = [0.,0.,0.,0.,0.,0.,0.,1.,0.,0.]
            elif item == 8.:
                one_h = [0.,0.,0.,0.,0.,0.,0.,0.,1.,0.]
            elif item == 9.:
                one_h = [0.,0.,0.,0.,0.,0.,0.,0.,0.,1.]

            one_hot.append(one_h)
        one_hot = np.array(one_hot)
        #one_hot = one_hot.reshape(len(one_hot),10,1)
        #one_hot = one_hot.reshape(len(one_hot), 7,1)
        #return tf.constant([one_hot])
        return one_hot
    def one_hot_tf(val):
        indices = val
        depth = 10
        on_value = 1.0
        off_value = 0.0
        axis = -1
        oh = tf.one_hot(indices, depth,
                   on_value=on_value, off_value=off_value,
                   axis=axis, dtype=tf.float32,
                   name='ONEHOT')
        return (oh)
    x_train = normalize(x_train)
    x_test =  normalize(x_test)
    #    x_train = sess.run(tf.convert_to_tensor(x_train))
    #    x_test =  sess.run(tf.convert_to_tensor(x_test))

    '''
    data_initializer = tf.placeholder(dtype=x_train.dtype,
                                        shape=x_train.shape)
    label_initializer = tf.placeholder(dtype=x_test.dtype,
                                         shape=x_test.shape)
    x_train= sess.run(tf.Variable(data_initializer, trainable=False, collections=[]))
    x_test = sess.run(tf.Variable(label_initializer, trainable=False, collections=[]))
    '''


    y_test =  one_hot(y_test)
    y_train =  one_hot(y_train)
    print(y_test[:5])
    #   y_test =  sess.run(one_hot_tf(y_test))
    #   y_train =  sess.run(one_hot_tf(y_train))


    # define the parameters
    input_nodes = 784
    output_nodes = 10
    hl1_nodes = 500
    hl2_nodes = 500
    hl3_nodes = 500
    epochs = 10
    x = tf.placeholder(tf.float32, [None, input_nodes])
    y = tf.placeholder(tf.float32)

    # graphing
    loss_rate = []


    def nn(data):
        layer1 = {'w':tf.Variable(tf.random_normal([input_nodes, hl1_nodes])),
                  'b':tf.Variable(tf.random_normal([hl1_nodes]))}
        layer2 = {'w':tf.Variable(tf.random_normal([hl1_nodes, hl2_nodes])),
                  'b':tf.Variable(tf.random_normal([hl2_nodes]))}
        layer3 = {'w':tf.Variable(tf.random_normal([hl2_nodes, hl3_nodes])),
                  'b':tf.Variable(tf.random_normal([hl3_nodes]))}
        output_layer = {'w':tf.Variable(tf.random_normal([hl3_nodes, output_nodes])),
                  'b':tf.Variable(tf.random_normal([output_nodes]))}

        l1 = tf.add(tf.matmul(data, layer1['w']), layer1['b'])
        l1 = tf.nn.relu(l1)

        l2 = tf.add(tf.matmul(l1, layer2['w']), layer2['b'])
        l2 = tf.nn.relu(l2)

        l3 = tf.add(tf.matmul(l2, layer3['w']), layer3['b'])
        l3 = tf.nn.relu(l3)

        output = tf.add(tf.matmul(l3, output_layer['w']), output_layer['b'])

        return(output)


    def train(x):
        prediction = nn(x)
        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))
        optimizer = tf.train.GradientDescentOptimizer(0.001).minimize(loss)

        init = tf.global_variables_initializer()
        sess.run(init)

        for epoch in range(epochs):
            epochloss = 0
            batch_size = 10
            batches = 0
            for batch in range(int(len(x_train)/batch_size)):
                next_batch = batches+batch
                _, c = sess.run([optimizer, loss], feed_dict={x:x_train[batches:next_batch, :], y:y_train[batches:next_batch, :]})
                epochloss = epochloss + c
                batches += batch
                loss_rate.append(c)

            print(""Epoch "", epoch, "" / "", epochs, "" - Loss "", epochloss)

        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))
        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))
        print(""Accuracy : "", accuracy.eval({x:x_test, y:y_test}))


    train(x)

    plt.plot(loss_rate)
    plt.show()
</code></pre>

<p>The output of 3 different runs are:</p>

<pre><code>=========== RESTART: /Users/macbookpro/Desktop/AI/tf/OWN/test3.py ===========
(10000, 784)
[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]
 [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]
Epoch  0  /  5  - Loss  nan
Epoch  1  /  5  - Loss  nan
Epoch  2  /  5  - Loss  nan
Epoch  3  /  5  - Loss  nan
Epoch  4  /  5  - Loss  nan
Accuracy :  0.9053

=========== RESTART: /Users/macbookpro/Desktop/AI/tf/OWN/test3.py ===========
(10000, 784)
[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]
 [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]
Epoch  0  /  5  - Loss  nan
Epoch  1  /  5  - Loss  nan
Epoch  2  /  5  - Loss  nan
Epoch  3  /  5  - Loss  nan
Epoch  4  /  5  - Loss  nan
Accuracy :  0.8342

=========== RESTART: /Users/macbookpro/Desktop/AI/tf/OWN/test3.py ===========
(10000, 784)
[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]
 [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]]
Epoch  0  /  5  - Loss  nan
Epoch  1  /  5  - Loss  nan
Epoch  2  /  5  - Loss  nan
Epoch  3  /  5  - Loss  nan
Epoch  4  /  5  - Loss  nan
Accuracy :  0.9
</code></pre>

<p>---Update---
I found the answer in rewriting the code as follows:</p>

<pre><code>import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np

sess = tf.Session()

file = ""mnist_train.csv""
data = np.loadtxt(file, delimiter=',')


y_vals = data[:,0:1]
x_vals = data[:,1:785]

seed = 3
tf.set_random_seed(seed)
np.random.seed(seed)
batch_size = 90

# split into 80/20 datasets, normalize between 0:1 with min max scaling
train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)
# up there we chose randomly 80% of the data
test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))
# up we chose the remaining 20% 
print(test_indices)

x_vals_train = x_vals[train_indices]
x_vals_test = x_vals[test_indices]
y_vals_train = y_vals[train_indices]
y_vals_test = y_vals[test_indices]

def normalize_cols(m):
    col_max = m.max(axis=0)
    col_min = m.min(axis=0)
    return (m-col_min)/(col_max - col_min)
x_vals_train = np.nan_to_num(normalize_cols(x_vals_train))
x_vals_test = np.nan_to_num(normalize_cols(x_vals_test))

# function that initializes the weights and the biases 
def init_weight(shape, std_dev):
    weight = tf.Variable(tf.random_normal(shape, stddev=std_dev))
    return(weight)

def init_bias(shape, std_dev):
    bias= tf.Variable(tf.random_normal(shape, stddev=std_dev))
    return(bias)

# initialize placeholders. 
x_data = tf.placeholder(shape=[None, 784], dtype=tf.float32)
y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)


# the fully connected layer will be used three times for all three hidden layers
def fully_connected(input_layer, weights, biases):
    layer = tf.add(tf.matmul(input_layer, weights), biases)
    return (tf.nn.relu(layer))

# Now create the model for each layer and the output layer.
# we will initialize a weight matrix, bias matrix and the fully connected layer
# for this, we will use hidden layers of size 500, 500, and 10

'''
This will mean many variables variables to fit. This is because between the data and the first hidden layer we have 
784*500+500 = 392,500 variables to change.
continuing this way we will have end up with how many variables we have overall to fit
'''

# create first layer (500 hidden nodes)
weight_1 = init_weight(shape=[784,500], std_dev=10.0)
bias_1 = init_bias(shape=[500], std_dev=10.0)
layer_1 = fully_connected(x_data, weight_1, bias_1)

# create second layer (5-- hidden nodes)
weight_2 = init_weight(shape=[500,500], std_dev=10.0)
bias_2 = init_bias(shape=[500], std_dev=10.0)
layer_2 = fully_connected(layer_1, weight_2, bias_2)

# create third layer (10 hidden nodes)
weight_3 = init_weight(shape=[500,10], std_dev=10.0)
bias_3 = init_bias(shape=[10], std_dev=10.0)
layer_3 = fully_connected(layer_2, weight_3, bias_3)

# create output layer (1 output value)
weight_4 = init_weight(shape=[10,1], std_dev=10.0)
bias_4 = init_bias(shape=[1], std_dev=10.0)
final_output = fully_connected(layer_3, weight_4, bias_4)


# define the loss function and the optimizer and initializing the model
loss = tf.reduce_mean(tf.abs(y_target - final_output))
optimizer = tf.train.AdamOptimizer(0.05)
train_step = optimizer.minimize(loss)

init = tf.global_variables_initializer()
sess.run(init)

# we will now train our model 10 times, store train and test los, select a random batch size, 
# and print the status every 1 generation

# initalize the loss vectors
loss_vec = []
test_loss = []
for i in range(10):
    # choose random indices for batch selection
    rand_index = np.random.choice(len(x_vals_train), size=batch_size)
    # get random batch
    rand_x = x_vals_train[rand_index]
    #rand_y = np.transpose(y_vals_train[rand_index])
    rand_y = y_vals_train[rand_index] #???????????
    # run the training step
    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})
    # get and store train loss
    temp_loss = sess.run(loss, feed_dict={x_data:rand_x, y_target:rand_y})
    loss_vec.append(temp_loss)
    # get and store test loss 
    #test_temp_loss = sess.run(loss, feed_dict={x_data:x_vals_test, y_target:np.transpose([y_vals_test])})
    test_temp_loss = sess.run(loss, feed_dict={x_data:x_vals_test, y_target:y_vals_test}) #???????
    test_loss.append(test_temp_loss)
    if(i+1) %1==0:
        print('Generation: '+str(i+1)+"". Loss = ""+str(temp_loss))

plt.plot(loss_vec, 'k-', label='Train Loss')
plt.plot(test_loss, 'r--', label='Test Loss')
plt.title('Loss Per generation ')
plt.xlabel('Generation')
plt.ylabel('Loss')
plt.legend(loc='upper right')
plt.show()
</code></pre>

<p>I commented most of it just so if someone stumbles here and needs some help they can understand whats going on.</p>
",1,18078,,1,30639,30639,2017-04-03T19:21:32.283,2017-04-03T19:21:32.283,1,3,,
87597,1,2021-01-06T17:21:34.203,1,232,<python><nlp><data-cleaning>,NLP data cleaning and word tokenizing,"<p>I am new to NLP and have a dataset that has a bunch of (social media) messages on which I would like to try some methods like latent Dirichlet allocation (LDA). First, I need to clean the data of things like punctuation, emojis, etc. I'm not sure how to go about doing this in the most efficient and accurate manner. My code right now is this:</p>
<pre><code>import pandas as pd
import re

class TopicModel():
    def __init__(self, data_path = &quot;data.csv&quot;):
        self.data_path = data_path
        self.data = pd.read_csv(self.data_path, low_memory=False)

    def clean_data(self):
        self.remove_message_na()
        self.remove_emojis()
        self.remove_punctuation_and_lower()
        self.remove_url()
        self.remove_empty_messages()

    def remove_message_na(self):
        self.data = self.data.loc[~pd.isna(self.data['message'])]

    def remove_emojis(self):
        self.data['message'] = self.data['message'].str.encode(&quot;ascii&quot;, &quot;ignore&quot;).str.decode(&quot;utf8&quot;)

    def remove_punctuation_and_lower(self):
        p = re.compile('''[!#?,.:&quot;;]''')
        self.data['cleaned_data'] = [p.sub(&quot;&quot;, ii).lower() for ii in self.data['message'].tolist()]

    def remove_empty_messages(self):
        self.data = self.data.loc[self.data['cleaned_data'] != &quot;&quot;]

    def remove_url(self):
        self.data = [re.sub(r&quot;http\S+&quot;, &quot;&quot;, ii) for ii in self.data['message'].tolist()]
</code></pre>
<p>I don't want to remove contractions, which is why I left out <code>'</code> from my punctuation list, but I think optimally, the contractions would be reformatted as two separate words. I also wonder about the other punctuation marks when dealing with social media data, e.g., <code>#</code>. I know this question is a bit general, but I'm wondering if there is a good python library for performing the kind of data-cleaning operations that I want, prior to perform topic analysis, sentiment analysis, etc. I'd also like to know which libraries can efficiently perform these data-cleaning operations on a pandas data frame.</p>
",1,87705,,1,103309,,2021-01-17T21:12:28.793,,1,1,,
28529,1,2018-03-02T17:12:28.610,0,1538,<python><predictive-modeling><evaluation>,Python - Calculate Cost profitability and benefit of the model,"<p>I've this code in Python in order to calculate the precision of my model and to print confusion matrix using Decision Trees Classifier:</p>

<pre><code>coef_gini = DecisionTreeClassifier(criterion = ""gini"", random_state = 100, max_depth = 3, min_samples_leaf = 5)
coef_gini.fit(training_features, training_target)

y_pred = coef_gini.predict(test_features)
y_pred

for name, importance in zip(training_features.columns, coef_gini.feature_importances_):
    print(name, importance)

print ( ""Train Accuracy using Decision Trees Classifier is : "", accuracy_score(training_target, coef_gini.predict(training_features)))
print ( ""Test Accuracy using Decision Trees Classifier is : "", accuracy_score(test_target, y_pred))
print ( ""Confusion matrix using Decision Trees Classifier is "", confusion_matrix(test_target, y_pred))
</code></pre>

<p>What is the cost matrix? Is this the money that company will lost for each wrong predictive target value? Anyone have an example?</p>

<p>Thanks!</p>
",1,28534,,0,24719,,2018-03-03T12:59:17.770,,1,1,,
35488,1,2018-07-15T13:34:57.340,0,50,<python><feature-engineering><encoding>,How to transform dictionary data into a string vector?,"<p>I have <code>key</code>,<code>value</code> data where each record is in a Python string.
An example record looks like this:</p>

<pre><code>record = {
    'first_name': 'john',
    'last_name': 'doe',
    'age': '50',
}
</code></pre>

<p>To encode this into a neural net, I would like to firs have this data as a string vector. A sample output is like this:</p>

<pre><code>""first_name john last_name doe age 50""
</code></pre>

<p>How can I make this transformation?</p>
",1,35491,,0,54395,,2018-07-15T13:51:15.760,,1,2,,
29840,1,2018-04-03T07:55:17.413,4,24734,<python><pandas><data-cleaning>,How to count grouped occurrences?,"<p>My dataset has 2 columns:</p>

<p>1) Gender( that has 1 or 2)</p>

<p>2) Rating1(That has 3 ratings (1,2,3))</p>

<pre><code>rating1: 1,2,3,3,2

gender: 2,1,2,2,1
</code></pre>

<p>I want output as:<a href=""https://i.stack.imgur.com/6QqIl.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6QqIl.png"" alt=""enter image description here""></a> </p>

<p>I have tried this: </p>

<pre><code>nutri.groupby(['Rating1','Gender']).nunique()
</code></pre>

<p>but I get an output which looks wrong.</p>
",1,29842,,4,49878,49878,2019-04-16T02:29:12.060,2019-04-16T02:29:12.060,1,1,,
47769,1,2019-03-22T05:14:42.583,1,1445,<python><regression><svm><hyperparameter>,What is the possible range of SVR parameters range?,"<p>I'm working on a regression problem. While tunning the Parameters of SVR I got the following values c=100, gamma= 10 and epsilon =100. For which I got 95 percent r-square. My question is what is the theoretical range of these parameters values.?</p>
",1,47771,,1,67993,,2019-03-22T12:51:43.503,,1,1,,
96807,1,2021-06-18T10:55:46.273,1,138,<python><random-forest>,Random forest and the number of samples,"<p>I am new to AI and ML and I am learning how does random forest work. I implemented a small experiment. I have got a dataset with 1.6M samples and about 120 features. It is a classification problem, the output, which I am trying to predict, is a binary value. I am using RandomForestClassifier from sklearn in python. I am aiming to maximize accuracy calculated by accuracy_score function. At first attempt there was a big difference between train and test set accuracy, e.g. 100% train and 50% test, so I came to conclusion that my forest is overfitting. I did hyper-params tuning and managed to reduce the difference. Eventually I ended up with the following set:</p>
<pre><code>model = RandomForestClassifier(
  n_estimators = 200,
  max_features = 11,
  max_depth = 30,
  min_samples_leaf = 30,
  n_jobs = 12,
  verbose = 1)
</code></pre>
<p>Then I played around with the number of samples and I got the following results: the more samples I use, the lower accuracy I get. Here are results for 2'500, 10'000 and 100'000 samples, on x axis the number of steps ahead I am trying to predict, on y axis accuracy, red is the train set, blue is the test set. It further decreases with more samples.</p>
<p><a href=""https://i.stack.imgur.com/iVcQ9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/iVcQ9.png"" alt=""enter image description here"" /></a>
<a href=""https://i.stack.imgur.com/zKCWF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zKCWF.png"" alt=""enter image description here"" /></a>
<a href=""https://i.stack.imgur.com/zY6bB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zY6bB.png"" alt=""enter image description here"" /></a></p>
<p>I find it counterintuitive, since I believe more data should improve quality, so I would like to first understand why is it the way like that. The only reason I can come up with is, since some of the features used clearly show a trend and are not stationary, the algorithm performs well on a subset of data, which is &quot;more stationary&quot;, than on the whole set, which exhibits more changeability. Would it be correct reasoning?</p>
<p>If so, how can I improve it? I can thing of a couple of ideas.</p>
<ol>
<li>De-trend features, which are not stationary. Seems to be against the general rule, which says decision trees do not require data preprocessing.</li>
<li>Just use a subset of the most recent data. Again intuitively the more data the better, so it sounds awkward.</li>
<li>Accept the fact that with these features this is the best I can get and look for different/more features.</li>
</ol>
<p>Thanks in advance.</p>
",1,96826,,1,119518,,2021-06-18T18:54:30.230,,2,1,,
21918,1,2017-08-02T20:37:06.863,7,19012,<python><markov>,What's a good Python HMM library?,"<p>I've looked at hmmlearn but I'm not sure if it's the best one. </p>
",1,21921,,7,33171,,2019-07-23T22:38:51.983,,1,1,2017-08-03T11:11:22.300,
45867,1,2019-02-20T10:44:55.693,2,2190,<python><keras><time-series><lstm><rnn>,How to reshape data for LSTM training in multivariate sequence prediction,"<p>I want to build an LSTM model for customer behaviour. It's the first time for me working on a timeseries, so some concepts are not clear to me at all.</p>

<p>My prediction problem is <strong>multidimensional</strong>, meaning that I also want to predict many informations associated to an action for each customer.</p>

<p>The dataset is currently shaped as a list of 2d padded arrays of one-hot encoded features (customer actions + other informations), for example:</p>

<pre><code>   customer_id               encoded_features
0   25464205      [[0,1,0],..,[1,1,1],[1,0,1],..,[1,0,1]]
1   56456574      [[0,1,1],..,[1,0,1],[1,0,1],..,[1,1,1]]
</code></pre>

<p>where each element in the encoded_features entries represents a specific timestep. </p>

<p>My idea here is to use keras <strong>input shape</strong> </p>

<pre><code>(n. customers, n. timesteps, length of features encoding)
</code></pre>

<p>In the example above it would be <code>(2,#timesteps,3)</code>.</p>

<p>I have two main questions:</p>

<ol>
<li><p>Is this whole setting rigth for the prediction of next single customer action? I would like to simply give a new sequence of features for a certain customer and predict <em>all features in the next timestep</em>. </p></li>
<li><p>I am thinking about splitting the data (according to a certain ratio) into sequential training and test sets, in order to test the trained model on <em>unseen feature vectors</em>. In the example above it would be:</p></li>
</ol>

<pre><code>  customer_id       X_train          y_train   
0   25464205       [[0,1,0],..]      [1,1,1]  
1   56456574       [[0,1,1],..]      [1,0,1] 

  customer_id       X_test           y_test    
0   25464205       [[1,0,1],..]      [1,0,1]
1   56456574       [[1,0,1],..]      [1,1,1]

</code></pre>

<p>Notice that X_train and X_test will generally contain all Train/Test events, except for the last one which has to be predicted.
Is this a correct interpretation?</p>
",1,45892,,2,67986,67986,2019-02-20T15:26:55.587,2019-02-20T13:23:34.940,1,2,,
16186,1,2017-01-08T17:22:36.960,2,1781,<python><optimization><xgboost>,Kelly Criterion in xgboost loss function,"<p>I have a model that predicts the outcome of ATP tennis matches. The quality of predictions varies, and I want to develop a second binary classification model that optimises the decision to bet (or not) based on a number of features about the match. Amongst the second model's features are the <strong>probabilities</strong> from the first, and archived bookmaker's <strong>odds</strong> for each match. The size of the bet is determined by the <a href=""https://en.wikipedia.org/wiki/Kelly_criterion"" rel=""nofollow noreferrer"">Kelly Criterion</a>. The training data has been classified such that all bets that would have won = 1, all losing bets = 0. I'm using <strong>xgboost</strong>.</p>

<p>I'm attempting to incorporate the Kelly Criterion into my xgb loss function but without success.</p>

<p>I've had a look at the custom objective example in the xgb demo. From my understanding, for xgb to <strong>maximise the expected value of the logarithmic bankroll</strong>, my objective function needs to return the first:</p>

<p>$$\frac{\partial}{\partial x}(p\: log(1 + bx)+(1-p)\:log(1-x))=\frac{-(b+1)\:p+b\:x+1}{(x-1)(b\:x+1)}$$</p>

<p>and second order derivatives:</p>

<p>$$\frac{\partial ^2}{\partial x^2}(p\: log(1 + bx)+(1-p)\:log(1-x))=-\frac{b^{2}p}{(bx+1)^{2}}-\frac{1-p}{(1-x)^{2}}$$</p>

<p>where:</p>

<ul>
<li>b is the net odds received on the wager (""b to 1""); that is, you could win \$b (on top of getting back your \$1 wagered) for a $1 bet</li>
<li>p is the probability of winning;</li>
</ul>

<p>I've also implemented my own cost function that calculates the profit and loss for each bet.</p>

<p>The code I have so far is below.</p>



<pre><code>import pandas as pd
import xgboost as xgb
import numpy as np
import StringIO #  ('import io' in python 3.x)
import requests


url_train = 'https://gist.githubusercontent.com/martinstaniforth/162b9691132f7099b4da08fd14defc39/raw/9372c5cac42b545ecde4200503b97f895e24cbfe/train.csv'
url_test = 'https://gist.githubusercontent.com/martinstaniforth/4445b884abea22d4ae238cda869b5e0e/raw/84d3dead9122a644f8d273e04b898920a8e5a811/test.csv'

train_content = requests.get(url_train).content
test_content = requests.get(url_test).content

train_df = pd.read_csv(StringIO.StringIO(train_content.decode('utf-8')), index_col='match_id')
test_df = pd.read_csv(StringIO.StringIO(test_content.decode('utf-8')), index_col='match_id')

train_target_df = train_df.reset_index(drop=True)[['bet_wins']]
train_df = train_df.reset_index(drop=True).drop(['bet_wins'], axis=1)

test_target_df = test_df.reset_index(drop=True)[['bet_wins']]
test_df = test_df.reset_index(drop=True).drop(['bet_wins'], axis=1)

odds_train = train_df['player_odds'].values - 1
probs_train = train_df['win_prob'].values

odds_test = test_df['player_odds'].values - 1
probs_test = test_df['win_prob'].values

dtrain = xgb.DMatrix(train_df.values, train_target_df.values)
dtest = xgb.DMatrix(test_df.values, test_target_df.values)

param = {
    'max_depth': 3,
    'eta': 0.05,
    'silent': 1,
    'n_estimators': 50,
    'seed': 366}
watchlist = [(dtest, 'eval'), (dtrain, 'train')]
num_round = 200


def kelly_loss(odds_train, probs_train, odds_test, probs_test):
    def logregobj(x, dmatrix):
        bet_outcome = dmatrix.get_label()

        odds = odds_train if len(bet_outcome) == len(odds_train) else odds_test
        probs = probs_train if len(bet_outcome) == len(probs_train) else probs_test

        y = -((odds + 1) * probs + odds * x + 1) / ((x - 1) * (odds * x + 1))
        grad = y - bet_outcome
        hess = -(np.power(odds, 2) * probs) / np.power(odds * x + 1, 2) - \
                (1 - probs) / np.power(1 - x, 2)

        return grad, hess

    return logregobj


def kelly_error(odds_train, probs_train, odds_test, probs_test):
    def evalerror(preds, dmatrix):
        bet_outcome = dmatrix.get_label()

        odds = odds_train if len(bet_outcome) == len(odds_train) else odds_test
        probs = probs_train if len(bet_outcome) == len(probs_train) else probs_test

        kelly_fraction = (probs * (odds + 1) - 1) / odds

        def value_bets(f):  # ignore any bets with a negative kelly fraction
            return 0 if f &lt; 0 else f

        kelly_fraction = np.array([value_bets(x) for x in kelly_fraction])

        profit = preds * kelly_fraction * odds
        loss = (1 - preds) * kelly_fraction

        total_profit = float(sum(profit - loss))

        return 'error', total_profit

    return evalerror

bst = xgb.train(
    param,
    dtrain,
    num_round,
    watchlist,
    kelly_loss(odds_train, probs_train, odds_test, probs_test),
    kelly_error(odds_train, probs_train, odds_test, probs_test))
</code></pre>

<p>When I execute the code, xgb does not update predictions.  I suspect the <strong>logregobj</strong> function is incorrect as I haven't fully understood its purpose. Can someone please assist in correctly implementing the <strong>Kelly Criterion</strong> in a binary classification model?  Training data is available in this <a href=""https://gist.github.com/martinstaniforth/162b9691132f7099b4da08fd14defc39"" rel=""nofollow noreferrer"">gist</a>, as referenced in the code.</p>

<p>Thanks in advance.</p>
",1,16260,,2,27724,,2019-06-27T21:29:34.400,,2,1,,
69210,1,2020-03-05T12:53:18.327,0,263,<python><nlp>,Generating text using NLP based on parameters,"<p>I want to generate some text based on the value of certain parameters. For instance, let's say I want to generate descriptions of video games. So, besides real descriptions as training data, I would like that the model takes in account the following parameters (for example) about the game:</p>

<ul>
<li>Violent: yes </li>
<li>Multiplatform: yes </li>
<li>Drugs: no</li>
</ul>

<p>So that if the game has drugs content, the output text has some phrase referring to it. </p>

<p>Is this possible? If so, how could I do it in Python? I was going to use LSTM neural networks in Tensorflow. </p>
",1,69213,,0,83066,,2020-03-05T14:30:50.430,,1,2,,
57953,1,2019-08-21T11:30:23.573,0,602,<machine-learning><python><classification><normalization>,What is the purpose of standardization in machine learning?,"<p>I'm just getting started with learning about K-nearest neighbor and am having a hard time understanding why standardization is required. Reading through, I came across a section saying</p>

<blockquote>
  <p>When independent variables in training data are measured in different
  units, it is important to standardize variables before calculating
  distance. For example, if one variable is based on height in cms, and
  the other is based on weight in kgs then height will influence more on
  the distance calculation.</p>
</blockquote>

<p>Since K nearest neighbor is just a comparison of distances apart, why does it matter if one of the variables has values of a larger range since it is what it is.</p>

<p>Considering 3 points A,B &amp; C with x,y co-ordinates (x in cm, y in grams) A(2,2000), B(8,9000) and C(10,20000), the ranking of the points as distance from origin for example (or any other point), will be the same whether the y values are in grams,pounds, tonnes or any other combinations of units for both x and y so where's the need to standardise. Every example or QA i see brushes through with the same statement of 'one variable influencing the other' without a real example of how this might occur. Again, how does one know when this influence is too much as to call for standardization.</p>

<p>Also,what exactly does standardization do to the values? One of the formulas does it by Xs = (X-mean)/(max-min) Where does such a formula come from and what is it really doing? Hopefully someone can offer me a simplified explanation or give me a link to a site or book that explains this in simple terms for beginners.</p>
",1,57957,,0,79879,,2019-08-21T16:42:43.370,,4,3,,
114959,1,2022-10-06T11:50:40.343,3,1364,<machine-learning><python><nlp><scikit-learn><text-classification>,Accuracy is getting worse after text pre processing,"<p>I'm working a multi-class text classification project.</p>
<p>After splitting the dataset into train and test datasets, I've applied the below function on the train dataset (AKA pre processing):</p>
<pre><code>STOPWORDS = set(stopwords.words('english'))

def clean_text(text):   
    # lowercase text
    text = text.lower() 
    
    # delete bad symbols
    text = re.sub(r&quot;(@\[A-Za-z0-9]+)|([^0-9A-Za-z \t])|(\w+:\/\/\S+)|^rt|http.+?&quot;, &quot;&quot;, text)  
  
    # delete stopwords from text
    text = ' '.join(word for word in text.split() if word not in STOPWORDS) 

    # Stemming the words
    text = ' '.join([stemmer.stem(word) for word in text.split()])
    
    return text
</code></pre>
<p>To my surprise, I've got much worst results (i.e. va_accuracy) applying on the train dataset rather than just &quot;do nothing&quot; (59% vs 69%)</p>
<p>I've literally commented out the apply line in the below section:</p>
<pre><code>all_data = dataset.sample(frac=1).reset_index(drop=True)
train_df, valid = train_test_split(all_data, test_size=0.2)

train_df['text'] = train_df['text'].apply(clean_text)

</code></pre>
<p>What am I missing?
How can it be that pre processing steps decreased accuracy?</p>
<p><strong>A bit more info</strong></p>
<p>I forgot to mention I'm using the below to tokenize the text:</p>
<pre><code>X_train = train.iloc[:, :-1]
y_train = train.iloc[:, -1:]
X_test = valid.iloc[:, :-1]
y_test = valid.iloc[:, -1:]

weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), 
                                            y=y_train.values.reshape(-1))
le = LabelEncoder()
le.fit(weights)
class_weights_dict = dict(zip(le.transform(list(le.classes_)), weights))


tokenizer = Tokenizer(num_words=vocab_size, oov_token='&lt;OOV&gt;')
tokenizer.fit_on_texts(X_train['text'])

train_seq = tokenizer.texts_to_sequences(X_train['text'])
train_padded = pad_sequences(train_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)

validation_seq = tokenizer.texts_to_sequences(X_test['text'])
validation_padded = pad_sequences(validation_seq, maxlen=max_length, padding=padding_type, truncating=trunc_type)
</code></pre>
<p>Later on I'm fitting all into the model as follows:</p>
<pre><code>model = Sequential()
model.add(Embedding(vocab_size, embedding_dim, input_length=train_padded.shape[1]))

model.add(Conv1D(48, len(GROUPS), activation='relu', padding='valid'))
model.add(GlobalMaxPooling1D())
model.add(Dropout(0.5))

model.add(Flatten())
model.add(Dropout(0.5))

model.add(Dense(len(GROUPS), activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

epochs = 100
batch_size = 32

history = model.fit(train_padded, training_labels, shuffle=True ,
                    epochs=epochs, batch_size=batch_size,
                    class_weight=class_weights_dict,
                    validation_data=(validation_padded, validation_labels),
                    callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001), 
                               EarlyStopping(monitor='val_loss', mode='min', patience=2, verbose=1),
                               EarlyStopping(monitor='val_accuracy', mode='max', patience=5, verbose=1)])
</code></pre>
",1,114989,,3,109113,109113,2022-10-11T14:43:23.383,2022-10-06T19:55:59.093,4,2,,
67884,1,2020-02-11T10:21:58.193,0,160,<machine-learning><python><deep-learning><machine-learning-model><text-generation>,predicting next jobtitle,"<p>I have a dataset of which has 30M rows each like [current_jobtitles, nextjobtitles].</p>
<pre><code>[['junior software programmer', 'senior software programmer'],
 ['senior software programmer', 'lead software programmer'],
 ['sales associate', 'regional sales associate']]
</code></pre>
<p>I want to build a deep learning model to predict the nextjobtitle when a currenttitle is given. Are there any ways that I could acheieve this using some deep learning model? if yes, what kind of model ?</p>
<p>Can we use any of the text generation models for this scenario ? I have seen <a href=""https://github.com/TannerGilbert/Tutorials/blob/master/Keras-Tutorials/4.%20LSTM%20Text%20Generation/Keras%20LSTM%20Text%20Generation.ipynb"" rel=""nofollow noreferrer"">some examples</a>, but I cannot relate to my solution for the problem. Any suggestions please ..!</p>
<h1>update:</h1>
<p>I have sequences of jobtitles in each row.</p>
<pre><code>[['junior programmer', 'senior programmer', 'lead programmer'],
 ['sales associate', 'sales regional associate', 'sales manager'],
 ['chairman', 'ceo'],
 ['associate', 'intern', 'junior', 'student']]
</code></pre>
<p>for the orginal data (in update) i have modifed data as above (before update) by just taking the nextjob title.
Can I train model with the original sequence data to predict the next jobtitle?
** - all the rows will be of different lengths.</p>
",1,67887,,0,49268,-1,2021-11-09T09:59:26.283,2020-06-16T11:08:43.077,1,2,,
30682,1,2018-04-23T11:38:56.540,3,617,<machine-learning><python><predictive-modeling><regression><data-cleaning>,What data treatment/transformation should be applied if there are a lot of outliers and features lack normal distribution?,"<p>I am solving for a <strong><code>regression</code></strong> use case using tensorflow's <code>DNNRegressor</code>. For EDA purpose, I referred to this <a href=""https://machinelearningmastery.com/quick-and-dirty-data-analysis-with-pandas/"" rel=""nofollow noreferrer"">post</a> and used <a href=""https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.boxplot.html"" rel=""nofollow noreferrer"">pandas boxplot</a> to plot my numerical predictors and target variable(here, <em>pid demand</em>) and <a href=""https://pandas.pydata.org/pandas-docs/stable/visualization.html#scatter-matrix-plot"" rel=""nofollow noreferrer"">scatter_matrix</a> for plotting the distributions and here are the results :
<a href=""https://i.stack.imgur.com/t6osb.png"" rel=""nofollow noreferrer"">predictor_target_boxplot</a> ; <a href=""https://i.stack.imgur.com/y7lwm.png"" rel=""nofollow noreferrer"">features_label_pdf_scatter_matrix</a>
.</p>

<p>I need help in interpreting these two plots, specifically on these fronts:</p>

<ol>
<li>How come the boxplot shows so many points beyond whiskers (~10%), can there be so many outliers in a dataset?</li>
<li>How do I handle those outliers?</li>
<li>Based on the second plot (feature, label pdf), should I normalize my features to exhibit Gaussian distribution? If so, why? </li>
</ol>
",1,30687,,3,50852,,2018-04-23T13:11:11.263,,1,4,,
66380,1,2020-01-13T06:25:17.410,2,1486,<machine-learning><python><multiclass-classification><data-science-model><multilabel-classification>,Multiclassification Error: NotFittedError: This MultiLabelBinarizer instance is not fitted yet,"<p>After picking the model, when I try to use it, I am getting error - </p>

<blockquote>
  <p>""NotFittedError: This MultiLabelBinarizer instance is not fitted yet.
  Call 'fit' with appropriate arguments before using this estimator.""</p>
</blockquote>

<pre><code>X = &lt;training_data&gt;
y = &lt;training_labels&gt;

# Perform multi-label classification on class labels.
mlb = MultiLabelBinarizer()
multilabel_y = mlb.fit_transform(y)

p = Pipeline([
('vect', CountVectorizer(min_df=min_df, ngram_range=ngram_range)),
('tfidf', TfidfTransformer()),
('clf', OneVsRestClassifier(clf))
])

# Use multilabel classes to fit the pipeline.
p.fit(X, multilabel_y)
</code></pre>
",1,66397,,2,88280,86339,2020-01-13T17:38:25.617,2020-01-13T17:38:25.617,1,13,,
5226,1,2015-02-25T01:07:14.717,85,139501,<machine-learning><python><scikit-learn><random-forest><decision-trees>,strings as features in decision tree/random forest,"<p>I am doing some problems on an application of decision tree/random forest. I am trying to fit a problem which has numbers as well as strings (such as country name) as features. Now the library, <a href=""http://scikit-learn.org"" rel=""noreferrer"">scikit-learn</a> takes only numbers as parameters, but I want to inject the strings as well as they carry a significant amount of knowledge.</p>

<p>How do I handle such a scenario?</p>

<p>I can convert a string to numbers by some mechanism such as hashing in Python. But I would like to know the best practice on how strings are handled in decision tree problems.</p>
",1,5229,,85,8409,26686,2020-10-29T06:16:43.570,2019-10-02T14:32:28.693,6,2,,
62316,1,2019-10-28T13:12:53.287,3,3553,<machine-learning><python><keras><transfer-learning><vgg16>,How to fine tuning VGG16 with my own layers,"<p>I want to maintain the first 4 layers of vgg 16 and add the last layer. I have this example:</p>
<pre class=""lang-py prettyprint-override""><code>vgg16_model = VGG16(weights=&quot;imagenet&quot;, include_top=True)

# (2) remove the top layer
base_model = Model(input=vgg16_model.input, 
                   output=vgg16_model.get_layer(&quot;block5_pool&quot;).output) #I wanna cut all layers after 'block1_pool'

# (3) attach a new top layer
base_out = base_model.output
base_out = Reshape(25088,)(base_out) 
top_fc1 = Dropout(0.5)(base_out)
top_preds = Dense(1, activation=&quot;sigmoid&quot;)(top_fc1)

# (4) freeze weights until the last but one convolution layer (block4_pool)
for layer in base_model.layers[0:4]:
    layer.trainable = False

# (5) create new hybrid model
model = Model(input=base_model.input, output=top_preds)
</code></pre>
<p>So in this example he is cutting from the 'block5_pool', and I want to cut from 'block1_pool' but if I only change to block1_pool it throws this error:</p>
<pre><code>data_format = value.lower()

AttributeError: 'int' object has no attribute 'lower'
</code></pre>
<p>So how could I change it to cut in block1_pool, and then add my own dense layers?</p>
<h2>FULL CODE</h2>
<pre><code>#import tensorflow as tf
import cv2
import os
import numpy as np

from keras.layers.core import Flatten, Dense, Dropout, Reshape
from keras.models import Model
from keras.layers import Input, ZeroPadding2D, Dropout
from keras import optimizers
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import EarlyStopping

from keras.applications.vgg16 import VGG16

TRAIN_DIR = 'train/'
TEST_DIR = 'test/'
v = 'v/'
BATCH_SIZE = 32
NUM_EPOCHS = 5

def crop_img(img, h, w):
    h_margin = (img.shape[0] - h) // 2 if img.shape[0] &gt; h else 0
    w_margin = (img.shape[1] - w) // 2 if img.shape[1] &gt; w else 0

    crop_img = img[h_margin:h + h_margin,w_margin:w + w_margin,:]

    return crop_img

def subtract_gaussian_blur(img):

    return cv2.addWeighted(img, 4, cv2.GaussianBlur(img, (0, 0), 5), -4, 128)

def ReadImages(Path):
    LabelList = list()
    ImageCV = list()
    classes = [&quot;nonPdr&quot;, &quot;pdr&quot;]

    # Get all subdirectories
    FolderList = [f for f in os.listdir(Path) if not f.startswith('.')]
    
    # Loop over each directory
    for File in FolderList:
        for index, Image in enumerate(os.listdir(os.path.join(Path, File))):
            # Convert the path into a file
            ImageCV.append(cv2.resize(cv2.imread(os.path.join(Path, File) + os.path.sep + Image), (224,224)))
            #ImageCV[index]= np.array(ImageCV[index]) / 255.0
            LabelList.append(classes.index(os.path.splitext(File)[0])) 
            
            img_crop = crop_img(ImageCV[index].copy(), 224, 224)
            
            ImageCV[index] = subtract_gaussian_blur(img_crop.copy())
            
    return ImageCV, LabelList


data, labels = ReadImages(TRAIN_DIR)
valid, vlabels = ReadImages(TEST_DIR)

vgg16_model = VGG16(weights=&quot;imagenet&quot;, include_top=True)

# (2) remove the top layer
base_model = Model(input=vgg16_model.input, 
                   output=vgg16_model.get_layer(&quot;block1_pool&quot;).output)
print(base_model)
# (3) attach a new top layer
base_out = base_model.output
base_out = Reshape(25088,)(base_out)
top_fc1 = Dropout(0.5)(base_out)
# output layer: (None, 5)
top_preds = Dense(1, activation=&quot;sigmoid&quot;)(top_fc1)

# (4) freeze weights until the last but one convolution layer (block4_pool)
for layer in base_model.layers[0:4]:
    layer.trainable = False

# (5) create new hybrid model
model = Model(input=base_model.input, output=top_preds)
    
# (6) compile and train the model
sgd = SGD(lr=1e-4, momentum=0.9)
model.compile(optimizer=sgd, loss=&quot;binary_crossentropy&quot;, metrics=[&quot;accuracy&quot;])

data = np.asarray(data)
valid = np.asarray(valid)

data = data.astype('float32')
valid = valid.astype('float32')

data /= 255
valid /= 255
labels = np.array(labels)

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True)

# compute quantities required for featurewise normalization
# (std, mean, and principal components if ZCA whitening is applied)
datagen.fit(data)
mean = datagen.mean  
std = datagen.std

print(mean, &quot;mean&quot;)
print(std, &quot;std&quot;)

es = EarlyStopping(monitor='val_loss', verbose=1)

# fits the model on batches with real-time data augmentation:
model.fit_generator(datagen.flow(data, np.array(labels), batch_size=32), 
                    steps_per_epoch=len(data) / 32, epochs=15,
                    validation_data=(valid, np.array(vlabels)),
                    nb_val_samples=72, callbacks=[es])


model.save('model.h5')
</code></pre>
<h2>FULL ERROR</h2>
<pre><code>    base_out = Reshape(25088,)(base_out)

    self.target_shape = tuple(target_shape)

TypeError: 'int' object is not iterable
<span class=""math-container"">```</span>
</code></pre>
",1,62324,,3,80406,-1,2019-10-28T18:41:37.237,2020-06-16T11:08:43.077,1,2,,
32205,1,2018-05-26T17:09:15.193,1,2382,<machine-learning><python><neural-network><deep-learning><cnn>,Resizing images for training with Mobilenets,"<p>I have a script to download images, but the images are of different resolutions so I have written a script to shrink the image. I have two options:</p>

<pre><code>size=(224,224)
</code></pre>

<p>with cv2</p>

<pre><code>cv2.resize(img,size,interpolation=cv2.INTER_AREA)
</code></pre>

<p>with PIL</p>

<pre><code>img.thumbnail(size,Image.ANTIALIAS)
</code></pre>

<p>after saving them I see cv2 doesn't maintain the original ratio where as PIL maintains the ratio.</p>

<p>My question :</p>

<ol>
<li><p>Maintaining aspect ratio is important or not.</p></li>
<li><p>If yes <code>(224,224)</code> is a good choice or should I set it to higher
resolution.</p></li>
</ol>

<p>Sorry if the question is naive, I am new to image processing.</p>
",1,32207,,1,44673,28175,2018-05-26T18:23:08.137,2018-05-26T18:23:08.137,1,1,,
109366,1,2022-03-25T22:03:02.697,0,342,<python><pandas>,"TypeError: 'int' object is not subscriptable, On making header = None when reading a csv file","<p>As soon as I add header = None, I get the error <code>TypeError: 'int' object is not subscriptable</code>. Any help on how to solve this without removing <code>header = None</code> from reader?</p>
<p>Code:</p>
<pre><code>reader = pd.read_csv('counts.csv', header = None)

X3 = []
y3 = []
for row in reader:
    label = row[2]
    if len(label) &gt; 0 and label.find(',') == -1:
        y3.append(label)
y3 = np.asarray(y3)
encoder = LabelEncoder()
encoder.fit(y3)
encoded_y = encoder.transform(y3)
counts = np.bincount(encoded_y)
print(counts)
fig, ax = plt.subplots()
plt.bar(list(range(6)), counts)
ax.set_xticklabels(('', 'plasma', 'lymphocyte', 'epithelial', 'neutrophil','eosinophil','connective'))
ax.set_ylabel('Counts')
</code></pre>
<p>Error:</p>
<pre><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-97-53828df7d817&gt; in &lt;module&gt;
      7 y3 = []
      8 for row in reader:
----&gt; 9     label = row[2]
     10     if len(label) &gt; 0 and label.find(',') == -1:
     11         y3.append(label)

TypeError: 'int' object is not subscriptable

</code></pre>
",1,109380,,0,133758,75157,2022-03-26T13:01:22.197,2022-03-25T22:20:24.577,1,1,2022-04-12T22:05:14.617,
64521,1,2019-12-10T02:33:10.083,1,21096,<python>,Why I get AttributeError: 'float' object has no attribute '3f'?,"<p>I am getting this error:</p>

<pre><code>AttributeError: 'float' object has no attribute '3f'
</code></pre>

<p>I don't understand why I am getting it, I am following the example straight from the book ""applied text analysis""</p>

<p>The chunk of code in python is:</p>

<pre><code>total = sum(words.values())
for gender, count in words.items():
pcent = (count / total) * 100
nsents = sents[gender]
print(
""{0.3f}% {} ({} sentences)"".format(pcent, gender, nsents)
)
</code></pre>

<p>I see that <strong>pcent</strong> clearly will return a float, why the author tries to apply .3f what  am I missing?</p>
",1,64522,,1,86676,,2020-02-06T10:18:50.160,,2,5,,
29938,1,2018-04-05T14:14:12.703,4,4799,<python><nlp><fuzzy-logic>,Plagiarism detection with Python,"<h1>Background</h1>
<p>Using Python, I need to score the existence of a quote, containing around 2-7 words, a longer text. The quote doesn't have to match the text precisely, but similar words should have the <em>same order</em>.</p>
<p>For example, given the following <strong>long text</strong>:</p>
<blockquote>
<p>The most beautiful things in the world cannot be seen or touched, they are felt with the heart</p>
</blockquote>
<p>The following quotes should be scored <strong>high</strong> (say, above 80 / 100):</p>
<blockquote>
<p>The beautiful thing in our world</p>
<p>World cannot see</p>
<p>They feel with the heart</p>
</blockquote>
<p>Since they are not precise, but they preserve the order.</p>
<p>While, on the other hand, these quotes should be scored <strong>lower</strong> (say, below 50 / 100):</p>
<blockquote>
<p>The beautiful heart cannot be felt or seen</p>
<p>They are the most seen in the world</p>
<p>These words don't even appear on this text</p>
</blockquote>
<p>Because (the first 2) appear entirely in the text, but do not preserve the order.</p>
<h1>The problem</h1>
<p>This task cannot be accomplished by simply checking the existence of each word in the text. I don't know which algorithm fits best for this task.</p>
<h1>What I have tried</h1>
<p>Most of the functions in <code>fuzzywuzzy</code> (<code>partial_token_sort_ratio</code>, <code>token_sort_ratio</code> and etc) scored the later terms higher.
<code>partial_ratio</code> did score the earlier terms higher, but the quote</p>
<blockquote>
<p>These words don't even appear on this text</p>
</blockquote>
<p>Got 52 / 100 which is unreasonably high.</p>
<h1>My question</h1>
<p>How can I use python to score the existence of short quotes in longer texts as mentioned above?</p>
",1,36114,,4,10972,-1,2019-10-11T16:11:16.550,2020-06-16T11:08:43.077,1,1,,
21994,1,2017-08-05T22:28:15.163,2,701,<python><pandas><csv><tableau>,Breaking down a column in Pandas into a separate CSV for display in Tableau,"<p>My data is coming from a CSV, which should be visualized in Tableau.</p>

<p>However, the data contains the column <code>category_list</code>, which consists of values separated by a vertical bar (<code>|</code>).</p>

<p>Since Tableau can't handle arrays inside of attributes, I used Python (Pandas) to load the CSV and manipulate the data:</p>

<pre><code>import pandas as pd
companies = pd.read_csv(""companies.csv"")
</code></pre>

<p>I assume that the <code>category_list</code> column needs to be broken down and stored into another CSV (containing the <code>permalink</code> (unique ID) and <code>category</code> pairs).</p>

<p>Something like this:</p>

<pre><code>permalink,category
/organization/-qounter,Application Platforms
/organization/-qounter,Real Time
/organization/-qounter,Social Network Media
/organization/-the-one-of-them-inc-,Apps
/organization/-the-one-of-them-inc-,Games
/organization/-the-one-of-them-inc-,Mobile
/organization/1-4-all,Entertainment
/organization/1-4-all,Games
/organization/1-4-all,Software
/organization/1-800-publicrelations-inc-,Internet
/organization/1-800-publicrelations-inc-,Marketing
/organization/1-800-publicrelations-inc-,Media
/organization/1-800-publicrelations-inc-,Public Relations
/organization/1-mainstream,Apps
/organization/1-mainstream,Cable
/organization/1-mainstream,Distribution
/organization/1-mainstream,Software
...
</code></pre>

<p>How to achieve it?</p>

<p>Excerpt of the original CSV:</p>

<pre><code>permalink,category_list,...
/organization/-qounter,Application Platforms|Real Time|Social Network Media,...
/organization/-the-one-of-them-inc-,Apps|Games|Mobile,...
/organization/1-4-all,Entertainment|Games|Software,...
/organization/1-800-publicrelations-inc-,Internet|Marketing|Media|Public Relations,...
/organization/1-mainstream,Apps|Cable|Distribution|Software,...
...
</code></pre>
",1,21999,,2,13235,,2018-11-10T10:18:11.587,,2,2,,
48990,1,2019-04-09T19:52:28.847,0,763,<python><visualization><matplotlib>,What's the best way to plot a bar graph with large numeric difference in values?,"<p>I'm graphing the value of the Ruble against the US Dollar in the 1990s. There was hyper-inflation from 1992-1997 (where the ""y"" values expanded from 125 to 6000). On Jan 1st 1998, the government revalued the money to 5. Since then the number has trended upward but has only reached 70 or so. </p>

<p>This creates a problem in my bar or line graph. You can't understand the low values after the stabilization. Any suggestions to help with this discrepancy when viewing the whole dataset in one graph?</p>

<p><a href=""https://i.stack.imgur.com/O7Vhd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/O7Vhd.png"" alt=""Bar graph showing precipitous drop in values and therefore affecting the scale of the graph.""></a></p>

<p>Plotting using matplotlib</p>
",1,48997,,0,71212,55122,2021-02-26T15:50:19.793,2021-02-26T15:50:19.793,1,3,,
30689,1,2018-04-23T13:29:03.863,6,4163,<python><apache-spark><pyspark>,What are the alternatives to Python + Spark (pyspark)?,"<p>I like Python, and I like Spark, but they don't fit very well together.  In particular,</p>
<ol>
<li>it is very hard to use python functions in spark (have to create JVM binding for function in python)</li>
<li>it is hard to debug pyspark, with py4j in the middle</li>
</ol>
<p>So I wonder if there are any alternatives to pyspark that supports python natively instead of via an adapter layer?</p>
<p><a href=""https://stackoverflow.com/a/34412182/842860"">Reference</a></p>
",1,38139,,6,28423,98307,2020-08-11T08:18:51.347,2020-08-11T08:18:51.347,2,1,,
12321,1,2016-06-21T10:05:08.587,238,336451,<python><scikit-learn>,What's the difference between fit and fit_transform in scikit-learn models?,"<p>I do not understand the difference between the <code>fit</code> and <code>fit_transform</code> methods in scikit-learn. Can anybody explain simply why we might need to transform data?</p>
<p>What does it mean, fitting a model on training data and transforming to test data? Does it mean, for example, converting categorical variables into numbers in training and transforming the new feature set onto test data?</p>
",1,12346,,238,15064,43000,2021-07-08T08:09:09.163,2021-07-08T08:09:09.163,10,4,,
81807,1,2020-09-16T14:08:42.860,0,75,<machine-learning><python><neural-network><deep-learning><cnn>,How to handle images of different sizes that are smaller than the input layer of a deep learning model?,"<p>I am performing human awareness detection and have trained my model using transfer learning with MobileNetV2. This model expects a tensor of dimension [Null,224,224,3].</p>
<p>I have applied face detection using BlazeFace which uses an input of [128,128,3] on the input video stream and cropped the detected faces in order to send the cropped faces to my custom model but I am not sure what to do as the cropped images are all of varying sizes and smaller than what my model expects.</p>
<p><strong>Example of a cropped face tensor</strong></p>
<pre><code>Array [
  1,
  43,
  111,
  3,
]
</code></pre>
",1,81843,,0,104392,,2020-09-17T04:46:46.163,,1,1,,
106420,1,2021-12-25T12:03:11.863,2,349,<machine-learning><python><scikit-learn><r-squared>,SKlearn PolynomialFeatures R^2 score,"<p>I'm trying to create a linear regression model with use of PolynomialFeatures. But when I evaluate it, I get really strange scores. I know that R^2 can be applied to this model and I think I've trying everything. I'd really apricate a good advice. Here is my code.</p>
<pre><code>X = df_all[['Elevation_gain', 'Distance']] 
y = df_all['Avg_tempo_in_seconds']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)

for n in range(2,10,1):
 
    poly_feat = PolynomialFeatures(degree=n, include_bias = True)

    X_poly_train = poly_feat.fit_transform(X_train)
    X_poly_test = poly_feat.transform(X_test)
    

    lin_reg_2 = LinearRegression()
    lin_reg_2.fit(X_poly_train, y_train)
    test_pred_2 = lin_reg_2.predict(X_poly_test)

    #testset evaluation
    r2 = metrics.r2_score(y_true = y_test, y_pred = test_pred_2)
    mse = metrics.mean_squared_error(y_true = y_test, y_pred = test_pred_2)
    print(round(r2,2))
    #print(round(mse,2))
</code></pre>
<p>And this is the output I get:</p>
<pre><code>0.36
-3.99
-59.96
-1299.38
-627.37
-1773329.36
-19673802.94
-23125681.65
</code></pre>
<p>Here is the sample data:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th>Elevation_gain</th>
<th>Distance</th>
<th>Avg_tempo_in_seconds</th>
</tr>
</thead>
<tbody>
<tr>
<td>70</td>
<td>6,13</td>
<td>290.1</td>
</tr>
<tr>
<td>135</td>
<td>9.27</td>
<td>301.0</td>
</tr>
<tr>
<td>10</td>
<td>4.94</td>
<td>287.5</td>
</tr>
<tr>
<td>270</td>
<td>15.74</td>
<td>310.2</td>
</tr>
<tr>
<td>120</td>
<td>8.11</td>
<td>298.5</td>
</tr>
</tbody>
</table>
</div>",1,106567,,2,130252,130252,2021-12-30T14:56:53.270,2021-12-30T13:35:57.847,2,3,,
33766,1,2018-06-28T12:52:40.890,0,1689,<python><bigdata><numpy>,How to compare fast the value with the ones of neighbours in a 3D array,"<h2>Question:</h2>

<p>I want to compare every item in a 3D array with its first neighborhoods. It's really slow when I have a 500x500x500 (e.g. with only values of 0, 1, 2) ndarray. I post the <strong>principle lines</strong> here:</p>

<pre><code>import numpy as np

# Create a list to stock all the neighbours' coordinations of the voxel wanted 
def check_neighbor(array, x, y, z):
   #top
   t = array[x, y , z + 1]
   #down
   d = array[x, y , z - 1]
   #left
   l = array[x, y - 1 , z]
   #right
   r = array[x, y + 1 , z]
   #front
   f = array[x - 1, y , z]
   #back
   b = array[x + 1, y , z]
   return [t, d, l, r, f, b]

# Check the voxel with all its neighborhood
def compare_neighbor(array, Value2match, Value2Bmatched):
   for index in np.argwhere(array==Value2match)
      output[index] = 1 if Value2BMatched in checkneighbor(array, index[0],index[1], index[2]) else 0 
   return output

# Main
array = np.random.randint(3, shape=(500, 500, 500))
output = compare_neighbor(array, 1, 2)
</code></pre>

<p>This code take me hours only for the n=1 neighbour! Is there an efficient way which can also check the 2, 3... nearest neighbours? Can somebody help me?</p>

<h1>Solution 1:</h1>

<p>Based on <strong>jayprich</strong>'s answer and <strong>n1k31t4</strong>'s comments, I fused the both function into one and replace the <code>argwhere()</code> by <code>where()</code>. The <strong>advantage</strong> of this code is that we <strong>don't iterate voxel by voxel</strong> but do it in a vectorized way:</p>

<pre><code>import numpy as np
# Build a helper function to SHIFT(not roll) a 3Darray
def shift_helper(array, neib_value, shift=0, axis=0):
    #Roll the 3D array along axis with certain unity
    _array = np.roll(array == neib_value, shift=shift, axis=axis)

    # Cancel the last/first slice shifted to the first/last slice
    if axis == 0:
        if shift &gt;= 0:
            _array[:1, :, :] = 0
        else:
            _array[-1:, :, :] = 0
        return _array
    elif axis == 1:
        if shift &gt;= 0:
            _array[:, :1, :] = 0
        else:
            _array[:, -1:, :] = 0
        return _array
    elif axis == 2:
        if shift &gt;= 0:
            _array[:, :, :1] = 0
        else:
            _array[:, :, -1:] = 0
        return _array


def compneib(array, that_value, neib_value):
    _array = np.zeros(array.shape)
    _array[np.where((array == that_value)
                    &amp; (shift_helper(array, neib_value, shift=-1, axis=0)
                    | shift_helper(array, neib_value, shift=1, axis=0)
                    | shift_helper(array, neib_value, shift=-1, axis=1)
                    | shift_helper(array, neib_value, shift=1, axis=1)
                    | shift_helper(array, neib_value, shift=-1, axis=2)
                    | shift_helper(array, neib_value, shift=1, axis=2)
                    ))] = 1
    return _array

# Main
array = np.random.randint(3, shape=(500, 500, 500))
output = compneib(array, 1, 2)
</code></pre>

<h1>Solution 2:</h1>

<p>If there would still be a faster way.</p>
",1,33771,,0,53928,53928,2018-06-29T12:15:16.727,2018-06-29T12:15:16.727,1,4,,
41459,1,2018-11-20T13:22:07.777,5,184,<python><scraping>,Capture pattern in python,"<p>I would like to capture the following pattern using python
   <code>anyprefix-emp-&lt;employee id&gt;_id-&lt;designation id&gt;_sc-&lt;scale id&gt;</code></p>

<p>Example data</p>

<pre><code>strings = [""humanresourc-emp-001_id-01_sc-01"",""itoperation-emp-002_id-02_sc-12"",""Generalsection-emp-003_id-03_sc-10""]
</code></pre>

<p>Expected Output:</p>

<pre><code>[('emp-001', 'id-01', 'sc-01'), ('emp-002', 'id-02', 'sc-12'), ('emp-003', 'id-03', 'sc-10')]
</code></pre>

<p>How can i do it using python.</p>
",1,41493,,5,62077,,2018-11-20T23:48:31.643,,3,1,,
104597,1,2021-11-28T18:56:28.317,0,1100,<python><scikit-learn>,I am getting the error in SimpleImputer,"<pre><code>from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values= np.NaN, strategy='most_frequent')
imputer = imputer.fit(cat_vars[:,2:4])
cat_vars[:,2:4] = imputer.transform(cat_vars[:,2:4])
</code></pre>
<p>The above is my code for replacing the missing values with the most frequent value in the column index starting from 2 to 3.I am getting the below error. Please suggest why this error is coming. Thanks in advance.</p>
<pre><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-91-48eaa0ca1d43&gt; in &lt;module&gt;
      2 from sklearn.impute import SimpleImputer
      3 imputer = SimpleImputer(missing_values= np.NaN, strategy='most_frequent')
----&gt; 4 imputer = imputer.fit(cat_vars[:,2:4])
      5 cat_vars[:,2:4] = imputer.transform(cat_vars[:,2:4])

TypeError: 'SimpleImputer' object is not subscriptable
</code></pre>
",1,104618,,0,128293,92050,2021-11-29T10:33:00.573,2021-11-28T20:25:30.313,1,3,2021-12-31T19:30:41.540,
88851,1,2021-02-03T00:46:29.003,0,1059,<python><visualization><matplotlib>,How do I print full date in the x axis of the line plot here?,"<p><a href=""https://i.stack.imgur.com/agkDW.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/agkDW.png"" alt=""enter image description here"" /></a></p>
<p>My code:</p>
<pre><code>import matplotlib.pyplot as plt
plt.style.use('ggplot')
plt.rcParams[&quot;figure.figsize&quot;] = [12,6]
def time_series(start, end):
    time_series_df = df[['Date', 'Value']][(df['Date'] &gt;= start) &amp; (df['Date'] &lt;= end)]
    x = time_series_df.Date
    y = time_series_df.Value
    plt.plot(x,y)
    plt.xlabel('Time')
    plt.ylabel('PM2.5 Value')
    plt.title('PM2.5 Time Series')
    return plt.show();

time_series('2014','2019')
</code></pre>
",1,88950,,0,108233,29169,2021-02-05T02:04:30.940,2021-02-03T01:58:27.500,1,4,,
80069,1,2020-08-10T15:38:21.687,5,847,<python><classification><xgboost>,Why Does XGBoost Keep One Feature at High Importance?,"<p>I am training an XGboost model for binary classification on around 60 sparse numeric features. After training, the feature importance distribution has one feature with importance &gt; 0.6, and all the rest with importance &lt;0.05.</p>
<p>I remove the most important feature, and retrain. The same distribution forms; the most important feature has importance &gt; 0.6, and the rest have &lt; 0.05. I continued to remove the most important feature and retrain, remove and retrain, remove and retrain, etc. My f1-score started to drop, but every time there was one feature more important than the rest.</p>
<p>Also worth noting, when I removed the most important feature and retrained, the new most important feature was not the second most important feature from the previous training.</p>
<p>I cannot explain this behaviour intuitively. Does anyone know why this pattern arises?</p>
",1,80293,,5,103096,,2020-08-14T15:55:11.930,,1,2,,
677,1,2014-07-05T15:01:43.940,7,4748,<python><pandas><scikit-learn>,Struggling to integrate sklearn and pandas in simple Kaggle task,"<p>I'm trying to use the sklearn_pandas module to extend the work I do in pandas and dip a toe into machine learning but I'm struggling with an error I don't really understand how to fix.</p>

<p>I was working through the following dataset on <a href=""https://www.kaggle.com/c/data-science-london-scikit-learn/data"" rel=""noreferrer"">Kaggle</a>.</p>

<p>It's essentially an unheadered table (1000 rows, 40 features) with floating point values.</p>

<pre><code>import pandas as pdfrom sklearn import neighbors
from sklearn_pandas import DataFrameMapper, cross_val_score
path_train =""../kaggle/scikitlearn/train.csv""
path_labels =""../kaggle/scikitlearn/trainLabels.csv""
path_test = ""../kaggle/scikitlearn/test.csv""

train = pd.read_csv(path_train, header=None)
labels = pd.read_csv(path_labels, header=None)
test = pd.read_csv(path_test, header=None)
mapper_train = DataFrameMapper([(list(train.columns),neighbors.KNeighborsClassifier(n_neighbors=3))])
mapper_train
</code></pre>

<p>Output:</p>

<pre><code>DataFrameMapper(features=[([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
       n_neighbors=3, p=2, weights='uniform'))])
</code></pre>

<p>So far so good. But then I try the fit</p>

<pre><code>mapper_train.fit_transform(train, labels)
</code></pre>

<p>Output:</p>

<pre><code>---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-6-e3897d6db1b5&gt; in &lt;module&gt;()
----&gt; 1 mapper_train.fit_transform(train, labels)

//anaconda/lib/python2.7/site-packages/sklearn/base.pyc in fit_transform(self, X, y,     **fit_params)
    409         else:
    410             # fit method of arity 2 (supervised transformation)
--&gt; 411             return self.fit(X, y, **fit_params).transform(X)
    412 
    413 

//anaconda/lib/python2.7/site-packages/sklearn_pandas/__init__.pyc in fit(self, X, y)
    116         for columns, transformer in self.features:
    117             if transformer is not None:
--&gt; 118                 transformer.fit(self._get_col_subset(X, columns))
    119         return self
    120 

TypeError: fit() takes exactly 3 arguments (2 given)`
</code></pre>

<p>What am I doing wrong? While the data in this case is all the same, I'm planning to work up a workflow for mixtures categorical, nominal and floating point features and sklearn_pandas seemed to be a logical fit.</p>
",1,5834,,7,974,,2015-05-27T03:16:56.403,,2,2,,
104808,1,2021-12-06T03:32:46.493,1,347,<machine-learning><python><classification><evaluation>,"Select one best model according to accuracy, precision, recall, f1 score and roc score","<p>I have two classifiers that classify the same dataset with these results:</p>
<pre><code> Model        | Accuracy| Precision| Recall | F1 Score| ROC Score
--------------| --------| ---------|--------|---------|---------
 Random Forest| 90%     | 0.61     | 0.7    | 0.64    | 0.81      
 XGBoost      | 91%     | 0.70     | 0.67   | 0.66    | 0.80 

</code></pre>
<p>I am not sure but It seems to me XGBoost is the best model since it has 91% accuracy and higher precision and F1 score than Random Forest. <strong>Can anyone please help me to choose the best model from the above result?</strong></p>
",1,104843,,1,128565,128565,2021-12-07T06:26:04.187,2021-12-06T03:46:38.027,1,5,,
27386,1,2018-02-02T14:27:06.287,0,1010,<python><clustering><visualization><recommender-system>,Visualizing item similarities,"<p>I have an implicit dataset. It contains which user click which item. I'm doing collaborative filtering and finally i get the item similarites. So now i have data like;</p>

<pre><code>Item - SimilarItem - SimilarityValue
A    - C           - 0.12
A    - R           - 0.42
A    - Y           - 0.34
A    - J           - 0.62
B    - A           - 0.16
B    - Y           - 0.83
C    - J           - 0.23
</code></pre>

<p>or </p>

<pre><code>Item  --  Similarities
A     --  C,R,Y,J
B     --  A,Y
C     --  J,A,D
</code></pre>

<p>As i know all the relations between 40K item, can i turn this into a nice visualization showing some of them get together at somewhere and someothers are elsewhere. I can do this either with python or some javascript library.</p>

<p>What should be the way of doing this? Can you show me some examples?</p>
",1,27387,,0,44190,44190,2018-02-07T10:54:08.123,2018-02-07T10:54:08.123,1,1,2018-02-04T15:23:10.993,
82314,1,2020-09-28T08:52:02.073,2,344,<python><time-series><dataset><automation>,Automation of finding a starting point of measurement in a large dataset,"<p>I am looking for a way to automatically find a starting point of rising in my signal in Python. The data are collected with the frequency 10k (0.0001 s each) so the differences between each point are very small, lost in the noise. I found this point (black dot) manually using data analysis software before but I have multiple files and the manual process is not gonna work well. I was trying to think of something to do with derivative (red dots) or rolling variance (green dots) but it's a dead end for me now. Here's how manual point was chosen:</p>
<p><a href=""https://i.stack.imgur.com/mapsn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mapsn.png"" alt=""enter image description here"" /></a></p>
<p>I pick a point that looks to me that is the closest one to rising signal but is still in the middle of noise before rising. Chosing it manually is just my rough estimation but I don't mind being one or two points wrong from the &quot;correct&quot; starting rising point. I will use it to offset my signal so that rising starts more or less at X = 0.</p>
<p>And now I wanted to find it using python. The full signal looks like this:</p>
<p><a href=""https://i.stack.imgur.com/p84tr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/p84tr.png"" alt=""enter image description here"" /></a></p>
<p>The derivative:</p>
<p><a href=""https://i.stack.imgur.com/KHaXg.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/KHaXg.png"" alt=""enter image description here"" /></a></p>
<p>The rolling variance:</p>
<p><a href=""https://i.stack.imgur.com/yacbH.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yacbH.png"" alt=""enter image description here"" /></a></p>
<p>So they're all close to the interest point (black dot) but I don't know what to do with them next. If I change the limits it all looks like this:</p>
<p><a href=""https://i.stack.imgur.com/NPaeT.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NPaeT.png"" alt=""enter image description here"" /></a>
<a href=""https://i.stack.imgur.com/PoOyr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PoOyr.png"" alt=""enter image description here"" /></a>
<a href=""https://i.stack.imgur.com/bQRE7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bQRE7.png"" alt=""enter image description here"" /></a></p>
<p><strong>Any ideas how to solve my problem?</strong> The simple code sample is below (plotting excluded)</p>
<pre><code>import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from scipy.optimize import curve_fit
import scipy.signal as sig

#reading dataset
signal = pd.read_csv('dataset.txt', delimiter=' ' )
signal.columns = ['time','current']

#calculating derivative, finding max and min indices of derivative
signal_derivative = np.gradient(signal,axis=0)
signal['derivative'] = pd.DataFrame(signal_derivative[:,1])
index_derivative_max = signal['derivative'].index[signal['derivative'] == signal['derivative'].max()]
index_derivative_min = signal['derivative'].index[signal['derivative'] == signal['derivative'].min()]

#calculating rolling variance, range 50 points, finding indices of peaks
signal['rolling_var'] = signal['current'].rolling(window=50,center=False).std()
index_rolling_max = signal['rolling_var'].index[signal['rolling_var'] == signal['rolling_var'].max()]
index_rolling_2nd_max = signal['rolling_var'].index[signal['rolling_var'] == signal['rolling_var'][:100000].max()]
</code></pre>
",1,82318,,2,39764,39764,2020-09-28T09:39:12.543,2020-09-28T09:20:17.797,1,2,,
28025,1,2018-02-20T11:43:18.410,10,17253,<machine-learning><python><deep-learning><tensorflow><decision-trees>,Does Tensorflow support a Decision Tree Classifier?,"<p>I am trying to implement decision tree classifier to classify my data set. I am using Python. Now it is easy to implement in scikit learn, but how can I implement this in tensorflow.</p>
",1,28029,,10,46433,29575,2020-03-12T19:41:43.907,2018-02-20T13:38:22.940,3,1,,
58484,1,2019-08-31T23:37:42.300,0,77,<python><pandas>,How to create dictionaries out of pandas dataframes?,"<p>I import three csv-files with characteristics of countries (rows) and years (columns):</p>

<pre><code>country_data_m = 'country_data_m.csv'
m_year = pd.read_csv(country_data_m, nrows=161, index_col=0, header=0, sep=';', na_values=[""""])

country_data_e = 'country_data_e.csv'
e_year = pd.read_csv(country_data_e, nrows=161, index_col=0, header=0, sep=';', na_values=[""""])

country_data_i = 'country_data_i.csv'
i_year = pd.read_csv(country_data_i, nrows=161, index_col=0, header=0, sep=';', na_values=[""""])
</code></pre>

<p>The datasets look like this:</p>

<pre><code>                                       1995          1996          1997  \
Afghanistan                              NaN           NaN           NaN   
Albania                                  NaN           NaN           NaN   
Angola                          5.538749e+09  7.526447e+09  7.648377e+09   
Antigua and Barbuda             5.772807e+08  6.337306e+08  6.806171e+08 


                                  1995    1996    1997    1998    1999  \
Afghanistan                        NaN     NaN     NaN     NaN     NaN   
Albania                            NaN     NaN     NaN     NaN     NaN   
Angola                          0.8565  0.8369  0.8173  0.7976  0.7777   
Antigua and Barbuda             0.6957  0.6352  0.6513  0.6401  0.6171 


                                  1995    1996    1997    1998    1999  \
Afghanistan                        NaN     NaN     NaN     NaN     NaN   
Albania                            NaN     NaN     NaN     NaN     NaN   
Angola                          0.0612  0.0626  0.0641  0.0655  0.0670   
Antigua and Barbuda             0.1852  0.2264  0.2147  0.2147  0.2030   
</code></pre>

<p>For each country, I need a dictionary, where the key is the year, and where the values are the variables from the three different datasets. So far, I tried this code:</p>

<pre><code>afghanistan = {m_year.loc[""Afghanistan"", (year)],e_year.loc[""Afghanistan"", (year)], i_year.loc[""Afghanistan"", (year)]): year for year in range(1995, 2017)} 

albania = {m_year.loc[""Albania"", (year)],e_year.loc[""Albania"", (year)], i_year.loc[""Albania"", (year)]): year for year in range(1995, 2017)} 
...
zimbabwe = {m_year.loc[""Zimbabwe"", (year)],e_year.loc[""Zimbabwe"", (year)], i_year.loc[""Zimbabwe"", (year)]): year for year in range(1995, 2017)}
</code></pre>

<p>However, the code cannot find the year in the dataframes and gives me the following error:</p>

<pre class=""lang-py prettyprint-override""><code>TypeError: cannot do label indexing on &lt;class 'pandas.core.indexes.base.Index'&gt; with these indexers [1995] of &lt;class 'int'&gt;
</code></pre>

<p>Any help would be very much appreciated!</p>
",1,58504,,0,80463,80463,2019-09-02T06:52:49.953,2019-09-01T15:00:11.347,1,3,,
19768,1,2017-06-16T14:13:34.620,6,33851,<python><neural-network><scikit-learn><cross-validation><hyperparameter>,How to implement Python's MLPClassifier with gridsearchCV?,"<p>I am trying to implement Python's <strong><em>MLPClassifier</em></strong> with <strong><em>10 fold</em></strong> cross-validation using <strong><em>gridsearchCV</em></strong> function. Here is a chunk of my code:</p>

<pre><code>parameters={
'learning_rate': [""constant"", ""invscaling"", ""adaptive""],
'hidden_layer_sizes': [(100,1), (100,2), (100,3)],
'alpha': [10.0 ** -np.arange(1, 7)],
'activation': [""logistic"", ""relu"", ""Tanh""]
}

clf
= gridSearchCV(estimator=MLPClassifier,param_grid=parameters,n_jobs=-1,verbose=2,cv=10)
</code></pre>

<p>Though,I am not sure if <code>hidden_layer_sizes: [(100,1), (100,2), (100,3)]</code> is correct. Here, I am trying to tune <strong><em>'hidden layer size'</em></strong> &amp; <strong><em>'number of neurons'</em></strong>. I would like to give this <strong><em>'tuple'</em></strong> parameter for <strong><em>hidden_layer_sizez: 1, 2, 3</em></strong>, and <strong>neurons: 10, 20, 30,...,100</strong>.</p>

<p>But
I do not know if it is the correct way to do it. Therefore, I am choosing default neurons to be <strong><em>100</em></strong> in each layer.</p>

<p>Can
anyone advise please?</p>
",1,19771,,6,33476,23305,2021-06-01T03:11:03.437,2017-12-20T16:17:37.167,2,3,,
96636,1,2021-06-14T23:39:42.360,0,94,<python><visualization><data-cleaning><transformation>,How to reshape or clean data to be able to visualize it with violin plots?,"<p>My end goal is to visualize some data using a violin plot or something similar using Python.</p>
<p>I have the following data in a file (<code>test.csv</code>). The first column is a list of species. The other columns determine abundance of the species at a certain latitude (e.g. how abundant is species A at altitude 1000, 2000?). (Ignoring units for now.) How can I plot this as a violin plot (or something similar)?</p>
<p><strong>test.csv</strong></p>
<pre><code>species,1000,2000,3000,4000,5000,6000,7000
species_A,0.5,0.5,,,2,1,2
species_B,0.5,1,0.5,0.5,1,1,10
species_C,1,1,10,3,15,4,5
species_D,15,3,2,1,0.5,1,3
</code></pre>
<p>The Python code I tried so far is below. This does not work because it only plots the distribution of altitudes, which is the same for all species (because they were all sampled from the same set of altitudes).</p>
<pre><code>file = &quot;test.csv&quot;
df = pd.read_csv(file)

# convert columns to list
colnames = list(df.columns)
colnames.remove(&quot;species&quot;)

# Transform the data so that I have a dataframe with only three columns: species, Altitude, and Count
df = pd.melt(df, id_vars=['species'], value_vars=colnames, value_name=&quot;Count&quot;, var_name=&quot;Altitude&quot;)
df.species = df.species.astype('category')
df.Altitude = df.Altitude.astype('int')

# Plot the data
sns.violinplot(x=&quot;species&quot;, y=&quot;Altitude&quot;, data=df)
plt.title(&quot;Abundance of Species at Various Altitudes&quot;)
plt.grid(alpha=0.5, ls=&quot;--&quot;)
plt.xticks(rotation=90)

# show graph
plt.show()
<span class=""math-container"">```</span>
</code></pre>
",1,96675,,0,107613,107613,2021-06-26T02:10:58.867,2021-06-14T23:51:51.443,2,9,,
103419,1,2021-10-23T10:24:41.987,1,349,<python><scikit-learn><xgboost><pipelines><imbalanced-learn>,ColumnTransformer worse performance than sklearn pipeline,"<p>I have an (unbalanced , binary data) pipeline model consisting of two pipelines (preprocessing and the actual model). Now I wanted to include <code>SimpleImputer</code> into my preprocessing pipeline and because I don't want to apply it to all columns used <code>ColumnTransformer</code> but now I see that the performance with <code>ColumnTransformer</code> is a lot worse than with the sklearn pipeline (AUC before around 0.93 and with <code>ColumnTransformer</code>it's around 0.7). I filled the nan values before the pipeline to check if the performance would be better then (as the SimpleImputer would not do anything then) but even without any nan values in the data the performance stays this bad. I have part of the code below. Does anyone know what's happening or what I can change?</p>
<pre><code>from sklearn.pipeline import Pipeline as pipeline
from imblearn.pipeline import Pipeline as pipeline_imb
from sklearn.compose import ColumnTransformer


#option with ColumnTransformer (performs a lot worse)
preproc = ColumnTransformer([
           ('imputer',SimpleImputer(strategy = 'mean'),['col1','col2','col3'])
           ])


#option with sklearn pipeline (performs better)
preproc = pipeline([
           ('SimpleImputer', SimpleImputer(strategy = 'mean')), 
           ])


modelpipe = pipeline_imb([
             ('undersampling',RandomUnderSampler()),
             ('xgboost', xgb.XGBClassifier(**params, n_jobs=-1))
             ])

model = pipeline([('preproc', preproc), ('modelpipe', modelpipe)])

</code></pre>
<p>so only exchanging the two preproc makes such a huge performance difference. Why is this?</p>
",1,103430,,1,79602,,2021-10-23T17:42:59.430,,1,3,,
78277,1,2020-07-24T15:41:03.610,2,87,<python><classification><probability><lightgbm><probability-calibration>,How can i tell if my model is overfitting from the distribution of predicted probabilities?,"<p>all,</p>
<p>i am training light gradient boosting and have used all of the necessary parameters to help in over fitting.i plot the predicted probabilities (i..e probabililty has cancer) distribution from the model (after calibrating using calibrated classifier) i.e. their histogram or kde. as you can see from below the probabilities for my class 1 are concentrated on the upper and lower end.</p>
<p>i have tried playing around with bandwith too to smooth this a little and it doesn't smooth the bumps too much. what do you think this shows about my model? isn't it a good thing that the model for class 1 (which is has cancer) is assigning a greater probability for this class?</p>
<p>i am unsure how to interpret this or where i could be going wrong</p>
<p><a href=""https://i.stack.imgur.com/KPw48.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/KPw48.png"" alt=""enter image description here"" /></a></p>
<p>the red curve is positive class (has cancer) and the blue curve is hasn't. below is plot used to generate.</p>
<pre><code>results = df[['label','predicted_prob']]

colors = ['b', 'r']



for label in [0, 1]:
    results[results['label'] == label]['predicted_prob'].plot.kde(bw_method=0.35,color=colors[label])
plt.xlim(0,1)
</code></pre>
",1,78281,,2,67931,,2020-08-24T03:01:20.173,,1,1,,
41246,1,2018-11-15T03:38:17.340,4,1149,<machine-learning><python><deep-learning><machine-learning-model>,How to extract characteristics from text using machine learning?,"<p>I would like to develop some kind of model/algorithm that allows me to <em>extract the characteristics of a given product name</em>. (let's say the brand, model and color).</p>

<p>I am looking for a solution similar to the one offered by <em>MonkeyLearn</em> and its model <em>Laptop Feature Extract</em>. </p>

<p>For example: </p>

<p>Given the item ""Apple iPhone 6s, 64GB Silver"", It should compute:</p>

<pre><code>{
  brand: ""iPhone"",
  model: ""6s"",
  capacity: ""64Gb"",
  color: ""Silver""
}
</code></pre>

<p>Any suggestions will be appreciated.
Thank you.</p>
",1,45087,,4,62631,,2019-02-05T12:09:03.863,,1,1,,
9813,1,2016-01-17T04:36:02.373,1,755,<machine-learning><python><scikit-learn><svm><object-recognition>,Face Recognition using Eigenfaces and SVM,"<p>I am new to machine learning. I want to develop a face recognition system using scikit-learn. <a href=""http://scikit-learn.org/stable/auto_examples/applications/face_recognition.html#example-applications-face-recognition-py"" rel=""nofollow noreferrer"">This</a> is the example given in the tutorials of scikit-learn.</p>
<p>I am not getting how the input is being provided to the program. How should I load a particular image and make my program run to predict the label for that?</p>
",1,9814,,1,15412,85045,2020-12-30T17:06:42.760,2020-12-30T17:06:42.760,1,1,,
29893,1,2018-04-04T09:02:27.417,17,61523,<python><deep-learning><classification><keras><overfitting>,High model accuracy vs very low validation accuarcy,"<p>I'm building a sentiment analysis program in python using Keras Sequential model for deep learning</p>

<p>my data is 20,000 tweets:</p>

<ul>
<li>positive tweets: 9152 tweets</li>
<li>negative tweets: 10849 tweets</li>
</ul>

<p>I wrote a sequential model script to make the binary classification as follows:</p>

<pre><code>model=Sequential()
model.add(Embedding(vocab_size, 100, input_length=max_words))
model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))
model.add(MaxPooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(250, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Fit the model

print(model.summary())
history=model.fit(X_train[train], y1[train], validation_split=0.30,epochs=2, batch_size=128,verbose=2)
</code></pre>

<p>however I get very strange results! The model accuracy is almost perfect (>90)
whereas the validation accuracy is very low (&lt;1) (shown bellow)</p>

<pre><code>Train on 9417 samples, validate on 4036 samples
 Epoch 1/2
- 13s - loss: 0.5478 - acc: 0.7133 - val_loss: 3.6157 - val_acc: 0.0243
 Epoch 2/2
- 11s - loss: 0.2287 - acc: 0.8995 - val_loss: 5.4746 - val_acc: 0.0339
</code></pre>

<p>I tried to increase the number of epoch, and it only increases the model accuracy and lowers the validation accuracy</p>

<p>Any advice on how to overcome this issue?</p>

<p>Update:</p>

<p>this is how I handle my data</p>

<pre><code>#read training data
pos_file=open('pos2.txt', 'r', encoding=""Latin-1"")
 neg_file=open('neg3.txt', 'r', encoding=""Latin-1"")
# Load data from files
pos = list(pos_file.readlines())
neg = list(neg_file.readlines()) 
x = pos + neg
docs = numpy.array(x)
#read Testing Data
pos_test=open('posTest2.txt', 'r',encoding=""Latin-1"")
posT = list(pos_test.readlines())
neg_test=open('negTest2.txt', 'r',encoding=""Latin-1"")
negT = list(neg_test.readlines())
xTest = posT + negT
total2 = numpy.array(xTest)

CombinedDocs=numpy.append(total2,docs)

# Generate labels
positive_labels = [1 for _ in pos]
negative_labels = [0 for _ in neg]
labels = numpy.concatenate([positive_labels, negative_labels], 0)

# prepare tokenizer
t = Tokenizer()
t.fit_on_texts(CombinedDocs)
vocab_size = len(t.word_index) + 1
# integer encode the documents
encoded_docs = t.texts_to_sequences(docs)
#print(encoded_docs)

# pad documents to a max length of 140 words
max_length = 140
padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')
</code></pre>

<p>Here I used Google public word2vec</p>

<pre><code># load the whole embedding into memory
embeddings_index = dict()
f = open('Google28.bin',encoding=""latin-1"")
for line in f:
values = line.split()
word = values[0]
coefs = asarray(values[1:], dtype='str')
embeddings_index[word] = coefs
f.close()

# create a weight matrix for words in training docs
embedding_matrix = zeros((vocab_size, 100))

for word, i in t.word_index.items():
embedding_vector = embeddings_index.get(word)
if embedding_vector is not None:
    embedding_matrix[i] = embedding_vector


#Convert to numpy
NewTraining=numpy.array(padded_docs)
NewLabels=numpy.array(labels)
encoded_docs2 = t.texts_to_sequences(total2)

# pad documents to a max length of 140 words

padded_docs2 = pad_sequences(encoded_docs2, maxlen=max_length, padding='post')


# Generate labels
positive_labels2 = [1 for _ in posT]
negative_labels2 = [0 for _ in negT]
yTest = numpy.concatenate([positive_labels2, negative_labels2], 0)
NewTesting=numpy.array(padded_docs2)
NewLabelsTsting=numpy.array(yTest)
</code></pre>
",1,29896,,17,49944,49944,2021-08-18T02:34:10.560,2018-04-05T08:44:41.297,5,7,,
43240,1,2018-12-28T11:47:06.553,3,933,<machine-learning><python><classification>,"Select two best classifier using F1-score,Recall and precision","<p>I have three classifiers that classify same dataset with these results:</p>

<pre><code>classifier A:
              precision    recall   f1-score 
  micro avg       0.36      0.36      0.36      
  macro avg       0.38      0.43      0.36       
  weighted avg    0.36      0.36      0.32    

classifier B:
              precision    recall   f1-score 
   micro avg       0.55      0.55      0.55      
   macro avg       0.60      0.60      0.56       
   weighted avg    0.61      0.55      0.53       

classifier C:
               precision    recall   f1-score 
   micro avg       0.34      0.34      0.34       
   macro avg       0.36      0.38      0.32      
   weighted avg    0.39      0.34      0.32       
</code></pre>

<p>I want two select two best of them, and I know F1-score is a parameter for compare the classifiers because of its harmony between precision and recall.
So, at first I select classifier B for its best F1-score. for next, both A and C have a same F1-measure,
I want to ask how can I select between them? </p>
",1,43241,,3,64758,,2018-12-28T13:38:58.240,,2,1,,
51348,1,2019-05-03T22:42:39.580,9,7199,<machine-learning><python><dataset><data-cleaning><randomized-algorithms>,Splitting train/test sets by an identifier?,"<p>I know sklearn has <code>train_test_split()</code> to split a train and test set. But I read that, even with setting a random seed, if your actual dataset is updated regularly, the random seed will reset with each updated dataset and take a different train/test split. Doing this, your ML algos will eventually cover the whole dataset, defeating the purpose of the train/test split because it'll eventually train on too much of the whole dataset over time.</p>

<p>The book I'm reading (Hands-On Machine Learning with Scikit-Learn and Tensorflow) gives this code to split train/test by id:</p>

<pre><code># Function to check test set's identifier.
def test_set_check(identifier, test_ratio):
    return crc32(np.int64(identifier)) &amp; 0xffffffff &lt; test_ratio * 2**32

# Function to split train/test
def split_train_test_by_id(data, test_ratio, id_column):
    ids = data[id_column]
    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))
    return data.loc[~in_test_set], data.loc[in_test_set]
</code></pre>

<p>And it says when there's no ID column given, to create one either by indexing the rows or creating a unique index from one of the variables.</p>

<p>My questions are:</p>

<ol>
<li><p>What is the 3rd line doing:</p>

<p><code>crc32(np.int64(identifier)) &amp; 0xffffffff &lt; test_ratio * 2**32</code></p></li>
<li><p>What is the anonymous function doing in the 2nd to last line?</p>

<p><code>lambda id_: test_set_check(id_, test_ratio)</code></p></li>
<li><p>In practice, do you commonly split datasets by id in this manner?</p></li>
</ol>

<p>Thanks,</p>

<p>Greg</p>
",1,51384,,9,71231,45264,2021-05-07T21:58:26.803,2019-05-08T05:38:10.683,3,3,,
45118,1,2019-02-05T20:38:56.830,9,25877,<python><r>,Cutting numbers into fixed buckets,"<p>I am trying to put numeric data into fixed number of buckets using Python/R.</p>

<p>I have data in key:value format <code>{1 : 12.3, 2 : 4.7, 3 : 7.4, 4 : 15.9, ......, 50 : 24.1}</code>, which is <code>device_id:data_usages</code> I need to bucket based on value into nine buckets <code>(1,5,25,50,150,250,1000,5000,10000)</code>, So later I can see which data points are in which bucket.</p>

<p>What function can do this in Python OR R?</p>
",1,45122,,9,67137,924,2021-09-11T20:53:33.500,2019-02-10T13:37:59.270,2,2,,
82644,1,2020-10-06T21:15:18.210,0,105,<python><statistics><simulation><monte-carlo>,Pull Random Numbers from my Data (Python),"<p>Let's imagine I have a series of numbers that represents cash flows into some account over the past 30 days in some time window. This data is non-normal but it does represent some distribution. I would like to pull &quot;new&quot; numbers from this distribution in an effort to create a monte-carlo simulation based on the numerical data I have. How can I accomplish this? I've seen methods where you assume the data is normal &amp; pull numbers based on some mean and standard deviation - but what about non-normal distributions? I'm using python so any reference including python or some python libraries would be appreciated.</p>
",1,82646,,0,104161,,2020-10-06T22:16:18.300,,1,1,,
103706,1,2021-11-02T05:22:27.897,0,33,<python><encoding><tfidf><one-hot-encoding>,Encoding feature containing both text and string?,"<p>I have a feature which has following entries:-</p>
<pre><code>| Exterior |
| -------- |
| Vinyl    |
| Wd Sdng  |
| MetalSd  |
| Wd Sdng  |
| HdBoard  |
| BrkFace  |
| Wd Sdng  | 
</code></pre>
<p>and so on.</p>
<p>I am assuming that <code>Wd Sdng</code> is a text value and other values are string (but please correct me if I am wrong).</p>
<p>How do I encode this feature since it has both text and string values?</p>
<p>Should I perform a OneHotEncoding or should I perform some kind of NLP encoding (Tfidf etc)??</p>
",1,103880,,0,119921,119921,2021-11-06T11:31:26.897,2021-11-02T08:35:41.073,2,2,,
34396,1,2018-07-12T21:34:36.543,0,1110,<python><deep-learning><dataset>,How to extract particular key from the dict()?,"<p>I have a <code>dict()</code> with 1000 keys. First 4 entries of dict are like. </p>

<pre><code>{
    'aaa': [1,0,6,8,0,5,9,1,1,0],
    'abc': [1,1,1,2,4,0,0,0,9,8],
    'cfg': [0,0,0,4,3,1,0,0,0,1],
    'cghjj': [7,8,9,2,3,0,0,0,0,0]
}
</code></pre>

<p>I want to create a dataset using each key one by one. I want to pick <code>key1</code>. Then create a dataset using <code>function1</code> using the values of <code>key1</code> and then pick <code>key2</code>. Creating another dataset using values of <code>key2</code> and appending the result of <code>key2</code> to <code>key1</code> row-wise. Then with <code>key3</code>... and then append the result to the result of <code>key1</code> and <code>key2</code> and so on.. up to 1000 keys.</p>

<pre><code>dataset=dict()

create_dataset:
    select values of key 1.
    b1=function1()
    b1=np.asarray(b1)

    then select key 2.
    b2=function1()
    b2=np.asarray(b2)

    np.append(b1,b2,axis=0)
</code></pre>

<p>...upto 1000 key.</p>
",1,35484,,0,53283,54395,2018-07-15T11:02:46.573,2018-07-15T11:02:46.573,1,4,,
88190,1,2021-01-19T13:36:04.637,1,137,<python><visualization><matplotlib>,Visualising feature selection results for multiple classifiers and feature subset sizes,"<p>I am using information gain feature selection technique to get different features subset sizes for my dataset, like so:</p>
<pre class=""lang-py prettyprint-override""><code>fs1 = SelectKBest(score_func=mutual_info_classif, k=10)
fs1.fit(X_train, y_train)
X_train_fs1 = fs1.transform(X_train)
X_test_fs1 = fs1.transform(X_test)


fs2 = SelectKBest(score_func=mutual_info_classif, k=20)
fs2.fit(X_train, y_train)
X_train_fs2 = fs2.transform(X_train)
X_test_fs2 = fs2.transform(X_test)


fs3 = SelectKBest(score_func=mutual_info_classif, k=30)
fs3.fit(X_train, y_train)
X_train_fs3 = fs3.transform(X_train)
X_test_fs3 = fs3.transform(X_test)
</code></pre>
<p>I am then testing the performance of 4 different algorithms (Logistic Regression, SVM, AdaBoost and Decision Trees) using different subset sizes of feature selected features (subset 1 has k=10, so 10 features, subset 2 has 20 features, etc.). To evaluate the model's performance, I am calculating the Precision, Recall and AUC, like so:</p>
<pre class=""lang-py prettyprint-override""><code>def compareAlgorithms(X_train, y_train, score):
    # Compare Algorithms
    seed = 7

    # prepare models
    models = []
    models.append(('LR', LogisticRegression()))
    models.append(('SVM', SVC()))
    models.append(('Linear SVC', LinearSVC()))
    models.append(('ADABOOST', AdaBoostClassifier()))
    models.append(('DT', DecisionTreeClassifier()))


    # evaluate each model in turn
    results = []
    names = []
    scoring = score
    
    print(score, &quot;:&quot;)
    
    for name, model in models:
        skf = StratifiedKFold(n_splits=5, shuffle=False, random_state=seed)
        #kfold = model_selection.KFold(n_splits=5, random_state=seed)
        cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=skf, scoring=scoring)
        results.append(cv_results)
        names.append(name)
        msg = &quot;%s: %f (%f)&quot; % (name, cv_results.mean(), cv_results.std())
        print(msg)
        
    return results, names
</code></pre>
<p>As I now have lots of results, I am trying to plot the results to better visualise which algorithm is performing better with which subset. I want to create plots similar to the ones I found in <a href=""https://link.springer.com/article/10.1007/s11227-018-02738-w"" rel=""nofollow noreferrer"">this article</a>:</p>
<p><a href=""https://i.stack.imgur.com/Dh90D.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Dh90D.png"" alt=""enter image description here"" /></a></p>
<p>I have tried using matplotlib to do this, but have found it quite difficult seeing as I am trying to plot different classifiers on different features subset. I can (sort of) plot a line plot of the algorithms performance for one data subset using this function:</p>
<pre class=""lang-py prettyprint-override""><code>def plot(results,names, score):
    import matplotlib.pyplot as plt
    # plot for algorithm comparison
    fig = plt.figure()
    fig.suptitle(score)
    ax = fig.add_subplot(111)
    plt.plot(results)
    ax.set_xticklabels(names)
    plt.show()
   
</code></pre>
<p>Which results in this plot:</p>
<p><a href=""https://i.stack.imgur.com/Jy1OZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Jy1OZ.png"" alt=""enter image description here"" /></a></p>
<p>The problem with the above plot (beside the overlapping model names below which I am working on fixing) is that it is for one feature subset.</p>
<p>Can anyone help me do a plot like the one in the paper I have attached and maybe direct me to useful resources for someone just starting to learn about data visualisation?</p>
<p>Many thanks.</p>
",1,88240,,1,99648,99648,2021-01-20T15:25:19.197,2021-01-20T15:25:19.197,4,7,,
14883,1,2016-11-02T08:15:53.687,13,3356,<python><nlp>,Extract information from sentence,"<p>I'm creating a simple chatbot. I want to obtain the information from the user response. An example scenario:</p>

<pre><code>Bot : Hi, what is your name?
User: My name is Edwin.
</code></pre>

<p>I wish to extract the name Edwin from the sentence. However, the user can response in different ways such as </p>

<pre><code>User: Edwin is my name.
User: I am Edwin.
User: Edwin. 
</code></pre>

<p>I'm tried to rely on the dependency relations between words but the result does not do well.</p>

<p>Any idea on what technique I could use to tackle this problem?</p>

<p><strong>[UPDATED]</strong></p>

<p>I tested with named entity recognition together with part of speech tagger and parser. I found out that most model is trained in a way that the first character of the entity for the person name or the proper noun must be upper case. This may be true for normal document, but it is irrelevant for a chatbot. E.g. </p>

<pre><code>User: my name is edwin.
</code></pre>

<p>Most NER failed to recognize this.</p>
",1,14933,,13,20974,20974,2021-01-05T16:28:43.830,2016-11-07T10:14:20.850,4,2,,
9413,1,2015-12-16T16:13:42.943,2,116,<machine-learning><python><neural-network><logistic-regression>,"How to analyse move kindness in python (Logistic regression, neural network, etc.)?","<p>With a team of researchers we were given the assignment to make a scale for the <em>move kindness</em> (how inviting a room or place is for exercise--e.g., a gym). In order to get objective results we were asked to make a measurement device. This device receives input through various sensors and maybe some true/false questions, and then analyze it with training information in mind. After the analysis it returns a number from, say: 1 to 10, indicating the move kindness. So a gym gets, for example an eight and a classroom a three. The problem with this is, that move kindness is very subjective, so we have conducted some surveys. For example one of the criteria is the temperature of the room/place. While the survey was being conducted we measured the temperature:</p>

<blockquote>
  <p>From a scale from 1 to 10, what is your opinion about the temperature?</p>
</blockquote>

<p>And then we measured the temperature. We have put all these information into some  spreadsheets:</p>

<p>Rating (Move Kindness): 8<br>
Temperature: 18 degrees Celsius</p>

<p>At the end of this survey we asked them to give the move kindness a rating.
So we have this, for example: <br>
Temperature: 8, 18 <br>
Light: 7, 300 <br>
Humidity: 8, 50 <br>
.... <br>
Rating (Move Kindness): 8</p>

<p>So my question is, what's the best way to analyse these data for a reliable measurement device using python?
We were thinking of using neural networks, because they can be trained, but logistic regression or some other machine learning algorithm is also an option. Can anyone give me some direction on this?</p>
",1,9414,,2,14800,13413,2021-04-21T02:47:11.873,2015-12-17T15:09:32.183,1,4,,
17885,1,2017-03-26T18:40:50.630,1,1276,<python><tensorflow><keras>,Getting low accuracy on keras pretrained word embeddings example,"<p><a href=""https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html"" rel=""nofollow noreferrer"">Original blog post</a> claims that it is possible to get 95% accuracy on the validation set (20 Newsgroup dataset) after only 2 epochs using pretrained word embeddings (glove.6B.100d). All code is located <a href=""https://github.com/fchollet/keras/blob/master/examples/pretrained_word_embeddings.py"" rel=""nofollow noreferrer"">here</a>. I did not changed anything in this example but getting only 40% accuracy on the validation set after 2 epochs and 75% after 10 epochs. I can't get to 95% accuracy even after 20 epochs. Switching from tensorflow to theano backend do not make any significant change. I'm using Keras 2.0.2, tensorflow-gpu 1.0.1, theano 0.9.0, python 2.7.12. What I'm doing wrong?</p>
",1,18863,,1,30396,,2017-05-09T23:07:57.877,,2,9,,
103603,1,2021-10-29T09:19:05.447,1,48,<machine-learning><python><nlp><scikit-learn><prediction>,Which algorithm is best for predicting diseases if symptoms are given?,"<p>After Topic modelling through LDA, I get the following dataset as result.</p>
<pre><code>    Document_No Dominant_Topic  Topic_Perc_Contrib  Keywords    TextBookFindings    Disease/Drugs
0   0   3.0 0.7625  hypotension, bradycardia, mydriasis, hypersali  Hypotension,hypothermia,bradycardia NSAIDS Poisoning
1   1   5.0 0.6833  edema, cyanosis, cardiacarrest, lacrimation,    Hyperventilation,respiratoryalkalosis,edema–br...   NSAIDS Poisoning
2   2   0.0 0.8100  vomiting, nausea, diarrhea, abdominalpain,  Nausea,vomiting,diarrhea,abdominalpain– NSAIDS Poisoning
3   3   0.0 0.2625  vomiting, nausea, diarrhea, abdominalpain,  GIbleeding,pancreatitis,hepaticinjury   NSAIDS Poisoning
4   4   1.0 0.4463  insomnia, drowsiness, irritability, neurotoxic  Headache,dizziness,encephalopathy,irritability  NSAIDS Poisoning

... ... ... ... ... ... ...
1446    1446    7.0 0.5250  weakness, muscle, coagulopathy, fasciculations...   metabolicacidosis,Elevatedlactateconcentration...   Neuroleptic malignant syndrome (NMS)
1447    1447    0.0 0.0500  vomiting, nausea, diarrhea, abdominalpain, pan...   hematologictoxicity Neuroleptic malignant syndrome (NMS)
1448    1448    0.0 0.5250  vomiting, nausea, diarrhea, abdominalpain, pan...   Pancreatitis    NaN
1449    1449    0.0 0.0500  vomiting, nausea, diarrhea, abdominalpain, pan...   Hypersensitivity    Neuroleptic malignant syndrome (NMS)
1450    1450    0.0 0.0500  vomiting, nausea, diarrhea, abdominalpain, pan...   sensoryperipheralneuropathy NaN
</code></pre>
<p>I want to create a prediction system when a symptom is inputted, it shows the percentage matches of the Disease/Drugs. So I want to create a prediction between columns <code>keywords</code> and <code>Disease/Drugs</code>.</p>
<p>Which will be the best algorithm and some suggestions how to move forward with this?</p>
",1,103623,,1,117548,,2021-10-29T18:49:49.180,,1,2,2021-11-19T10:51:20.260,
24780,1,2017-11-15T19:30:56.623,0,2891,<python><tensorflow><rnn>,Reading a CSV in TensorFlow RNN,"<p>I am just starting off with TensorFlow and trying to implement an RNN for a dataset which consists of 11 Features (all numeric). These features will be used to predict the output of another column. </p>

<p>I am currently lost on where to start and tho I am able to understand how a RNN functions all the tutorials I could find were mainly related to image and text datasets. </p>
",1,24793,,0,41913,,2017-11-16T03:20:21.590,,1,3,,
13059,1,2016-07-28T15:15:45.510,7,22235,<python><pandas><data><csv>,Merging large CSV files in pandas,"<p>I have two CSV files (each of the file size is in GBs) which I am trying to merge, but every time I do that, my computer hangs. Is there no way to merge them in chunks in pandas itself?</p>
",1,13063,,7,15412,85045,2020-12-27T13:48:47.960,2020-12-27T13:48:47.960,2,4,,
11893,1,2016-05-23T20:33:17.557,4,551,<python><time-series><anomaly-detection><sequential-pattern-mining>,"If a time series has random time events, how to detect patterns?","<p>My app receives messages with a random number of bits at a random time. But two weeks ago I started to notice some almost regular patterns on the metrics of my app. I suspect they are some bots sending artificially generated data to my app. Specifically, I'm looking for sequential subsets of messages in a time series where messages has almost the same number of bits.</p>

<p>I read about some methods but they use data where time is not a random variable. I appreciate any help you can provide, including books, web pages, tutorials (in Python if possible), etc.</p>
",1,12415,,4,18612,18612,2016-07-26T11:04:22.087,2016-05-26T01:27:41.120,1,2,,
26206,1,2018-01-02T15:21:36.827,7,32210,<machine-learning><python><k-means>,calculate distance between each data point of a cluster to their respective cluster centroids,"<p>I have a dataset of some keywords in some text files. Using the append feature I have access each text file and I append all of the keywords to token_dict like this </p>

<pre><code>token_dict=""wrist. overlapping. direction. receptacles. comprising. portion. adjacent. side. hand. receive. adapted. finger. comprising. thumb. ...............................""
</code></pre>

<p>By using k-means clustering, I clustered this data by using k=3. Now, I want to calculate the distance between each data point in a cluster to its respective cluster centroid. I have tried to calculate euclidean distance between each data point and centroid but somehow I am failed at it. My code is as follows: </p>

<pre><code>from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from matplotlib import style
import numpy as np
style.use('ggplot')
token_dict = []
import glob   
path = 'E:\\Project\\*.txt'   
files=glob.glob(path)   
for file in files:     
    f=open(file, 'r')
    text = f.read()
    token_dict.append(text)
vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000, min_df=2, use_idf=True)

#print(X)

km = KMeans(n_clusters=3)
#labels = km.fit_predict(vectorizer)
#print(labels)
X = vectorizer.fit_transform(token_dict).todense()
km.fit(X)
pca = PCA(n_components=2).fit(X)
data2D = pca.transform(X)
# =============================================================================
# cluster_0=np.where(X==0)
# print(cluster_0)
# 
# X_cluster_0 = data2D[cluster_0]
# print (X_cluster_0)
# =============================================================================

# =============================================================================
# def euclidean(X1, X2):
#     return(X1-X2)
# =============================================================================

# =============================================================================
# distance = euclidean(X_cluster_0[0], km.cluster_centers_[0])
# print(distance)
# =============================================================================
# =============================================================================
# 
# km.predict()
# =============================================================================
order_centroids = km.cluster_centers_
centers2D = pca.transform(order_centroids)
labels = km.labels_
colors = [""y."", ""b."",""g.""]
for i in range(len(X)):
    plt.plot(data2D[i][0], data2D[i][1], colors[labels[i]], markersize=10)

plt.scatter(centers2D[:, 0], centers2D[:, 1], marker='x', s=200, linewidths=3, c='r')
plt.show()
</code></pre>

<p>Can someone see where I went wrong?</p>
",1,26207,,7,43954,29575,2018-11-14T09:55:38.310,2018-01-02T15:34:38.720,2,1,,
117505,1,2023-01-04T10:38:12.553,1,54,<python><tensorflow><cnn><random-forest><vgg16>,Random Forest Classifier is giving me an array of zeroes,"<p>I used VGG16 as feature extractor on a dataset with 9 classes and trained the Random Forest Classifier on the feature vector. I tried to make prediction on the test feature vector but the prediction is an array of zeroes. What am i doing wrong ?</p>
<p><a href=""https://i.stack.imgur.com/o11Bc.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/o11Bc.png"" alt=""All zero prediction"" /></a>
<a href=""https://colab.research.google.com/drive/1IzewE9ZK3pT9D6r6etbTogCP9n3gH6zW?usp=sharing"" rel=""nofollow noreferrer"">Notebook Link</a></p>
",1,117549,,1,144509,,2023-01-05T17:24:55.943,,1,8,,
68265,1,2020-02-18T03:06:37.523,1,612,<python><keras><tensorflow><computer-vision><object-detection>,Using Tensorflow object detection API vs Keras,"<p>I am new to machine learning. I am curious to know what is the difference between using Keras instead of TensorFlow object detection API. We need to manually configure hidden layers and input layer in Keras so what is the advantage to use Keras and how to know how many layers should configure to achieve object detection using Keras.</p>

<p>Please check two different types of implementation 1) <a href=""https://medium.com/predict/object-classification-from-scratch-using-tensorflow-and-keras-964e42e898b2"" rel=""nofollow noreferrer"">Using Keras</a> 2) <a href=""https://medium.com/coinmonks/tensorflow-object-detection-with-custom-objects-34a2710c6de5"" rel=""nofollow noreferrer"">Using Tensorflow Object detection API without Keras</a></p>

<p>Thanks !!!</p>
",1,68271,,1,76275,76275,2020-02-18T07:39:45.823,2020-02-18T03:12:34.173,1,3,,
10809,1,2016-03-21T11:04:21.280,2,1570,<python><classification><neural-network><scikit-learn><image-classification>,Image Segmentation with a challenging background,"<p>I'm working on an animal classification problem, with the data extracted from a video feed. The recording was made in a pen, so the problem is quite challenging with a dark background and many shadows: <a href=""https://i.stack.imgur.com/2B5BE.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2B5BE.png"" alt=""enter image description here""></a></p>

<p>Initially I tried scikit-image, but then someone helped me with an advanced tool called crf-rnn (<a href=""http://crfasrnn.torr.vision/"" rel=""nofollow noreferrer"">http://crfasrnn.torr.vision/</a>) that does a great job segmenting and labelling objects in an image. I did the following: </p>

<pre><code>import caffe
net = caffe.Segmenter(MODEL_FILE, PRETRAINED)
IMAGE_FILE = '0045_crop2.png'
input_image = caffe.io.load_image(IMAGE_FILE)
from PIL import Image as PILImage
image = PILImage.fromarray(np.uint8(input_image))
image = np.array(image)
mean_vec = [np.mean(image[:,:,vals]) for vals in range(image.shape[2])]
im = image[:, :, ::-1]
im = im - reshaped_mean_vec
cur_h, cur_w, cur_c = im.shape
pad_h = 750 - cur_h
pad_w = 750 - cur_w
print(pad_h, pad_w, ""999"")
im = np.pad(im, pad_width=((0, max(pad_h,0)), (0, max(pad_w,0)), (0, 0)), mode = 'constant', constant_values = 255)
segmentation = net.predict([im])
segmentation2 = segmentation[0:cur_h, 0:cur_w]
</code></pre>

<p>The resulting image segmentation is rather poor (although two cows are recognized correctly):
<a href=""https://i.stack.imgur.com/eBEr4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eBEr4.png"" alt=""enter image description here""></a></p>

<p>I use a trained crf-rnn (MODEL_FILE, PRETRAINED), which works well for other problems, but this one is harder. I would appreciate any suggestions on how to pre-process this sort of image to extract the shape of most cows. </p>
",1,10819,,2,1426,,2016-03-21T23:12:41.200,,1,1,,
15923,1,2016-12-25T19:35:16.417,4,660,<python><statistics>,Computing confidence interval for average from individual predictions,"<p>In the attached image, I am plotting actual vs predicted along with confidence intervals for each of the predicted points. The black star represents the average of all the predicted points. What formula can I use to combine the confidence intervals of all the predicted data points to get a confidence interval for the average? Also, please assume that the average could be a weighted average.</p>

<p>I am using python, numpy.</p>

<p><a href=""https://i.stack.imgur.com/8KzMz.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8KzMz.png"" alt=""enter image description here""></a></p>
",1,16037,,4,12985,8560,2017-08-03T02:10:55.650,2017-06-04T01:20:47.477,2,2,,
82028,1,2020-09-21T12:25:22.337,3,2564,<python><scikit-learn><xgboost><optimization>,Is it possible to get worse model after optimization?,"<p>I am trying recently to optimize models but for some reason, whenever I try to run the optimization the model score in the end is worse than before, so I believe I do something wrong.</p>
<p>in order to optimize my model I define param grid and than fit with the train data and then according to the results run again with nre parameters, e.g-</p>
<pre><code>#ROUND 1
param_grid={
    'max_depth': [3,4,5],
    'learning_rate':[0.1,0.01,0.05],
    'gamma': [0,0.25,1.0],
    'reg_lambda':[0,1.0,10.0],
    'scale_pos_weight':[1,3,5]
}

grid_search = GridSearchCV(estimator = clf_xgb, param_grid = param_grid, 
                          cv = 3, n_jobs = -1, verbose = 2)
grid_search.fit(X_train,y_train)
grid_search.best_params_

&gt;&gt;&gt;.....

</code></pre>
<p>(and now based on the result changing the params...)</p>
<p>after this step I choose the best hyperparameters and run the model;</p>
<pre><code>clf_xgb=xgb.XGBClassifier(seed=42,
                         objective='binary:logistic',
                         gamma=0,
                         learn_rate=0.7,
                         max_depth=6,
                         reg_lambda=0.8,
                         scale_pos_weight=1,
                         subsample=0.9,
                         cilsample_bytree=0.5)

clf_xgb.fit(X_train,
           y_train,
           verbose=True,
           early_stopping_rounds=10,
           eval_metric='aucpr',
           eval_set=[(X_test,y_test)])
</code></pre>
<p>The problem is that when I check the model score</p>
<pre><code>clf_xgb.score(X_test,y_test)
</code></pre>
<p>I always get lower score than what I got before the optimization which makes me suspect that I'm missing something in the way doing it/basic principle in this process.</p>
<p><strong>Is it possible that after running the optimization my score won't get better (and even worse?) ? Where is my mistake? Are there other parameters that could influence or improve my model?</strong></p>
",1,82350,,3,98535,,2020-09-28T22:22:33.337,,4,3,,
27541,1,2018-02-06T23:56:08.963,3,21991,<python><pandas>,Python: Unable to install pandas_profiling,"<p>I have tried installing profiling pandas profiling library with the following command from the terminal:</p>

<pre><code>conda install pandas-profiling
</code></pre>

<p>Output:</p>

<pre><code>ModuleNotFoundError: No module named 'pandas_profiling'
</code></pre>

<p>What am I doing wrong?</p>
",1,27696,,3,45534,,2018-02-11T09:13:34.983,,1,1,2018-02-11T21:59:37.407,
27949,1,2018-02-18T09:21:55.397,1,7490,<machine-learning><python><scikit-learn><decision-trees><performance>,Improve Precision of a binary classifier - Decision Tree in Python,"<p>Currently, I am working on a project. The dataset is balanced roughly in the ratio of 50:50. I created a decision tree classifier. I am achieving decent accuracy (~75%) on validation data but the precision for the target variable is biased. For class=0 it is approx. 98% while for the class = 1 it is just 17%.</p>

<p>I have tried scaling the data using MinMaxScaler still no luck.</p>

<pre><code>model = tree.DecisionTreeClassifier(class_weight={1:30}, min_samples_leaf=160, max_depth=10)

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=10)

min_max_scaler = preprocessing.MinMaxScaler()
X_train_scaled = min_max_scaler.fit_transform(X_train)
X_test_scaled = min_max_scaler.fit_transform(X_test)

model = model.fit(X_train_scaled, y_train)

prediction = model.predict(X_test_scaled)

print metrics.accuracy_score(y_test, prediction)
print classification_report(y_test, prediction)
</code></pre>

<blockquote>
<pre><code>Size of x_train_scaled = 12600 and x_test_scaled = 5400
Accuracy: 75%
Precision: {0:100%, 1:17%}
Recall: {0:74%, 1:100%}
F1-Score: {0:85%, 1:29%}
</code></pre>
</blockquote>

<p>How can I improve the precision of class=1 while still maintaining the overall precision and accuracy?</p>
",1,27950,,1,46431,,2019-07-23T18:34:37.627,,2,3,,
44224,1,2019-01-19T08:44:20.973,3,1694,<python><statistics><data><ipython>,Why do a lot of people use ipython notebook over python file when doing analyzing data? Is it the same in industry?,"<p>I have seen that a lot of people write code in ipython notebook when doing statistical analysis on data, apart from easy visualization after each step rather than running the whole code every time on a .py file. What are the other advantages,if there are any?</p>

<p>Also in industry which one is used more often? </p>
",1,44226,,3,58761,,2019-01-20T02:27:10.610,,2,2,,
10211,1,2016-02-11T21:52:50.030,4,7129,<python><nlp><sentiment-analysis>,Sentiment retriving from text (Russian),"<p>Does anybody knows python library to retrieve sentiment from Russian text. The dictionary with sentiment parameterization will be ok to. The idea of library something like in GPOMS in <a href=""http://arxiv.org/abs/1010.3003"" rel=""nofollow"">article</a>.</p>
",1,10795,,4,9992,31513,2019-01-10T18:52:31.710,2017-05-11T14:26:24.317,2,7,,
116242,1,2022-11-17T04:04:10.383,0,132,<python><classification><machine-learning-model><xgboost>,Unable to build a XGBoost classifier that gives good precision and recall on highly imbalanced data,"<p>The XGBoost Classifier I built is consistently returning a f1 score of 0 and I am unable to fix this despite experimenting with various hyperparameters. The data is heavily imbalanced and hence I feel the model in trying to maximize accuracy is behaving like this . Even changing the eval_metrics to use &quot;aucpr&quot; had no effect. I have searched on Google quite a bit but am unable to find out how to increase the f1 score as either I get high precision or high recall but not both . Please let me know if I am missing something</p>
<p>This is the code I am using. The csv file has 100,000 rows and 2 numeric columns as the feature set and 1 response variable (0 or 1) hence no transformation was carried out .</p>
<pre><code>df = pd.read_csv(&quot;Output\\SimulatedData.csv&quot;)
X = df.drop('Response', axis=1)
y = df[&quot;Response&quot;]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=25)

estimator_ = XGBClassifier(objective='binary:logistic',  eval_metric='aucpr')
estimator_.fit(X_train, y_train)
y_pred = estimator_.predict(X_test)
</code></pre>
",1,116413,,0,142876,29169,2022-11-23T03:15:17.720,2022-11-17T16:34:18.750,3,4,,
104311,1,2021-11-20T02:00:41.173,0,1112,<python><pandas>,Select Random Value from Pandas list column for each row ensuring that value don't get picked again,"<p>I have a pandas DataFrame below</p>
<pre><code>import pandas as pd
data = {
'poc':[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;],
'school':[&quot;school1&quot;, &quot;school2&quot;, &quot;school3&quot;, &quot;school4&quot;],
'volunteers':[[&quot;sam&quot;, &quot;mat&quot;, &quot;ali&quot;, &quot;mike&quot;, &quot;guy&quot;, &quot;john&quot;], 
[&quot;sam&quot;, &quot;mat&quot;, &quot;ali&quot;, &quot;mike&quot;], [&quot;rose&quot;, &quot;sam&quot;, &quot;mike&quot;, &quot;jorge&quot;], 
[&quot;susan&quot;, &quot;jack&quot;, &quot;alex&quot;, &quot;mat&quot;, &quot;mike&quot;]]
}
df = pd.DataFrame.from_dict(data) ​
</code></pre>
<p>I need to create a new column that has a random pick from the volunteers column to select 1 volunteer for each school ensuring that the same volunteer doesn't get picked twice</p>
<p>so far I have tried</p>
<pre><code>import random
df[&quot;random_match&quot;] = [random.choice(x) for x in df[&quot;volunteers&quot;]]
</code></pre>
<p>but this just gives me a random pick without ensuring it is not repeated.</p>
",1,104352,,0,127960,,2021-11-22T03:15:09.127,,1,2,2021-11-29T04:20:39.947,
31740,1,2018-05-16T14:36:22.320,1,996,<machine-learning><python><deep-learning><keras><theano>,Keras/Theano custom loss calculation - working with tensors,"<p>I'm struggling to write some tensor manipulation code for a custom loss function I'm using in Keras.</p>

<p>Basically, I'm trying to modify a binary_crossentropy loss by adding a weight that is calculated from a particular feature.</p>

<p>First thing I do is pass in my extra feature data to the custom loss by appending it to the y_true like this:</p>

<pre><code>y_trainModded = numpy.append(y_train, MyExtraData, axis=1)
</code></pre>

<p>Which is then passed to the fit function like:</p>

<pre><code>model.fit(X_train, y_trainModded, epochs=2500, .....)
</code></pre>

<p>Then extracted to make it usable like this:</p>

<pre><code>def myCustomLoss(data, y_pred):
    y_true = data[:,:2]
    MyExtraData = data[:,2]
    ...
    ...
</code></pre>

<p>So far, that all works fine.  However, I'm struggling with a section where I want to only select the MyExtraData where I predicted '1'.  Intuitively, this would simply be something like:</p>

<pre><code>ExtraDataWherePredicted1 = MyExtraData[y_pred &gt; 0]
</code></pre>

<p>However, we're dealing with tensors, not numpy arrays. I tried casting to numpy arrays using eval(), but that didn't work. I also tried various approaches using keras.backend operations such as:</p>

<pre><code>WherePredicted1 = K.greater( y_pred,0)
ExtraDataWherePredicted1 = tf.boolean_mask(MyExtraData, WherePredicted1)
</code></pre>

<p>Which I could then use to weight my loss such as:</p>

<pre><code>return K.mean(K.binary_crossentropy(y_pred,y_true), axis=-1)-(K.mean(ExtraDataWherePredicted1))
</code></pre>

<p>But anything I try throws out various errors...I just can't figure out how to calculate <em>ExtraDataWherePredicted1</em>. I'm also finding it super hard to debug the loss function because I can't print() anything inside it, so it's very hard to double check to see if the arrays/tensors are what I expect them to be.</p>

<p>Any help would be appreciated!</p>
",1,31743,,1,51852,,2018-05-16T15:52:35.383,,1,1,,
49197,1,2019-04-12T14:06:29.210,1,82,<machine-learning><python><scikit-learn><decision-trees><logistic-regression>,What happens to a machine learning technique (specifically Decision Tress and Logistic Regression) if the validation dataset has a new category?,"<p>Let's suppose I have a dataset which has a categorical variable and the problem I am solving is a classification one.</p>

<p>This categorical variable <em>var</em> has ['A','B','C'] as the possible set of data.</p>

<p>What happens to a <strong>decision tree</strong> if a new category 'D' is seen only in the validation data set (meaning: absolutely new data)? <em>Supposing the variable var is a feature used in the tree.</em></p>

<p><strong>With the decision tree:</strong></p>

<p>Does it give an error? The decision tree stops the path and returns the not-final-node's probability?</p>

<p><strong>With the Logistic Regression:</strong></p>

<p>The dummy variables are zero for all the categories (I suppose), and then the model runs normally?</p>
",1,49213,,1,71218,,2019-04-12T20:16:21.143,,1,4,,
41285,1,2018-11-15T21:34:54.793,6,8194,<python><nlp><sentiment-analysis>,any efficient way to find surrounding adjective/verbs with respect to the target phrase in python [updated]?,"<p>I am doing sentiment analysis on given documents. My goal is to find out the closest or surrounding <strong>adjective words with respect to the target phrase</strong> in my sentences. I do have an idea how to extract surrounding words with respect to target phrases. But how do I find out <strong>relatively close or closest</strong> adjective or <code>NNP</code> or <code>VBN</code> or other POS tag with respect to target phrase ?</p>

<p>Here is the sketch idea of how I may get surrounding words with respect to my target phrase.</p>

<pre><code>sentence_List = {
    ""Obviously one of the most important features of any computer is the human interface."", 
    ""Good for everyday computing and web browsing."",
    ""My problem was with DELL Customer Service"", 
    ""I play a lot of casual games online[comma] and the touchpad is very responsive""
}

target_phraseList = {
    ""human interface"",
    ""everyday computing"",
    ""DELL Customer Service"",
    ""touchpad""
}
</code></pre>

<p>Note that my original dataset was given as DataFrame where the list of the sentences and respective target phrases were given. Here I just simulated data as follows:</p>

<pre><code>import pandas as pd
df=pd.Series(sentence_List, target_phraseList)
df=pd.DataFrame(df)
</code></pre>

<p>Here, I tokenize the sentence as follow:</p>

<pre><code>from nltk.tokenize import word_tokenize
tokenized_sents = [word_tokenize(i) for i in sentence_List]
tokenized=[i for i in tokenized_sents]
</code></pre>

<p>Then I try to find out surrounding words with respect to my target phrases by using this <a href=""https://stackoverflow.com/questions/17645701/extract-words-surrounding-a-search-word"">loot at here</a>. However, I want to find out relatively closer or closest <code>adjective</code>, or <code>verbs</code> or <code>VBN</code> with respect to my target phrase.</p>

<p>How can I make this happen? Any idea to get this done? Thanks</p>
",1,42691,,6,45237,45237,2018-12-15T22:41:12.767,2018-11-16T17:04:56.850,1,1,,
37168,1,2018-08-20T05:26:19.593,5,7392,<machine-learning><python><scikit-learn><dataset><regression>,High RMSE and MAE and low MAPE,"<p>I have used a few regression models on the same dataset and obtained error metrics for them as shown below,</p>

<p><a href=""https://i.stack.imgur.com/8FnHa.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/8FnHa.png"" alt=""enter image description here""></a></p>

<p>The RMSE(Root Mean Squared Error) and MAE(Mean Absolute Error) for model A is lower than that of model B where the R2 score is higher in model A. According to my knowledge this means that model A provides better predictions than model B. But when considering the MAPE (Mean Absolute Percentage Error) model B seems to have a lower value than model A. I would really appreciate it if someone could explain why it is so. Thanks in advance. </p>
",1,37172,,5,57889,,2018-08-20T06:44:45.883,,1,4,,
32639,1,2018-06-05T04:10:12.407,0,312,<python><pandas><stata>,Stata-style replace in Python,"<p>In Stata, I can perform a conditional replace using the following code:</p>

<pre><code>replace target_var = new_value if condition_var1 == x &amp; condition_var2 == y
</code></pre>

<p>What's the most pythonic way to reproduce the above on a pandas dataframe? Bonus points if I can throw the new values, and conditions into a dictionary to loop over. </p>

<p>To add a bit more context, I'm trying to clean some geographic data, so I'll have a lot of lines like</p>

<pre><code>replace county_name = new_name_1 if district == X_1 and city == Y_1
....
replace county_name = new_name_N if district == X_N and city == Y_N
</code></pre>

<p>What I've found so far:</p>

<ol>
<li><code>pd.replace</code>  which lets me do stuff like the following, but doesn't seem to accept logical conditions:</li>
</ol>

<p>`</p>

<pre><code>replacements = {   1: 'Male',   2: 'Female',   0: 'Not Recorded' }

df['sex'].replace(replacements, inplace=True)
</code></pre>

<p>`</p>
",1,32648,,0,53163,,2018-06-05T07:46:53.970,,2,1,,
26183,1,2018-01-01T12:18:06.063,4,7592,<python><clustering>,Clustering Data to learned cluster,"<p>I am new to data science, I have clustered some data using Scipy agglomerative clustering. how can I fit new data into the learned clusters?</p>

<pre><code>dm = pdist ( dataset ,lambda u,v: mlpy.dtw_std ( pd.Series(u).dropna().values.tolist(),pd.Series(v).dropna().values.tolist(),dist_only=True ))
z = hac.linkage(dm, method='average')
cluster = hac.fcluster(z, t=100, criterion='distance')
leader = scipy.cluster.hierarchy.fcluster(z, t=100, criterion='distance')
</code></pre>

<p>I would like to cluster new data into the same clusters, How can I do it?</p>
",1,26193,,4,42904,42904,2018-01-02T18:46:36.113,2018-01-02T10:33:40.833,2,1,,
24750,1,2017-11-15T04:07:00.537,0,1154,<python><scikit-learn><clustering><k-means><plotting>,Wrong Graph Plot using K-Means in Python,"<p>This is my first time implementing a Machine Learning Algorithm in Python. I tried implementing K-Means using Python and Sklearn for this <a href=""https://archive.ics.uci.edu/ml/datasets/seeds"" rel=""nofollow noreferrer"">dataset</a>.</p>
<pre><code>from sklearn.cluster import KMeans
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

# Importing the dataset
data = pd.read_csv('dataset.csv')
print(&quot;Input Data and Shape&quot;)
print(data.shape)
data.head()


# Getting the values and plotting it
f1 = data['Area'].values
f2 = data['perimeter'].values
f3 = data['Compactness'].values
f4 = data['length_kernel'].values
f5 = data['width_kernel'].values
f6 = data['asymmetry'].values
f7 = data['length_kernel_groove'].values



X = np.array(list(zip(f1,f2,f3,f4,f5,f6,f7)))
# Number of clusters
kmeans = KMeans(n_clusters=7)
kmeans = kmeans.fit(X)
# Getting the cluster labels
labels = kmeans.predict(X)
# Centroid values
centroids = kmeans.cluster_centers_

plt.scatter(X[:,0], X[:,1],cmap='rainbow')
plt.scatter(centroids[:,0], centroids[:1], color=&quot;black&quot;, marker='*')
plt.show()
</code></pre>
<p>The graph doesn't seem to plot the data correctly. How can I debug this issue?</p>
<p><a href=""https://prnt.sc/ham828"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2oMVC.png"" alt=""Image"" /></a></p>

",1,24761,,0,41913,25180,2023-01-17T17:28:41.763,2023-01-17T17:28:41.763,1,1,,
19882,1,2017-06-21T15:33:34.167,12,37514,<python><regression><xgboost>,Xgboost - How to use feature_importances_ with XGBRegressor()?,"<p>How could we get <code>feature_importances</code> when we are performing regression with <code>XGBRegressor()</code>?</p>

<p>There is something like <code>XGBClassifier().feature_importances_</code>?</p>
",1,19936,,12,32429,,2019-08-09T09:59:50.960,,3,3,,
9598,1,2016-01-04T00:17:58.200,10,4507,<python><scikit-learn><pandas>,Building a machine learning model to predict crop yields based on environmental data,"<p>I have a dataset containing data on temperature, precipitation and soybean yields for a farm for 10 years (2005 - 2014). I would like to predict yields for 2015 based on this data.</p>

<p>Please note that the dataset has DAILY values for temperature and precipitation, but only 1 value per year for the yield, since harvesting of crop happens at end of growing season of crop.</p>

<p>I want to build a regression or some other machine learning based model to predict 2015 yields, based on a regression/some other model derived by studying the relation between yields and temperature and precipitation in previous years.</p>

<p>I am familiar with performing machine learning using scikit-learn. However, not sure how to represent this problem. The tricky part here is that temperature and precipitation are daily but yield is just 1 value per year.</p>

<p>How do I approach this?</p>
",1,9599,,10,12985,,2020-07-31T14:32:22.763,,3,4,,
104727,1,2021-12-03T03:59:43.590,0,72,<python><keras><preprocessing><normalization>,Applying standardization using ImageDataGenerator,"<p>I have a multiclass image dataset ( 8 classes) that is divided as follows, the main folder is called training and I have 8 subfolders with each subfolder for one class. I know how to perform data standardization using ImageDataGenerator :</p>
<pre><code>train_datagen = ImageDataGenerator(
samplewise_center=True,
rescale=1. / 255,
shear_range=30,
zoom_range=30,
rotation_range=20,
width_shift_range=0.2,
height_shift_range=0.2)
</code></pre>
<p>then :</p>
<pre><code>train_datagen.fit(x_train)
</code></pre>
<p>My problem is with <code>x_train</code>, I don't know how I could pass my dataset as <code>x_train</code> ? They are contained in a directory as described above and they are 8 classes ( and hence 8 folders )?</p>
",1,104740,,0,112672,,2021-12-03T13:59:50.730,,1,5,,
118579,1,2023-02-16T23:38:46.250,0,36,<python><python-polars>,polars: parsing a funky datetime format with optional fields,"<p>I am trying to handle data coming from software that has as a terrible format for a time duration: <code>[days-]hours:minutes:seconds[.microseconds]</code>. In case someone else has already traveled this path, I'm fighting with the <code>Elapsed</code> and field from <a href=""https://slurm.schedmd.com/sacct.html"" rel=""nofollow noreferrer"">SLURM's <code>sacct</code> output</a>. (I'm also fighting with <code>ReqMem</code> but that's a problem for another day)</p>
<p>For example, one row might read <code>02:42:05</code> meaning 2 hours, 42 minutes, 5 seconds. Another row might read <code>6-02:42:05</code> which means the same, plus 6 days. Finally, on occasion, the seconds value has a microseconds value following it delimited by a decimal point, for example <code>6-02:42:05.745</code> meaning the same as the prior, plus 745 microseconds. Note that both the day and microsecond fields (and their delimiters) are optional and thus inconsistently present, and I can't just treat seconds as a float.</p>
<p>I need to replace this value with an integer number of seconds, or something suitably equivalent.</p>
<p>I have managed to muddle my way to a solution utilizing <code>apply()</code> and a python function, but I'm aware that this essentially breaks most of the benefit of using Polars? It's faster than the original pandas implementation it seems, but I would love to get as much as I can out of this work. The DataFrame geometry on this dataset is something like 109 columns and over 1 million rows, before filtering.</p>
<p>Here's my working but terrible code:</p>
<pre class=""lang-py prettyprint-override""><code># this is going to be called hundreds of thousands of times, so yea, compiling it is probably helpful
elapsed_time_re = re.compile(r'([0-9]+-)?([0-9]{2}):([0-9]{2}):([0-9.]{2})(\.[0-9]+)?')

def get_elapsed_seconds(data):
    match = elapsed_time_re.match(data)
    if match is None:
        return data
    groups = match.groups('0')
    days         = int(groups[0].strip('-'))
    hours        = int(groups[1])
    minutes      = int(groups[2])
    seconds      = int(groups[3])
    microseconds = int(groups[4].strip('.'))
    if microseconds &gt; 0:
        seconds = seconds + round(microseconds / 1e6)
    return seconds + (minutes * 60) + (hours * 3600) + (days * 86400)

# df is a polars.LazyFrame
df = df.with_columns(pl.col('Elapsed').apply(get_elapsed_seconds))
</code></pre>
<p>I have a thought on how to proceed, but I can't just find my way there:</p>
<ol>
<li>using expression conditionals, concatenate the string literal <code>'0-'</code> to the front of the existing value if it doesn't contain a <code>'-'</code> already. Problem: I can only find how to concatenate dataframes or series data, no matter how I phrase the search, and not how to concatenate a literal string to a column (of dtype str) existing value</li>
<li>parse this new string with <code>strptime()</code>. Problem 1: <code>chrono::format::strftime</code> has no format specifier for microseconds (only nanoseconds), but this part of the timestamp is not useful to me and could be dropped - but how? Problem 2: that'll give me a Datetime, but I don't know how to go from that to a Duration. I think if I create a second Datetime object from <code>0000-00-00 00:00:00</code> or similar and perform an addition between the two, I'd get a Duration object of the correct time?</li>
</ol>
<hr />
<p>For some context: I'm just getting started with Polars. I have almost no prior experience with writing Pandas, and can read it only with constantly looking things up. As such, examples/explanations using Pandas (or comparisons to) won't save me.</p>
<p>I am aware that you can perform some amount of logic with Polars expressions, but it remains opaque to me. One roadblock is that the lambda syntax most examples seem to include is very difficult for me to parse, and even once past that I'm not understanding how one would branch within such expressions.</p>
",1,118588,,0,146055,146055,2023-02-17T18:18:13.050,2023-02-17T18:18:13.050,1,1,,
65983,1,2020-01-06T20:06:07.323,2,58,<machine-learning><python><r><numpy>,Machine learning dataframe dimension concept vs NumPy dimension,"<p>From <a href=""https://rads.stackoverflow.com/amzn/click/com/152095140X"" rel=""nofollow noreferrer"" rel=""nofollow noreferrer"">Machine Learning for Absolute Beginners: A Plain English Introduction</a>:</p>

<blockquote>
  <p>Contained in each column is a feature. A feature is also known as variable, a dimension or an attribute - but they all mean the same thing.</p>
</blockquote>

<p>From <a href=""https://github.com/ageron/handson-ml2/blob/master/tools_numpy.ipynb"" rel=""nofollow noreferrer"">here</a> (the supplement file for <a href=""https://rads.stackoverflow.com/amzn/click/com/1492032646"" rel=""nofollow noreferrer"" rel=""nofollow noreferrer"">this</a> book): </p>

<ul>
<li>In NumPy, each dimension is called an <strong>axis</strong>.</li>
<li>The number of axes is called the <strong>rank</strong>.

<ul>
<li>For example, the above 3x4 matrix is an array of rank 2 (it is 2-dimensional).</li>
<li>The first axis has length 3, the second has length 4.</li>
</ul></li>
<li>An array's list of axis lengths is called the <strong>shape</strong> of the array.

<ul>
<li>For example, the above matrix's shape is <code>(3, 4)</code>.</li>
<li>The rank is equal to the shape's length.</li>
</ul></li>
<li>The <strong>size</strong> of an array is the total number of elements, which is the product of all axis lengths (eg. 3*4=12)</li>
</ul>

<p><strong>Question:</strong> Is the dataframe dimension completely different not related to the NumPy dimension (just same word but describing different concept)?</p>

<p><em>I am learning Python and Machine learning but familial with R and R dataframe from statistical perspective</em></p>
",1,65991,,2,7705,,2020-10-08T09:06:00.657,,1,2,,
492,1,2014-06-19T19:29:57.797,27,13760,<machine-learning><python><neural-network><nlp>,Word2Vec for Named Entity Recognition,"<p>I'm looking to use google's word2vec implementation to build a named entity recognition system.  I've heard that recursive neural nets with back propagation through structure are well suited for named entity recognition tasks, but I've been unable to find a decent implementation or a decent tutorial for that type of model. Because I'm working with an atypical corpus, standard NER tools in NLTK and similar have performed very poorly, and it looks like I'll have to train my own system.   </p>

<p>In short, what resources are available for this kind of problem?  Is there a standard recursive neural net implementation available?</p>
",1,2367,,27,684,21,2020-08-05T08:41:02.810,2017-05-19T16:11:58.100,4,3,,
25893,1,2017-12-21T23:52:07.440,1,337,<machine-learning><python>,Find threshold in large dataset,"<p>I have a problem. I have a data set with some users and their ratings in several movies. The movies are separated into <strong>19 genres</strong>. </p>

<p>I want to cluster the users by their preferences(ratings in the movies). The problem is, that I want to find a $threshold ( θ )$ to do the clustering, but I do not know how to do this, because the data are discrete and I cannot use the statistics methods that I know.
The threshold is the maximum distance that two users can have to be in the same cluster, like 2 users that likes the same genre movies or have little differences in their tastes. </p>

<p>I've tried to find a threshold using simple statistics. For example, for a user sum all of his ratings in a genre and divide the result via the number of ratings and find some means in some genres, but I didn't got an answer. </p>

<p>Note: I must use BSAS</p>
",1,26005,,1,43637,43637,2017-12-26T01:43:16.307,2017-12-25T00:26:59.243,1,2,,
53009,1,2019-05-31T20:51:06.407,5,1005,<python><neural-network>,Approximating multi-variable function with neural network in python,"<p>I'm trying to use 2-5-1 neural network to approximate function <span class=""math-container"">$$x_1 \in[-3,3], x_2\in[-1,3],  f(x_1,x_2)=\sin(2x_1+x_2)$$</span></p>

<p>I used code from <a href=""https://blog.zhaytam.com/2018/08/15/implement-neural-network-backpropagation/"" rel=""nofollow noreferrer"">Implementing a flexible neural network with backpropagation from scratch</a>, to avoid using any complex libraries and tried teaching my network to approximate with following data:</p>

<pre><code># Define dataset
n = 40
np.random.seed(4)
x1_low, x1_up = -3, 3
x2_low, x2_up = -1, 3
x1s = np.random.uniform(x1_low, x1_up, size=n)
x2s = np.random.uniform(x2_low, x2_up, size=n)

Xs = []
for _x1 in x1s:
    for _x2 in x2s:
        Xs.append([_x1, _x2])

Zs = [my_func(_x1, _x2) for _x1, _x2 in Xs]

# Define test data
x1_pred = np.random.uniform(x1_low, x1_up, size=n)
x2_pred = np.random.uniform(x2_low, x2_up, size=n)
Xs_pred = []
for _x1, _x2 in zip(x1_pred, x2_pred):
    Xs_pred.append([_x1, _x2])
actual_ys = [my_func(_x1, _x2) for _x1, _x2 in Xs_pred]

# Train and test neural network
for ee in range(0, 4):
    for e in range(1, 4):
        alpha = e / 10 ** ee
        nn = NeuralNetwork()
        nn.add_layer(Layer(2, 5, 'tanh'))
        nn.add_layer(Layer(5, 1, 'sigmoid'))
        errors = nn.train(Xs, Zs, alpha, 300)
        print('Accuracy: %.2f%%' % (nn.accuracy(nn.predict(Xs_pred), actual_ys) * 100))
        # Plot changes in mse
        plt.plot(errors)
        plt.ylim([0, 1])
        plt.title(str('Changes in MSE - alpha ' + str(alpha)))
        plt.xlabel('Epoch (every 10th)')
        plt.ylabel('MSE')
        plt.show()
</code></pre>

<p>But I can't seem to have MSE lower than <span class=""math-container"">$0.4$</span>. What can I do here to make it more accurate?</p>
",1,53566,,5,75232,38892,2019-06-11T14:20:18.620,2019-06-11T14:20:18.620,3,2,,
40345,1,2018-10-28T14:06:07.533,0,6203,<python><pandas>,how to convert multiple columns into single columns in pandas?,"<p>I have a dataframe like this 
<a href=""https://i.stack.imgur.com/NJZdO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NJZdO.png"" alt=""enter image description here""></a></p>

<p>my desire format is like this 
<a href=""https://i.stack.imgur.com/Wzwes.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Wzwes.png"" alt=""enter image description here""></a></p>

<p>how can i do this?</p>
",1,40349,,0,60550,,2018-10-28T16:26:03.690,,2,1,2018-10-29T22:25:59.647,
93497,1,2021-04-24T16:08:22.793,1,135,<python><numpy><pca><image>,Computing SVD through Eigendecomposition of correlation matrix,"<p>I am following the excellent series on SVD by Steve Brunton from the University of Washington, on YouTube, but I have trouble interpreting his 4th video on the subject.</p>
<p>If I understand correctly, he mentions that one can compute the economy SVD decomposition <span class=""math-container"">$X = \hat{U}\hat{\Sigma}V^T$</span> with the following :</p>
<p><span class=""math-container"">$$X^TX= V\hat{\Sigma}\hat{U}^T\hat{U}\hat{\Sigma}V^T = V\hat{\Sigma}^2V^T \implies X^TXV = V\hat{\Sigma}^2 $$</span>
<span class=""math-container"">$$XX^T= \hat{U}\hat{\Sigma}\hat{V}^T\hat{V}\hat{\Sigma}\hat{U}^T = \hat{U}\hat{\Sigma}^2\hat{U}^T \implies XX^T\hat{U} = \hat{U}\hat{\Sigma}^2 $$</span></p>
<p>Instead of using <code>U,S,VT = svd(X)</code> in Python, I want to try decomposing the image in its SVD, and reconstructing the original using only <span class=""math-container"">$r$</span> values with this technique. I am trying to apply this on a picture of The Starry Night, loaded in a grayscale numpy array <code>X</code>, which I do this way :</p>
<pre><code>r = 10    
XT = X.transpose()
C_1 = XT @ X
C_2 = X @ XT
[Lambda_1, V_hat] = np.linalg.eig(C_1)
[Lambda_2, U_hat] = np.linalg.eig(C_2)
V_hat_T = V_hat.transpose()
X_tilde = U_hat[:,:r] @ np.diag(Lambda_1)[0:r,:r] @ V_hat_T[:r,:]
</code></pre>
<p>But I can't reproduce the image, whatever the value I attribute to <span class=""math-container"">$r$</span>, whereas the product of <code>U @ S @ VT</code> , computed with the <code>svd(X)</code> function, perfectly reconstructs the original picture.</p>
<p>What am I doing wrong? It is certainly superfluous to mention that I am a beginner, and I probably made some big mistake.</p>
",1,93511,,1,116582,43000,2021-04-25T08:14:54.513,2021-04-24T22:26:00.090,1,2,,
73168,1,2020-04-28T15:41:36.640,4,283,<python><keras><time-series>,"Predicting time series, with few historical samples based on similar series","<p>I'm trying to build a model with Keras to predict the time series of a sensor, based on its type and historic data of sensors of the same type. </p>

<p>The figure below shows 3 time series, generated from 3 sensors of the same type, the green dashed line is the new sensor data and the vertical line is where the data for the new sensor end.</p>

<p><a href=""https://i.stack.imgur.com/kTAsN.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kTAsN.png"" alt=""enter image description here""></a></p>

<p>I've tried writing an LSTM network, that returns the hidden state output for each input time step, while the target was the values for each timestamp. Then trying to predict the new time series giving the model a few points of the sensor history data. With no luck :(</p>

<p>So I'm guessing I'm walking on the wrong path. What are the options of predicting a time series with just a few historical samples based on the history of other time series of the same type?</p>

<p>Any help / reference / video would be appericiated</p>
",1,73173,,4,25696,,2020-05-05T13:57:07.843,,2,3,,
73918,1,2020-05-10T12:05:54.703,0,363,<python><pandas><matplotlib>,Bar plot with varying length,"<p>Hello folks, 
            I am trying to plot a grouped bar plot of two variables with varying lengths, which means the x and y length of both the variables are different. The format of the data is given below:
This is for <strong>NRI</strong>.</p>

<p><a href=""https://i.stack.imgur.com/zvAic.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zvAic.png"" alt=""enter image description here""></a></p>

<p>This is for RI. </p>

<p><a href=""https://i.stack.imgur.com/IGIap.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/IGIap.png"" alt=""enter image description here""></a></p>

<p>I want these two datasets to be grouped together. When I try to plot it both the datasets are overlapping each other. If anyone can help me in this regard it will be much appreciated.</p>

<p>Here is the code I used:</p>

<pre><code>import numpy as np
from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt
import matplotlib.path as mpath
from PIL import *
import os
import sys
import csv
from matplotlib import rc, rcParams
import pandas as pd
from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,
                               AutoMinorLocator)
#df = pd.read_csv('E:/v.csv')
df = pd.read_excel('IC12_freq.xlsx',sheet_name='NRI')
df_1 = pd.read_excel('IC12_freq.xlsx',sheet_name='RI')


x = df.IC12.values
x1 = df_1.IC12.values
y = df.FRQ.values
y1 = df_1.FRQ.values
fig, ax = plt.subplots(figsize=(10,10))
ax.bar( x+1.3,y,color = 'w', width = 1.3,hatch='***',edgecolor='k',label='NRI',align='center')
#ax.twinx()
ax.bar( x1,y1,color = 'w', width = 1.3,hatch='/////',edgecolor='k',label='RI',align='center')
#ax.plot(x, y,'ro',color = 'k')
#ax.plot(x1, y1,'ro',color = 'r')
ax.xaxis.set_major_locator(MultipleLocator(10))
ax.xaxis.set_major_formatter(FormatStrFormatter('%d'))
ax.xaxis.set_minor_locator(MultipleLocator(5))
ax.xaxis.set_minor_formatter(FormatStrFormatter('%d'))
# For the minor ticks, use no labels; default NullFormatter.
ax.yaxis.set_major_locator(MultipleLocator(10))
ax.yaxis.set_major_formatter(FormatStrFormatter('%d'))
ax.yaxis.set_minor_locator(MultipleLocator(5))
ax.yaxis.set_minor_formatter(FormatStrFormatter('%d'))

plt.rcParams[""font.weight""] = ""bold""
axis_font = {'fontname':'Arial', 'size':'14'}
tick_font = {'fontname':'Arial', 'size':'5'}

ax.tick_params(which='both', width=2)
ax.tick_params(which='major', length=7)
ax.tick_params(which='minor', length=7)
plt.xlabel('IC12(kt)', fontweight='bold',**axis_font)
#plt.xticklabel(**tick_font)
plt.ylabel('Frequency(%)', fontweight='bold',**axis_font)
ax.set_facecolor(""#f1f1f1"")
ax.spines['top'].set_linewidth(1.5)
ax.spines['right'].set_linewidth(1.5)
ax.spines['bottom'].set_linewidth(1.5)
ax.spines['left'].set_linewidth(1.5)
leg = ax.legend()

#plt.grid(True)
#plt.style.use('ggplot')
##plt.xlabel(""x axis"", **axis_font)
#plt.ylabel(""y axis"", **axis_font)
#plt.bar(y,x)
#plt.savefig('IC12_frq.tif', bbox_inches='tight', dpi=300)
plt.show
</code></pre>
",1,73920,,0,96814,96159,2020-05-10T13:04:11.360,2020-05-10T12:20:50.357,1,4,,
65746,1,2020-01-02T17:19:49.657,0,419,<machine-learning><python><multilabel-classification><nlp>,MultinomialNB predict_proba doesnt return labels with the probability,"<p>I have a model what looks like this</p>

<pre><code>Product_names= [
    'Dress white',
    'Pullover shirt',
    'etc'


]

category_labels = [
   'Female-&gt;Clothes-&gt;T-shirts',
   'Female-&gt;Jeans-&gt;Skinny',
   'etc'
]
</code></pre>

<p>I use the  MultinomialNB classifier to predict a new product name into a category. Before  it gets predicted i want to get the probability of the prediction.</p>

<p>So in psuedo it looks likes this:</p>

<pre><code>clf = MultinomialNB()  
clf.fit(Product_names,category_labels)   
clf.predict_proba('White Pullover shirt')

</code></pre>

<p>What I get is this:</p>

<pre><code>[4.18600796e-03 7.46021220e-04 4.14456233e-05 4.14456233e-05
 1.16047745e-03 6.92141910e-03 3.70938329e-03 1.78216180e-03
 1.49204244e-03 2.15517241e-03 1.03614058e-04 3.48143236e-03
 3.27420424e-03 7.66744032e-04 1.03614058e-03 8.91080902e-04
 8.49635279e-04 2.07228117e-04 4.14456233e-05 4.14456233e-05
 2.44529178e-03 1.84433024e-03 1.67854775e-03 1.01541777e-03
 5.28431698e-03 1.03614058e-03 1.45059682e-04 8.28912467e-05
 9.53249337e-04 1.86505305e-03 2.59035146e-03 2.32509947e-02
 1.24336870e-04 6.21684350e-05 2.69396552e-04 1.90028183e-02
 6.83852785e-04 8.28912467e-05 2.07228117e-05 8.91080902e-04
 5.80238727e-03 3.39854111e-03 1.11488727e-02 6.21684350e-05
 3.31564987e-04 8.18551061e-03 7.46021220e-04 3.52287798e-04
 6.21684350e-05 1.50862069e-02 2.48673740e-04 1.53141578e-02
 4.64190981e-03 4.14456233e-05 2.27950928e-04 1.73242706e-02
 8.89008621e-03 4.14456233e-04 1.28481432e-03 1.65782493e-04
 3.99950265e-03 7.41876658e-03 3.31564987e-04 1.90649867e-03
 1.24336870e-04 7.39804377e-03 1.07758621e-03 6.21684350e-05
 3.39854111e-03 2.19661804e-03 3.85444297e-03 1.88577586e-03
 3.56432361e-03 1.03614058e-03 2.07228117e-05 4.35179045e-04
 6.90069629e-03 1.86505305e-04 2.27950928e-03 2.90119363e-04
 4.39323607e-03 4.14456233e-05 5.18070292e-04 1.80288462e-03
 4.14456233e-05 4.10311671e-03 3.93733422e-04 4.53829576e-03
 6.21684350e-05 1.80288462e-03 5.38793103e-04 2.01011273e-03
 3.68037135e-02 3.50008289e-02 2.63386936e-02 9.82261273e-03
 1.75729443e-02 2.89497679e-02 1.78423408e-02 2.69396552e-03
 3.04418103e-02 4.35179045e-03 3.29492706e-03 1.59565650e-03
 1.67854775e-03 1.58115053e-02 1.83604111e-02 2.34375000e-02
 1.50033156e-02 1.38221154e-02 4.66263263e-03 1.92722149e-03
 1.59565650e-03 1.09830902e-03 3.43998674e-03 2.17589523e-03
 3.81299735e-03 1.11281499e-02 1.45059682e-04 1.91271552e-02
 1.96866711e-03 4.55901857e-04 5.80238727e-04 6.21684350e-05
 1.86505305e-04 6.15467507e-03 8.84864058e-03 3.73010610e-04
 1.24336870e-03 7.04575597e-04 1.03614058e-04 7.66744032e-04
 1.24336870e-04 4.14456233e-04 2.07228117e-04 4.97347480e-04
 1.61637931e-03 1.45059682e-04 1.20192308e-03 3.43998674e-03
 1.24336870e-04 3.00480769e-03 1.71999337e-03 1.03614058e-04
 2.07228117e-03 3.33637268e-03 1.69927056e-03 2.56962865e-03
 3.21203581e-03 5.38793103e-04 2.92191645e-03 4.24817639e-03
 4.90508952e-02 3.35709549e-03 6.00961538e-04 2.27950928e-04
 6.19612069e-03 1.59565650e-02 4.14456233e-03 1.52934350e-02
 8.70358090e-04 8.28912467e-05 1.24336870e-04 1.86505305e-03
 8.28912467e-05 1.80288462e-03 1.99767905e-02 2.63179708e-03
 2.69396552e-04 8.35129310e-03 7.08720159e-03 3.10842175e-04
 2.96336207e-03 3.46070955e-03 1.13975464e-03 3.58504642e-03
 5.59515915e-04 2.23806366e-03 2.07228117e-04 4.43468170e-03
 1.40915119e-02 1.15011605e-02 4.18600796e-03 4.20673077e-03
 7.41876658e-03 5.22214854e-03 2.07228117e-05 1.09001989e-02
 1.69927056e-03 1.45059682e-02 6.77635942e-03 1.46095822e-02
 3.25969828e-02 2.21734085e-03 9.94694960e-04 6.21684350e-05
 1.94794430e-03 3.62649204e-03 4.31034483e-03 3.25348143e-03
 1.28481432e-03 3.31564987e-04 3.93733422e-04 1.03614058e-04
 1.84433024e-03 1.71999337e-03 1.45059682e-04 2.73541114e-03
 2.25878647e-03 2.92191645e-03 3.31564987e-04 1.07758621e-03
 2.27950928e-04 1.65782493e-04 4.35179045e-04 1.26409151e-03
 1.51276525e-03 2.48673740e-04 4.14456233e-05 2.07228117e-04
 2.79757958e-03 8.28912467e-05 2.30023210e-03 1.24336870e-03
 3.31564987e-04 6.21684350e-05 9.11803714e-04 2.07228117e-05
 4.35179045e-04 2.07228117e-05 2.27950928e-04 1.16047745e-03
 9.73972149e-04 3.31564987e-04 3.64721485e-03]
</code></pre>

<p>Its an array of 235 items, It makes sense, because if i group my dataset on category it contains 235 categories. But its missing the Category label with the probability. Does someone know why? Or can someone give me the right directions?</p>

<p>I want to create a flask web application where i can see the probability of the prediction, if its greater then 0.80% for example i can assign it.</p>

<p>Can someone help me with this? I am struggling a couple of days with this issue now :(.</p>

<p>My complete code looks like this</p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
import string
from nltk.corpus import stopwords

#open file
data = pd.read_csv('cats.csv',sep=';')
data['length'] = data['Product Name'].str.len()

#remove all puncs
def text_process(mess):
    # Check characters to see if they are in punctuation
    nopunc = [char for char in mess if char not in string.punctuation]
    # Join the characters again to form the string.
    nopunc = ''.join(nopunc)
    # Now just remove any stopwords
    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english') if word.lower() not in stopwords.words('dutch')]


# Might take awhile...
bow_transformer = CountVectorizer(analyzer=text_process).fit(data['Product Name'])

# Print total number of vocab words
messages_bow = bow_transformer.transform(data['Product Name'])
tfidf_transformer = TfidfTransformer().fit(messages_bow)
messages_tfidf = tfidf_transformer.transform(messages_bow)

from sklearn.naive_bayes import MultinomialNB
spam_detect_model = MultinomialNB().fit(messages_tfidf, data['Category Path'])

message4 = ""Some input data from flask web app ""
bow4 = bow_transformer.transform([message4])
tfidf4 = tfidf_transformer.transform(bow4)

predicted =  spam_detect_model.predict_proba(tfidf4)[0]
print(predicted) 

</code></pre>

<p>Thanks!</p>
",1,65780,,0,87711,87726,2020-01-03T09:00:07.277,2020-01-03T04:18:56.173,1,1,,
29315,1,2018-03-20T14:53:30.840,3,166,<machine-learning><python><neural-network><classification><supervised-learning>,Recognising made up terms,"<p>Say I have a tagging system on an electrical circuit:</p>

<pre>
<b>Name</b>          <b>Description</b>
-------       --------------
BT104         Battery. Power source
SW104         Circuit switch
LBLB-F104     Fluorescent light bulb
LBLB104       Light bulb
...           ...
</pre>

<p>I have a hundreds of tags created by people who should have followed my naming conventions but sometimes they make mistakes add unnecessary additional characters to tag names (i.e. BTwq104 etc.).</p>

<p>Up until now I used regular expressions, that I built over time whilst observing various inconsistencies that users introduce whilst naming different parts of their circuits, to parse the names and tell me what the different elements are. For example: name '<em>BT104</em>' would tell me it's a <em>battery</em> on <em>circuit 104</em>.</p>

<p>I would like to investigate or use a machine learning technique to identify what a tag name is (same way I used regular expressions). Any suggestions and approaches are welcome.</p>

<p>So far I tried <a href=""https://en.wikipedia.org/wiki/Named-entity_recognition"" rel=""nofollow noreferrer"">Named-entity recognition</a> suggested technique ""<strong>Bag of words</strong>"". Followed a few tutorials <a href=""https://pythonprogramminglanguage.com/bag-of-words/"" rel=""nofollow noreferrer"">here</a> and <a href=""https://machinelearnings.co/text-classification-using-neural-networks-f5cd7b8765c6"" rel=""nofollow noreferrer"">here</a> (latter being the most useful in learning). None of them produced wanted results if any. I think that ""Bag of words"" are mostly used for real word rather than made up words.</p>
",1,36381,,3,38467,29575,2018-08-08T07:34:49.883,2018-08-02T16:51:38.527,3,7,,
80207,1,2020-08-13T07:24:02.280,2,314,<machine-learning><python><r><ai>,Significance of Object-Oriented Programming (OOP) in Data Science,"<p>Can someone please explain to me the role of Object-Oriented Programming (OOP) and Object-Oriented Design (OOD) in Data Science? I am from a non-computer science background. Do I need to learn these as well to become a Data Scientist? Also, please tell me if I should be learning Python or R for the same.</p>
",1,80208,,2,,85045,2021-09-20T19:56:22.017,2020-08-15T05:16:35.883,3,1,2020-08-13T12:49:54.743,
98223,1,2021-07-23T12:04:20.503,1,1079,<python><scikit-learn><random-forest><decision-trees>,Getting both results and probabilities running scikit learn random forest,"<p>I have a scikit learn RandomForestClassifier that returns 0s and 1s:</p>
<pre><code>X = [ [2,1,1,1], [2,0,2,1], [3,1,1,1] , [3,1,1,1], [3,1,1,1] ]
y = [ 0, 1, 1, 1, 1 ]

rf = RandomForestClassifier(n_estimators=200, max_depth=5)
rf.fit(X, y)

X_test = [ [2, 0, 1, 0], [2,1,1,1] , [3,1,1,1] ]
y_result = rf.predict(X_test)
</code></pre>
<p>I can rerun the classifier and get probabilities instead of values replacing with</p>
<pre><code>y_result = rf.predict_proba(X_test)
</code></pre>
<p>But how can I get from scikit learn BOTH the result and the probability?</p>
<p>If I cannot get both results in the same run, does it make sense to run the probability and have a threshold, say 0.7, that if the probability is greater than the threshold then the result is 1 ?</p>
",1,98246,,1,76801,76801,2021-07-23T23:36:07.440,2021-07-23T13:07:42.613,1,5,,
69246,1,2020-03-06T00:03:52.753,0,100,<python><python-3.x>,"PCA method for feature selection - How to solve the raise Exception error (""Data must be 1-dimensional"")?","<pre><code>#Função que permitirá rankear as features mais importantes em um barhplot
def ranks_PCA (x_train, y_train, features_train, RESULT_PATH='Results'):
    print(""\nMétodo PCA"")

    pca = PCA(n_components=58)
    pca.fit_transform(x_train)

    imp_array = np.array(pca.components_)
    imp_order = imp_array.argsort()
    ranks = imp_order.argsort()

    # Plot PCA
    imp = pd.Series(pca.components_, index=x_train.columns)
    imp = imp.sort_values()

    imp.plot(kind=""barh"")
    plt.xlabel(""Importance"")
    plt.ylabel(""Features"")
    plt.title(""Feature importance using PCA"")
    # plt.show()
    plt.savefig(RESULT_PATH + '/ranks_DT.png', bbox_inches='tight')

    return ranks
</code></pre>

<hr>

<pre><code>#Função para predição das features dos dados de teste
def predict_PCA(x_test_sel, k_vetor, y_train):
    model = decomposition.PCA()
    model.fit(k_vetor, y_train)
    y_predict = model.predict(x_test_sel)
    return(y_predict)
</code></pre>

<hr>

<pre><code>#Função que calcula o ranking dos dados de treinamento
ranks4 = frk.ranks_PCA(x_train, y_train, features_train, RESULT_PATH)
</code></pre>

<p>I have doubts if this implementation is correct to obtain more important features. When trying to run this code, I get the following error:</p>

<blockquote>
  <p>Traceback (most recent call last): File ""feat_test.py"", line 235, in
  'Results/PDBbind2018_F58_Delta_pKd') File ""feat_test.py"", line 78, in
  run_experiment ranks4 = frk.ranks_PCA(x_train, y_train,
  features_train, RESULT_PATH) File ""C:\Users\Patricia\Desktop\VT-58 -
  Cópia\feature-importance\feature_rank_
  ensemble\Scripts\feature_ranks.py"", line 121, in ranks_PCA imp =
  pd.Series(pca.components_, index=x_train.columns) File
  ""C:\Users\Patricia\Desktop\VT-58 -
  Cópia\feature-importance\feature_rank_
  ensemble\env\lib\site-packages\pandas\core\series.py"", line 305, in
  init data = sanitize_array(data, index, dtype, copy,
  raise_cast_failure=True) File ""C:\Users\Patricia\Desktop\VT-58 -
  Cópia\feature-importance\feature_rank_
  ensemble\env\lib\site-packages\pandas\core\construction.py"", line 482,
  in saniti ze_array raise Exception(""Data must be 1-dimensional"")</p>
</blockquote>

<p>Can anybody help me?</p>
",1,69296,,0,90151,,2020-03-06T22:03:55.923,,1,1,,
26283,1,2018-01-04T13:03:28.490,14,79996,<python><scikit-learn><data-mining><random-forest>,How can I fit categorical data types for random forest classification?,"<p>I need to find the accuracy of a training dataset by applying Random Forest Algorithm. But my the type of my data set are both categorical and numeric. When I tried to fit those data, I get an error.</p>

<blockquote>
  <p><em>'Input contains NaN, infinity or a value too large for dtype('float32')'.</em></p>
</blockquote>

<p>May be the problem is for object data types. How can I fit categorical data without transforming for applying RF?</p>

<p>Here's my code.  </p>

<p><a href=""https://i.stack.imgur.com/V6sHp.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/V6sHp.png"" alt=""screenshot""></a></p>

<p><a href=""https://i.stack.imgur.com/k7nOE.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/k7nOE.png"" alt=""screenshot""></a></p>

<p><a href=""https://i.stack.imgur.com/3NXtO.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/3NXtO.png"" alt=""screenshot""></a></p>
",1,26284,,14,43455,55122,2020-06-16T21:50:26.260,2020-04-27T21:26:23.093,3,2,,
37520,1,2018-08-28T15:35:24.490,1,56,<machine-learning><python><deep-learning>,Can we use a neural network to perform arithmetic operation between 2 numbers?,"<p>How to develop a neural network which can perform subtraction?</p>
",1,37524,,1,54050,,2018-08-28T18:07:16.550,,2,2,,
51935,1,2019-05-14T09:45:32.480,1,1616,<machine-learning><python><feature-selection><numpy><kaggle>,Is numpy.corrcoef() enough to find correlation?,"<p>I am currently working through Kaggle's titanic competition and I'm trying to figure out the correlation between the <code>Survived</code> column and other columns.  I am using <code>numpy.corrcoef()</code> to matrix the correlation between the columns and here is what I have:</p>

<pre><code>The correlation between pClass &amp; Survived is: [[ 1.         -0.33848104]
 [-0.33848104  1.        ]]

The correlation between Sex &amp; Survived is: [[ 1.         -0.54335138]
 [-0.54335138  1.        ]]

The correlation between Age &amp; Survived is:[[ 1.         -0.07065723]
 [-0.07065723  1.        ]]

The correlation between Fare &amp; Survived is: [[1.         0.25730652]
 [0.25730652 1.        ]]

The correlation between Parent-Children &amp; Survived is: [[1.         0.08162941]
 [0.08162941 1.        ]]

The correlation between Sibling-Spouse &amp; Survived is: [[ 1.        -0.0353225]
 [-0.0353225  1.       ]]

The correlation between Embarked &amp; Survived is: [[ 1.         -0.16767531]
 [-0.16767531  1.        ]]
</code></pre>

<p>There should be higher correlation between <code>Survived</code> and [<code>pClass</code>, <code>sex</code>, <code>Sibling-Spouse</code>] and yet the values are really low.  I'm new to this so I understand that a simple method is not the best way to find correlations but at the moment, this doesn't add up.</p>

<p>This is my full code (without the <code>printf()</code> calls):</p>

<pre><code>import pandas as pd
import numpy as np

train = pd.read_csv(""https://raw.githubusercontent.com/oo92/Titanic-Kaggle/master/train.csv"")
test = pd.read_csv(""https://raw.githubusercontent.com/oo92/Titanic-Kaggle/master/test.csv"")

survived = train['Survived']
pClass = train['Pclass']
sex = train['Sex'].replace(['female', 'male'], [0, 1])
age = train['Age'].fillna(round(float(np.mean(train['Age'].dropna()))))
fare = train['Fare']
parch = train['Parch']
sibSp = train['SibSp']
embarked = train['Embarked'].replace(['C', 'Q', 'S'], [1, 2, 3])
</code></pre>
",1,51942,,1,73912,71218,2019-05-14T13:45:32.947,2019-05-14T13:45:32.947,2,2,,
94067,1,2021-05-06T11:23:28.907,2,147,<machine-learning><python><classification><k-nn><ai>,Machine Learning - Euclidian Distance Classifier exercise,"<p>I'm taking part in an elective subject at university which mainly focuses on the foundations of Machine Learning.
Now we got our first exercise - this task should be done practically in any language (I've chosen Python). Our teacher doesn't explain the relations between theory and practice well and so it's hard for all of us to follow along - so I decided to post this question here. I don't want anyone to give me a solution, I just don't understand what he wants and may be a hint how to approach this question.:</p>
<p>Here is the full exercise:</p>
<blockquote>
<p>Euclidean distance classifier</p>
<ol>
<li><p>Develop an Euclidian distance classifier as below: Generate 1000
random points corresponding to each class out of 3 classes with
feature size 2 for a 3-class classification problem. For the
simplicity consider the classes following N([0 1 2], I), N([0 0 1], I)
and N([1 0 0],I) respectively.</p>
</li>
<li><p>Generate the output an 1000-dimensional vector whose ith component
contains the class where the corresponding vector is assigned,
according to the minimum Euclidean distance classifier.</p>
</li>
</ol>
</blockquote>
<p>I understand that I should generate random points with two features which are belonging to one of the three classes - okay. But I don't get the second part of the sentence. The classes are normally distributes with a mean(?)-vector of [0, 1, 2], [0, 0, 1] and [1, 0, 0]?</p>
<ol>
<li>For what does the second paramter I stand in the normal distribution</li>
<li>Does the vector stand for the position/mean of the multivariate normal distribution?</li>
<li>How would you approach this question? Using a k nearest neighbor algorithm?</li>
</ol>
<p>Thanks for any helpful answers!</p>
<p>Max</p>
",1,94069,,2,117221,,2021-05-06T13:14:55.997,,1,1,2021-05-15T13:10:14.850,
6727,1,2015-08-08T11:14:35.630,3,5667,<python><csv>,Merging repeating data cells in csv,"<p>I have a CSV file with around 1 Million rows. 
Let say its have details like </p>

<pre><code>Name      |   Age   | Salary 
name 1      52       10000
name 2      55       10043 
name 3      50       100054
name 2      55       10023
name 1      52       100322...
</code></pre>

<p>and soon .</p>

<p>but i need to merge the redundant details .
and need a output like </p>

<pre><code>Name      |   Age   | Salary 
name 1      52       110322*
name 2      55       20066 *
name 3      50       100054 
</code></pre>

<p>you might notice that the repeating Name 1 and Name 2 details are merged and the Salary values are added .So i'm looking for a way to apply this change to my original data set. so i need a python script to fix my problem . </p>
",1,6747,,3,9035,,2015-08-14T17:21:38.663,,3,1,,
15812,1,2016-12-19T11:22:03.587,9,27413,<python><classification><data-mining><time-series><pandas>,Check similarity between time series,"<p>I have time series of parameters <code>A</code>, <code>B</code>, <code>C</code> and <code>D</code>. All of them are under influence of the same major conditions, but each one has minor differences. They are placed in different locations, <code>A</code>, <code>B</code>, <code>C</code> are in <code>local1</code> and <code>D</code> is in <code>local2</code>.</p>

<p>I would like to know which one (<code>A</code>, <code>B</code>, <code>C</code>) has the major similarity to <code>D</code>. How should I approach this issue? </p>
",1,15814,,9,27194,,2020-12-04T21:54:36.503,,6,2,,
86748,1,2020-12-16T03:07:24.543,0,26,<python><r><algorithms><text>,How to Identify Repeating Data Entries when the Repeated Entries are Spelled or Constructed Differently,"<p>I have a dataset of entries and a variable for the owner of the entry. Some of these people occur more than once. However, the names are sometimes written differently. I want to eventually be able to aggregate the other data to the single owner. These are the names of business owners so sometimes it's a singular name, sometimes it's more than one name, and sometimes it's just the company name. Here's an example of some of the styles of names in the data:</p>
<ul>
<li>DOE JOHN</li>
<li>DOE JOHN J</li>
<li>DOE, JOHN</li>
<li>DOE, JOHN + JANE</li>
<li>DOE JOHN + JANE</li>
<li>JOHN DOE J ETAL % JOHN J DOE</li>
<li>COMPANY CO</li>
</ul>
<p>I've never done anything like this before. How could I go about identifying some of the same people? Is there a way to create an index to identify the similarity between these groups? Most of the ones I've seen are for longer text. Is there an index well suited for this?</p>
<p>I apologize if this is too basic a question. I'm new to doing things like this and I'm not sure if I know exactly what to search for. I'm most comfortable with Stata and R but I've used Python before and I could eventually figure out how to do something with that.</p>
",1,86760,,0,108911,,2020-12-16T09:08:15.683,,1,2,,
8657,1,2015-10-30T04:21:27.737,7,18994,<python><logistic-regression><gradient-descent>,Trying to understand Logistic Regression Implementation,"<p>I'm currently using the following code as a starting point to deepen my understanding of regularized logistic regression.  As a first pass I'm just trying to do a binary classification on part of the iris data set.  </p>

<p>One problem I think I have encountered is that the negative log-loss (computed with loss and stored in loss_vec) doesn't change much from one iteration to the next.</p>

<p>Another challenge I am facing is trying to figure out how to plot the decision boundary once I have learned the logistic regression coefficients. Using the coefficients to plot the 0.5 decision boundary is way off.  This makes me think I have made a mistake somewhere</p>

<p><a href=""http://fa.bianp.net/blog/2013/numerical-optimizers-for-logistic-regression/"" rel=""noreferrer"">http://fa.bianp.net/blog/2013/numerical-optimizers-for-logistic-regression/</a></p>



<pre><code>import numpy as np
import matplotlib.pyplot as plt
from sklearn import linear_model, datasets


iris = datasets.load_iris()
X = iris.data[:, :2]  # we only take the first two features.
Y = iris.target


X = X[:100,:]
Y = Y[:100]

def phi(t):
    # logistic function, returns 1 / (1 + exp(-t))
    idx = t &gt; 0
    out = np.empty(t.size, dtype=np.float)
    out[idx] = 1. / (1 + np.exp(-t[idx]))
    exp_t = np.exp(t[~idx])
    out[~idx] = exp_t / (1. + exp_t)
    return out


def loss(x0, X, y, alpha):
    # logistic loss function, returns Sum{-log(phi(t))}
    #x0 is the weight vector w are the paramaters, c is the bias term
    w, c = x0[:X.shape[1]], x0[-1]
    z = X.dot(w) + c
    yz = y * z
    idx = yz &gt; 0
    out = np.zeros_like(yz)
    out[idx] = np.log(1 + np.exp(-yz[idx]))
    out[~idx] = (-yz[~idx] + np.log(1 + np.exp(yz[~idx])))
    out = out.sum() / X.shape[0] + .5 * alpha * w.dot(w)
    return out


def gradient(x0, X, y, alpha):
    # gradient of the logistic loss
    w, c = x0[:X.shape[1]], x0[-1]
    z = X.dot(w) + c
    z = phi(y * z)
    z0 = (z - 1) * y
    grad_w = X.T.dot(z0) / X.shape[0] + alpha * w
    grad_c = z0.sum() / X.shape[0]
    return np.concatenate((grad_w, [grad_c]))


def bgd(X, y, alpha, max_iter):
    step_sizes = np.array([100,10,1,.1,.01,.001,.0001,.00001])
    iter_no = 0
    x0 = np.random.random(X.shape[1] + 1) #initialize weight vector

    #placeholder for coefficients to test against the loss function
    next_thetas = np.zeros((step_sizes.shape[0],X.shape[1]+1) )   
    J = loss(x0,X,y,alpha)
    running_loss = []
    while iter_no &lt; max_iter:
        grad = gradient(x0,X,y,alpha)
        next_thetas = -(np.outer(step_sizes,grad)-x0)
        loss_vec = []
        for i in range(np.shape(next_thetas)[0]):
            loss_vec.append(loss(next_thetas[i],X,y,alpha))
        ind = np.argmin(loss_vec)
        x0 = next_thetas[ind]
        if iter_no % 500 == 0:
            running_loss.append(loss(x0,X,y,alpha))
        iter_no += 1  
    return next_thetas
</code></pre>
",1,8663,,7,13775,13775,2018-11-11T23:18:44.517,2015-10-30T17:28:51.990,2,3,,
92968,1,2021-04-12T13:21:50.017,4,767,<python><scikit-learn>,Why use fit when already have fit_transform?,"<p>This is a follow up question to: <a href=""https://datascience.stackexchange.com/questions/12321/whats-the-difference-between-fit-and-fit-transform-in-scikit-learn-models/92921"">What&#39;s the difference between fit and fit_transform in scikit-learn models?</a></p>
<p>I want to know why should we use <code>fit</code> at all when we have <code>fit_transform</code> which is much faster than using <code>fit</code> and <code>transform</code> separately? After all we will always transform the training data after fitting it. Do we have any use of <code>fit</code> all by itself?</p>
",1,92972,,4,115840,43000,2022-06-27T09:33:20.187,2021-12-17T11:38:05.530,2,1,,
18236,1,2017-04-10T05:40:00.527,2,1843,<python><regex>,Regular expression in python -,"<p>I want to extract the values of the below text</p>

<pre><code>Paﬁent Name : Thomas Joseph MRNO : DQ026151?
Doctor : Haneef M An : 513! Gandar : Male
Admission Data : 19-Feb-2V'3‘¥T12:2'$ PM Bill No : IDOGIII.-H-17
Discharge Date : 22-Feb-20$? 1D:5‘F AM Bill Dale : E2-Feb-2017
</code></pre>

<p>extract only the values of the field names for example,</p>

<p>Thomas Joseph from the field name Pateint name, similarly for others field names and save the output to excel</p>

<p>Python code for the above</p>

<p>My attempt -</p>

<pre><code>text = pt.image_to_string(img1)
print(text)
s = re.findall(r'\s:\s(\w+)', text)
print (s)
</code></pre>
",1,18241,,2,29580,11097,2017-04-10T09:53:10.273,2017-04-10T05:40:23.840,2,7,,
58861,1,2019-09-08T15:51:44.180,1,2118,<python><nlp><named-entity-recognition>,How to extract location related terms from raw text in python,"<p>I want to extract location related keywords from raw text in python.
I have already tried spacy but the results were not good and I just got names of countries while I want fine-grained location mentions like streets or neighborhoods in a city.
I also have tried stanford NER but the problem is it is too slow and I need to produce my results with a good speed.
Is there any package or library for python which can solve my problem?
Also if there is any other suggestions which are not for python I will be glad to hear them.</p>
",1,61188,,1,80850,,2019-10-03T10:34:02.327,,1,3,,
23402,1,2017-09-28T22:43:10.070,2,274,<python><clustering><k-means>,Confused by kmeans results,"<p>I am using kmeans to cluster some data with 2 features. Not sure I understand why kmeans is producing the clusters I see:</p>

<p><a href=""https://i.stack.imgur.com/YMdou.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/YMdou.png"" alt=""kmeans results""></a></p>

<p>Why would kmeans not cluster these points in a way that matches what we would expect visually looking at the data? Why are seemingly random points in the middle of visual clusters being put into a second cluster like that?</p>

<p>The code I am running:</p>

<pre><code>cols = ['col1', 'col2']
features = map(lambda x: df[x], cols)
input = np.matrix(list(zip(*features)))

scaler = StandardScaler()
scaler.fit(input)
input_scaled = scaler.transform(input)

algo = KMeans(n_clusters=2)
algo.fit(input_scaled)
df['cluster'] = pd.Series(algo.labels_)

sns.lmplot(x=cols[0],y=cols[1],data=df, fit_reg=False, hue='cluster')
</code></pre>
",1,23479,,2,39814,,2018-01-30T23:59:18.493,,1,11,,
58631,1,2019-09-03T20:36:30.333,8,3086,<python><prediction><class-imbalance>,Is There a Way to Re-Calibrate Predicted Probabilities After Using Class Weights?,"<p>I have classification data with far more negative instances than positive instances. I have used class weights in my models and have achieved the discrimination I want but the predicted probabilities from the models do not match the actual probabilities in the modeling data. </p>

<p>Is there a way to adjust the predicted probabilities from the class weighted models to match the actual probabilities in the data? I have seen equations for under-sampling (<a href=""https://www3.nd.edu/~rjohns15/content/papers/ssci2015_calibrating.pdf"" rel=""noreferrer"">https://www3.nd.edu/~rjohns15/content/papers/ssci2015_calibrating.pdf</a>) but they don't seem to work for class weights. I have searched online for an answer but maybe I am not using the right language?</p>

<p>Thank you!</p>
",1,58899,,8,58488,,2020-07-12T23:43:20.383,,2,3,,
55485,1,2019-07-11T07:16:35.140,2,2591,<machine-learning><python><pandas><lstm>,'tuple' object is not callable while reshaping training data using python,"<p>I have data csv file with three inputs names temperature, humidity, wind. Here I want to predict temperature value in every 60 minute using LSTM model. </p>

<p>Here I write the code to reshape the train . But I got an error <code>tuple' object is not callable</code></p>

<p>My code:</p>

<pre><code>data = pd.read_csv('data6.csv' )
data['date'] = pd.to_datetime(data['date'] + "" "" + data['time'], format='%m/%d/%Y %H:%M:%S')
data.set_index('date', inplace=True)
data = data.values

scaler = MinMaxScaler(feature_range=(0, 1))
data = scaler.fit_transform(data)

train_size = int(len(data) * 0.67)
test_size = len(data) - train_size
train, test = data[0:train_size,:], data[train_size:len(data),:]

X = 1
n_out = 1

x,y=[],[]
start =0
data = train.reshape(train.shape(train.shape[0] ,3, train.shape[1]))
for _ in range(len(data)):
  in_end = start+X
  out_end= in_end + n_out
  if out_end &lt; len(data):
    x_input = data[start:in_end]
    x.append(x_input)
    y.append(data[in_end:out_end,0])
start +=1

x = np.asanyarray(x)
y = np.asanyarray(y)
</code></pre>

<p><a href=""https://docs.google.com/spreadsheets/d/1WWq1qhqi4bGzNir_svQV7VstBkGbocToipPCY83Cclc/edit?usp=drive_web&amp;ouid=113105666949273151155"" rel=""nofollow noreferrer"">My csv file</a></p>

<p>Error:</p>

<blockquote>
  <p>data = train.reshape(train.shape(train.shape[0] ,3, train.shape<a href=""https://docs.google.com/spreadsheets/d/1WWq1qhqi4bGzNir_svQV7VstBkGbocToipPCY83Cclc/edit?usp=drive_web&amp;ouid=113105666949273151155"" rel=""nofollow noreferrer"">1</a>))</p>
</blockquote>

<p>Error image:
<a href=""https://i.stack.imgur.com/cXxGd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/cXxGd.png"" alt=""enter image description here""></a></p>

<p>Can anyone help me to solve this problem?</p>

<p>Error:</p>

<p><a href=""https://i.stack.imgur.com/CGrz3.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/CGrz3.png"" alt=""enter image description here""></a></p>
",1,55492,,2,77356,77356,2019-07-11T15:17:47.210,2019-07-11T14:22:23.283,2,10,,
40477,1,2018-10-31T02:32:07.673,0,898,<python><keras><cnn><numpy><reshape>,keras Sequential CNN for image data reshaping data issues,"<p>I am new at keras and CNN and am working on building at CNN  for sequential analysis of movement in a image. What I am having issues with is the reshaping the data and the labels that go into the fitting and testing the data for the model.
So the original size/shape of the numpy file is (18, 50,50,16) which is saved in a text file from another program.  I know the text file is ok because I can read it in and display it correctly with the debug_potion method. So that looks good. There are 18 images in the folder for the data and otherData variable. I dont really know what the 16 is but the image size are 50*50. </p>

<p>The issue is the reshaping of that data is the problem. Can anyone suggest how to reshape this data in a way that I can train it. I think I need to do onehot encoding but not quite sure how. Any help will be appreciated. Here is what I have so far.</p>

<pre><code>def debug_potion(data):
    for i in range(0, 16):
        # get for each joint
        potion = Potion(data)
        plt.show(potion.display(joints=[i, i], channels=[0, 1, 2]))

# Build Model for sequential building
def create_model(input_shape):
    model = Sequential()
    model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))

    model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])
    return model


def read_in_data(file):
    with open(file, ""rb"") as f:
        return pickle.load(f)


batch_size = 1
num_classes = 2
epochs = 12

# input image dimensions
img_rows, img_cols = 50, 50
input_shape = (img_rows, img_cols, 16)

data = read_in_data(""heatmap.txt"")
otherData = read_in_data(""othermove.txt"")


data = np.array(data)
otherData = np.array(otherData)
print(""Data shape"", otherData.shape)


xtrain = []
ytrain = []
xtest  = []
ytest  = []

for x in range(0,len(data)):
    if x &lt; 15:
        xtrain.append(data)
        ytrain.append((""FWAC"", num_classes))
    else:
        xtest.append(data)
        ytest.append((""FWAC"", num_classes))

for x in range(0,len(otherData)):
    if x &lt; 15:
        xtrain.append(otherData)
        ytrain.append((""Other"", num_classes))
    else:
        xtest.append(otherData)
        ytest.append((""Other"", num_classes))

#Create x test and train arrays
xtrain = np.array(xtrain)
xtrain = xtrain.reshape(30,img_rows, img_cols,16)
ytrain = np.array(ytrain)

xtest = np.array(xtest)
xtest = xtest.reshape(108, img_rows, img_cols,16)
ytest = np.array(ytest)
print(xtrain.shape)
print(xtest.shape)
print(ytrain.shape)
print(ytest.shape)

# Build Model
model = create_model(input_shape)

model.fit(xtrain, ytrain,
          batch_size = batch_size,
          epochs = epochs,
          verbose=1,
          validation_data=(xtest, ytest))

score = model.evaluate(xtest,ytest, verbose=0)
print((""Test loss"", score[0]))
print(""Test Accuracy"", score[1])
</code></pre>
",1,40543,,0,61156,61156,2018-11-06T03:53:20.257,2018-10-31T02:43:17.980,1,1,,
57226,1,2019-08-08T11:53:43.390,0,492,<python><visualization><matplotlib>,How to rotate the plot and find minimum point?,"<p>I want to rotate the below curve to 45 degree and then find the minimum point.
<a href=""https://i.stack.imgur.com/bepcm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bepcm.png"" alt=""enter image description here""></a></p>

<p>For this, I have tried with below code:</p>

<pre><code>def rotate_vector(data, angle):
    theta = np.radians(angle)
    co = np.cos(theta)
    si = np.sin(theta)
    rotation_matrix = np.array(((co,-si), (si, co)))
    return np.matmul(rotation_matrix, data)


rotated_vector = rotate_vector(data, -45)
elbow = rotated_vector.min()
</code></pre>

<p>But what I get is this curve:
<a href=""https://i.stack.imgur.com/OwKLl.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OwKLl.png"" alt=""enter image description here""></a></p>
",1,57270,,0,78416,,2019-08-09T09:48:48.440,,1,4,,
77292,1,2020-07-07T09:50:25.883,2,325,<python><pandas><interpolation>,Find the best interpolation method for missing observations,"<p>I have a database  which has measurements of objects every day every hour.
However, some data is missing and I don't have measurements for all the hours.
in order to get over this challenge I have used different interpolations methods in order to create this missing data (with pandas).
So now I have several databases with those interpolations methods, and I need only one.</p>
<p><strong>My question is how can I determine which interpolation is the best interpolation method?</strong></p>
<p>I have researched the internet but mainly found explanation abut how to interpolate data  but not how to choose the best method and how can I visualize it.</p>
",1,77294,,2,98535,98535,2020-07-07T10:26:41.733,2020-07-07T10:19:40.263,1,1,,
398,1,2014-06-16T07:32:29.137,8,988,<python><visualization>,What to consider before learning a new language for data analysis,"<p>I'm currently in the very early stages of preparing a new research-project (still at the funding-application stage), and expect that data-analysis and especially visualisation tools will play a role in this project.</p>

<p>In view of this I face the following dilemma: Should I learn Python to be able to use its extensive scientific libraries (Pandas, Numpy, Scipy, ...), or should I just dive into similar packages of a language I'm already acquainted with (Racket, or to a lesser extent Scala)?</p>

<p>(Ideally I would learn Python in parallel with using statistical libraries in Racket, but I'm not sure I'll have time for both)</p>

<p>I'm not looking for an answer to this dilemma, but rather for feedback on my different considerations:</p>

<p>My current position is as follows:</p>

<p><strong>In favour of Python:</strong></p>

<ul>
<li>Extensively used libraries</li>
<li>Widely used (may be decisive in case of collaboration with others)</li>
<li>A lot of online material to start learning it</li>
<li>Conferences that are specifically dedicated to Scientific Computing with Python</li>
<li>Learning Python won't be a waste of time anyway</li>
</ul>

<p><strong>In favour of a language I already know:</strong></p>

<ul>
<li>It's a way to deepen my knowledge of one language rather than getting superficial knowledge of one more language (under the motto: you should at least know one language really well)</li>
<li>It is feasible. Both Racket and Scala have good mathematics and statistics libraries</li>
<li>I can start right away with learning what I need to know rather than first having to learn the basics</li>
</ul>

<p><strong>Two concrete questions:</strong></p>

<ol>
<li>What am I forgetting?</li>
<li>How big of a nuisance could the Python 2 vs 3 issue be?</li>
</ol>
",1,405,,8,872,,2014-06-16T15:00:04.577,,3,2,,
96645,1,2021-06-15T09:03:40.657,1,104,<python><sentiment-analysis>,How can the accuracy of the dictionary-based approach be measured and improved?,"<p>I recently used TextBlob and the NLTK library to do sentiment analysis. I used both dictionary-based and machine learning-based approaches. It is relatively easy to measure accuracy when we use machine learning approach, just define a test set. The same goes for improving accuracy, just modify the training set.</p>
<p>But what about dictionary-based approaches instead? How do you <strong>measure</strong> and <strong>improve</strong> their accuracy?</p>
",1,96729,,1,119351,119351,2021-06-16T23:01:46.047,2021-06-16T23:01:46.047,1,2,,
73193,1,2020-04-28T22:35:53.573,1,182,<machine-learning><python><regression><predictive-modeling>,How to choose best model for Regression?,"<p>I'm building a model to predict the flight delay. My dataset contains the following columns:</p>

<p>FL_DATE (contains months(1-12)), OP_CARRIER (One hot encoded data of Carrier names), ORIGIN(One hot encoded data of Origin Airport), Dest(one-hot encoded data of Dest Airport), CRS_DEP_TIME(Intended time of departure ex: 1015), DEP_TIME(Actual time of departure ex: 1017),DEP_DELAY(the difference between crs-dep ex: -2), ARR_DELAY(arrival delay ex: -2)</p>

<p><a href=""https://i.stack.imgur.com/WCcsP.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WCcsP.jpg"" alt=""Screenshot of first 10 rows of my dataset""></a></p>

<p>My target variable is ARR_DELAY. After checking my data, I have decided it is a regression problem. However, I'm not sure what method do I need to use for selecting the appropriate columns. On the other hand, I was plotting each column with ARR_DELAY to check their relation and got something like this: FL_TIME vs ARR_DELAY
<a href=""https://i.stack.imgur.com/OI1rl.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OI1rl.jpg"" alt=""enter image description here""></a></p>

<p>In such scenarios, if I have to build a model for such data which regression technique should I use?</p>

<p>PS: I'm new to Machine Learning. Please correct me If I'm heading in the wrong direction</p>
",1,73200,,1,95993,,2020-04-29T01:50:47.400,,2,1,,
45663,1,2019-02-15T20:49:28.663,5,3111,<machine-learning><python><scikit-learn><pandas>,Is shuffling training data beneficial for machine learning?,"<p>I was curious to know if shuffling ML training data is beneficial to better results?</p>

<p>Sorry not a lot of wisdom here, but I have been reading a post from <a href=""https://pythonprogramming.net/shuffling-data-learning/"" rel=""noreferrer"">pythonprogramming.net for this topic</a>.</p>

<p>I copied this function from the post and modified to just save my shuffled data to csv file.</p>

<pre><code>def Randomizing():
    df2 = df.reindex(np.random.permutation(df.index))
    df2.to_csv('C:\\Users\\Machine-Learning-Electric-Data\\randomized.csv')

Randomizing()
</code></pre>

<p>What appears to happen is only the index gets shuffled and all other data stays the same. I have many columns in my pd dataframe where I would need to keep all rows the same. (randomly shuffle all rows, its time series data) <strong><em>If this is beneficial</em></strong> can someone give me a tip on how to randomly shuffle my data more than just the index?</p>
",1,45664,,5,66386,67483,2021-09-21T04:56:02.890,2019-02-16T09:08:25.430,1,2,,
84179,1,2020-10-18T16:26:54.117,2,61,<python><classification><text-mining><correlation>,"Correlation among features (e.g. doc length, punctuation, ... ) in classifying spam emails","<p>I extracted some other features from my dataset regarding punctuation, capital letters, upper case words. I got these value:</p>
<p><a href=""https://i.stack.imgur.com/3LjM7.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/3LjM7.jpg"" alt=""enter image description here"" /></a></p>
<p>looking at the correlation with my target variable (1=spam, 0=not spam), using .corr() in python.
BT stands for binary text, e.g., and BS stands for binary summary, where I assign 1 or 0 based on the presence of a capital letter in the text/summary, or upper case word, or...</p>
<p>Do you think that features like these can be useful in model building? I cannot see very strong correlations, but I would like to determine if an email can be spam or not based also on features like these (number of character/text length; presence of !, upper case words,....).</p>
<p>I have around 1000 emails, but only 50 are spam (maybe too small to extract useful information).
However, I had to extract these information, so it is a new dataset, built on my own, so I could not get many more spam emails (and I would like to not use datasets from kaggle, for instance).</p>
<p>What do you think?</p>
",1,84182,,2,96922,,2020-10-18T22:38:04.087,,1,3,,
104775,1,2021-12-04T18:03:34.720,1,31,<machine-learning><python><neural-network>,Help starting ML project in pythin(novice),"<p>I am starting a machine learning project (for fun!), but I am not sure where to start from... I am fairly new to ML so any hints are appreciated.</p>
<p>I have a relatively large data-set where each input is a list of roughly 300 integers (mainly zeros). The output is a list of 20ish integers. The goal is to predict the output given a random input (obviously). And I am not sure what is the best method for that. I have started reading a bit into neural networks which seem like it could be a good way to solve such problem, but there seems to be a whole range of different activation etc. (not sure how it's actually called) so I am not really sure what to do.</p>
<p>Any hints on what direction to look into?</p>
<p>Thanks a lot!</p>
",1,104778,,1,128521,,2021-12-04T21:13:50.160,,1,2,,
45797,1,2019-02-19T07:45:48.423,1,53,<python><nlp>,Help to choose algorithm for computing difference between 2 texts?,"<p>I have a task to create a tool, which will be able to <strong>find articles-duplicates of a given reference article</strong>.
I know word vectorization (tf-idf,word2vec), RNN methods, but i can not choose something suitable for my situation.</p>

<p>My requirments:</p>

<ul>
<li>data are being collected on the fly  (program parses articles from web sites, so i don't have regular DB with collection of texts)</li>
<li>there is a reference text, whose copies need to be found</li>
<li>copies could be copypasted, partially copypasted (by paragraphs) or paraphrased</li>
<li><strong>reference-vs-copy comparison</strong> algorithm is preferable, but not required (instead of reference-vs-corps)</li>
<li>algorithm shouldn't do deep semantic analyzis, only kind of word counting, word vectorization, substring search</li>
<li>instead one algorithm, i can use a set of herurisitcs</li>
<li>algorithms can do false positive dicisions</li>
</ul>

<p>I come up with such ideas:</p>

<ol>
<li>download pretrained word2vec and compare means of word-vectors</li>
<li>Build a dictionary word->count from every text and compare it to reference dictionary</li>
<li>collect about 100 texts, vectorize them according to tf-idf and find closest to the reference</li>
</ol>

<p>I will apreciate, if you will point specific algorithms, libs, <strong>examples</strong> based on key-word extractions, dummy substring search, line difference comparison for <strong>python</strong> or CLI.</p>
",1,45877,,1,67966,,2019-02-25T13:11:22.430,,1,1,,
45163,1,2019-02-06T12:31:40.717,3,2662,<python><nlp><class-imbalance><imbalanced-learn>,imbalanced dataset in text classififaction,"<p>I have a data set collected from Facebook consists of 10 class, each class have 2500 posts, but when count number of unique words in each class, they has different count as shown in the figure <a href=""https://i.stack.imgur.com/eUIMX.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eUIMX.png"" alt=""word count in each class""></a></p>

<p>Is this an imbalanced problem due to word count , or balanced according number of posts. and what is the best solution if it imbalanced?</p>

<p><strong>update</strong>
My python code:</p>

<pre><code>data = pd.read_csv('E:\cluster data\One_File_nonnormalizenew2norm.txt', sep=""*"")

data.columns = [""text"", ""class1""]
data.dropna(inplace=True)
data['class1'] = data.class1.astype('category').cat.codes
text = data['text']

y = (data['class1'])
sentences_train, sentences_test, y_train, y_test = train_test_split(text, y, test_size=0.25, random_state=1000)
from sklearn.feature_extraction.text import CountVectorizer
num_class = len(np.unique(data.class1.values))



vectorizer = CountVectorizer()
vectorizer.fit(sentences_train)

X_train = vectorizer.transform(sentences_train)
X_test  = vectorizer.transform(sentences_test)

model = Sequential()
max_words=5000
model.add(Dense(512, input_shape=(60874,)))
model.add(Dense(20,activation='softmax'))####
model.summary()
model.compile(loss='sparse_categorical_crossentropy',
  optimizer='rmsprop',
  metrics=['accuracy'])

model.fit(X_train, y_train,batch_size=150,epochs=10,verbose=2,validation_data=(X_test,y_test),shuffle=True)
predicted = model.predict(X_test)
predicted = np.argmax(predicted, axis=1)
accuracy_score(y_test, predicted)
predicted = model.predict(X_test)
predicted = np.argmax(predicted, axis=1)
accuracy_score(y_test, predicted)

0.9592031872509961
</code></pre>
",1,45187,,3,62616,62616,2019-02-07T14:10:24.173,2019-02-07T11:45:08.107,3,2,,
13376,1,2016-08-11T19:31:25.963,1,10756,<machine-learning><python><deep-learning><scikit-learn><keras>,Error in model.fit() method in Keras,"<p>I was building a model for a classification problem in Keras for which I used the KerasClassifier, the wrapper scikit-learn. Below is the code for the same.</p>

<pre><code>import pandas as pd
import numpy as np
from sklearn.cross_validation import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,roc_auc_score
from keras.models import Sequential
from keras.layers import Dense,Dropout
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.grid_search import GridSearchCV


# In[3]:

def cleanPeople(people):
    people = people.drop(['date'],axis=1)

    people['people_id'] = people['people_id'].apply(lambda x : x.split('_')[1])
    people['people_id'] = pd.to_numeric(people['people_id']).astype(int)

    fields = list(people.columns)
    cat_data = fields[1:11]
    bool_data = fields[11:]

    for data in cat_data:
        people[data] = people[data].fillna('type 0')
        people[data] = people[data].apply(lambda x: x.split(' ')[1])
        people[data] = pd.to_numeric(people[data]).astype(int)

    for data in bool_data:
        people[data] = pd.to_numeric(people[data]).astype(int)

    return people


# In[4]:

def cleanAct(data, train=False):
    data = data.drop(['date'],axis = 1)
    if train:
        data = data.drop(['outcome'],axis=1)

    data['people_id'] = data['people_id'].apply(lambda x : x.split('_')[1])
    data['people_id'] = pd.to_numeric(data['people_id']).astype(int)

    data['activity_id'] = data['activity_id'].apply(lambda x: x.split('_')[1])
    data['activity_id'] = pd.to_numeric(data['activity_id']).astype(int)

    fields = list(data.columns)
    cat_data = fields[2:13]

    for column in cat_data:
        data[column] = data[column].fillna('type 0')
        data[column] = data[column].apply(lambda x : x.split(' ')[1])
        data[column] = pd.to_numeric(data[column]).astype(int)

    return data    


# In[5]:

people = pd.read_csv(""people.csv"")
people = cleanPeople(people)

act_train = pd.read_csv(""act_train.csv"")
act_train_cleaned = cleanAct(act_train,train=True)

act_test = pd.read_csv(""act_test.csv"")
act_test_cleaned = cleanAct(act_test)


# In[6]:

train = act_train_cleaned.merge(people,on='people_id', how='left')
test = act_test_cleaned.merge(people, on='people_id', how='left')


# In[8]:

output = act_train['outcome']
X_train, X_test, y_train, y_test = train_test_split(train,output, test_size=0.2, random_state =7)
input_len = len(X_train)
print(input_len)


# In[9]:

def base_model(optimizer='rmsprop', init='normal', dropout_rate =0.0):
    model = Sequential()

    model.add(Dense(100, input_dim = input_len, activation='relu', init=init))
    model.add(Dropout(dropout_rate))
    model.add(Dense(50, activation = 'relu', init = init))
    model.add(Dropout(dropout_rate))
    model.add(Dense(10, activation = 'relu', init = init))
    model.add(Dropout(dropout_rate))
    model.add(Dense(1, activation = 'sigmoid', init = init))

    model.compile(loss = 'binary_crossentropy', optimizer = optimizer, metrics =['accuracy'])
    return model


# In[10]:

seed = 7
np.random.seed(seed)
model = KerasClassifier(build_fn = base_model)


# In[12]:

#grid_parameters
optimizers = ['rmsprop', 'adam']
init = ['normal', 'uniform']
dropout_rate = [0.0, 0.2, 0.5]
epochs = [100, 150, 200]
batches = [10,20,30]
param_grid = dict(optimizer = optimizers, init=init, dropout_rate = dropout_rate, nb_epoch = epochs, batch_size=batches)


# In[ ]:

validator = GridSearchCV(estimator=model, param_grid= param_grid)
validator.fit(X_train, y_train)

print(validator.best_score_)
print(validator.best_params_)
</code></pre>

<p>The following code thrown this error when I ran it on my workstation.</p>

<pre><code>Traceback (most recent call last):
  File ""../src/script.py"", line 137, in 
    model.fit(X_train, y_train)
  File ""/opt/conda/lib/python3.5/site-packages/Keras-1.0.6-py3.5.egg/keras/wrappers/scikit_learn.py"", line 148, in fit
    history = self.model.fit(X, y, **fit_args)
  File ""/opt/conda/lib/python3.5/site-packages/Keras-1.0.6-py3.5.egg/keras/models.py"", line 429, in fit
    sample_weight=sample_weight)
  File ""/opt/conda/lib/python3.5/site-packages/Keras-1.0.6-py3.5.egg/keras/engine/training.py"", line 1036, in fit
    batch_size=batch_size)
  File ""/opt/conda/lib/python3.5/site-packages/Keras-1.0.6-py3.5.egg/keras/engine/training.py"", line 963, in _standardize_user_data
    exception_prefix='model input')
  File ""/opt/conda/lib/python3.5/site-packages/Keras-1.0.6-py3.5.egg/keras/engine/training.py"", line 108, in standardize_input_data
    str(array.shape))
Exception: Error when checking model input: expected dense_input_1 to have shape (None, 1757832) but got array with shape (1757832, 52)
</code></pre>

<p>When I trained the model in scikit-learn, there was no such error. Please help!</p>
",1,13392,,1,15412,,2016-08-12T13:18:32.027,,1,2,,
34038,1,2018-07-05T13:13:41.797,3,86,<python><classification><scikit-learn><random-forest><decision-trees>,Can I create random forest with RandomForestClassifier which will consist the same trees?,"<p>Based on answers to <a href=""https://datascience.stackexchange.com/q/16800/82"">this</a> question, I should be able to build a random forest with all the same trees by using <code>bootstrap = False, max_features = None, random_state = 42</code> parameters. </p>

<p>I wrote <a href=""https://gist.github.com/QuantumDamage/29474994f4dc51cd170ea706b0ad646f"" rel=""nofollow noreferrer"">quick code to test it</a>, and it seems that different trees are created. </p>

<p>Is it possible to create a random forest using <code>RandomForestClassifier</code> which will produce the same trees?</p>
",1,34124,,3,82,29169,2019-06-07T21:41:55.650,2019-06-07T21:41:55.650,1,6,,
114103,1,2022-09-05T06:18:53.463,0,26,<python><deep-learning><tensorflow><transfer-learning><vgg16>,"Hello guys, is dimension reduction required for tensorflow?","<p>I am working on face emotion detection using FER2013 dataset using tensorflow and vgg16 model.
I am applying t-sne to my training dataset for dimensionality reduction.</p>
<p>My question is that &quot;is dimensionality reduction required for the tensorflow ????</p>
",1,114104,,0,139687,,2022-09-05T07:12:40.720,,1,1,2022-09-17T05:49:39.833,
63174,1,2019-11-14T22:16:52.453,1,1043,<python><scikit-learn><decision-trees>,Why are my Decision Tree Leafs not pure?,"<p>I'm making a using <code>DecisionTreeClassifier</code> from SKlearn (v0.21.3) with its default settings, using Python. I do not want regularize it in any way, I want it to overfit as much as possible. </p>

<p>When drawing the tree out I saw that some of the leafs were not pure. Is this normal? Was the tree not able to separate the samples? </p>

<pre><code>   ...
   model = DecisionTreeClassifier(criterion=""entropy"")
   model = modell.fit(X, y) 
   ...
</code></pre>

<p><a href=""https://i.stack.imgur.com/3rrKs.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/3rrKs.png"" alt=""enter image description here""></a></p>
",1,63177,,1,58438,58438,2019-11-15T06:24:52.460,2019-11-15T06:24:52.460,1,2,,
109793,1,2022-04-08T06:17:58.583,2,173,<python><feature-extraction><feature-scaling>,Is it wise to always `StandardScaler()` features? [SOLVED],"<p>My current investigations point to the <code>sklearn.preprocessing.StandardScaler()</code> not always being the right choice for certain types of feature extractions for neural networks.</p>
<p>Suppose I want to classify sound events based on spectrogram data. A second of such data could look like this:
<a href=""https://i.stack.imgur.com/1ZMZU.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1ZMZU.png"" alt=""enter image description here"" /></a></p>
<p>Visible here is a sine wave of around 1kHz over one second. The settling of the low bands is specific to the feature extraction and <strong>not part of the question</strong>. The data is a <code>(n,28,40)</code> matrix of dBFS-values, ergo the logarithmic energy levels relative to the maximal digital headroom of the wav-file.</p>
<p>If <code>StandardScaler</code> is now applied, the visual representation of the sound now looks like this:
<a href=""https://i.stack.imgur.com/rrYzh.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/rrYzh.png"" alt=""enter image description here"" /></a></p>
<p>... which basically removes the defining features and amplifies the noise, exactly what is NOT wanted. Would a level-based scaler be the better choice here or is the <code>StandardScaler()</code> just not appearing to benefit the system in this specific case of a sine wave?</p>
<p><em><strong>Note</strong>: I am a student and I do not have years of experience. So if the question lacks quality, I ask of you to suggest an <strong>improvement</strong> before downvoting. Thank you.</em></p>
",1,109802,,2,134340,134340,2022-04-08T17:38:50.063,2022-04-08T17:38:50.063,2,1,,
56612,1,2019-07-30T09:53:31.517,4,1738,<python><data><visualization><distribution><seaborn>,Why do seaborn.dist and pyplot.hist generate two different looking histograms on the same data?,"<p>I'm looking at telecom customers data. Two of the variables I'm looking at currently are:</p>

<ul>
<li><em>Monthly Charges</em> - The total amount charged to the customer monthly.</li>
<li><em>Is Senior Citizen</em> - Whether the customer is a senior citizen.</li>
</ul>

<p>I'm trying to plot two histograms to see if the distributions for non-senior and senior citizens is different.</p>

<p>If I use seaborn's distplot then I get the following result<a href=""https://i.stack.imgur.com/PJwmh.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PJwmh.png"" alt=""enter image description here""></a></p>

<p>And if I use pyplot hist then I get the following result</p>

<p><a href=""https://i.stack.imgur.com/cAJLU.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/cAJLU.png"" alt=""enter image description here""></a></p>

<p>In the first plot the blue one towers above the orange ones in the range ~70-120 whereas in the second image the blue one always stays below the orange one. </p>

<p><strong>What is the difference between these two?</strong></p>
",1,56613,,4,78649,,2021-08-17T15:41:14.050,,2,1,,
84867,1,2020-11-02T21:37:31.057,1,391,<python><scikit-learn><pandas><numpy>,Running scikit-learn with large volume,"<p>I need to run a Random Forest process with <code>scikit-learn</code>. To train the model, I have a database table with 10 million rows of features. The question is: what is the best way to approach this, should I load into memory the 10 million rows, for example with numpy or pandas or there's a better way to load the data progressively by chunks?</p>
",1,84888,,1,76801,76801,2020-12-24T23:54:15.830,2020-11-02T21:56:27.607,1,1,,
75006,1,2020-05-28T16:14:37.847,0,1814,<python><scikit-learn><pandas>,Linear Regression not working due to wrong kind of array,"<p>I try to deal with my homework. The Job is to take <a href=""http://www.statsci.org/data/general/uscrime.html"" rel=""nofollow noreferrer"">this Data</a> and perform a linear regression on it.</p>
<p>The code is published <a href=""https://github.com/d3v3lop3rDE/DataScience"" rel=""nofollow noreferrer"">here</a>.</p>
<p>I am quite new to programming in Python and in data science. So I tried transforming as the interpreter suggests, but it didn't work.
My first error was that there was a 2d array expected but 1d given. Then I took the pure array and put it into an empty one suggested by a StackOverflow answer now the error is that a scalar array is given but a 2d array is given.</p>
<pre class=""lang-py prettyprint-override""><code>import pandas as pd
from sklearn.preprocessing import StandardScaler

#Import
data = pd.read_csv('uscrime.txt', sep=&quot;\t&quot;)
crime = pd.concat([data], axis = 1)
print(crime)

from sklearn.linear_model import LinearRegression
regression = LinearRegression()
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(crime.get(&quot;M&quot;), crime.get(&quot;Crime&quot;), test_size=0.2, random_state=0)

X_train_new = []
X_train_new.append(X_train.values)

y_train_new = []
y_train_new.append(y_train.values)

regression.fit(X_train_new, y_train_new)
</code></pre>
",1,75218,,0,98073,98307,2020-08-18T16:19:47.270,2020-08-18T16:19:47.270,1,3,,
87600,1,2021-01-06T18:31:05.607,2,10009,<python><scikit-learn><pandas><random-forest><numpy>,AttributeError: 'numpy.ndarray' object has no attribute 'nan_to_num',"<p>I'm trying to run a Random Forest model from <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"" rel=""nofollow noreferrer"">sklearn</a> but I keep getting an error: <code>ValueError: Input contains NaN, infinity or a value too large for dtype('float32').</code></p>
<p>I tried following steps in <a href=""https://datascience.stackexchange.com/questions/11928/valueerror-input-contains-nan-infinity-or-a-value-too-large-for-dtypefloat32"">ValueError: Input contains NaN, infinity or a value too large for dtype(&#39;float32&#39;)</a></p>
<p><code>fillna(0)</code> on my pandas dataframe still gave the ValueError.</p>
<p>So I tried working with my numpy array:</p>
<pre><code>val = setTo.ravel().nan_to_num(0)
</code></pre>
<p>But I keep getting an error: <code>'numpy.ndarray' object has no attribute 'nan_to_num'</code></p>
<p>I'm wondering how I can deal with the nan values if I have ndarray?</p>
<h3>Update</h3>
<p>Thanks so much to @Beniamin H for all the help, as suggested, I rescaled the data, which I based on
<a href=""https://stackoverflow.com/questions/34771118/sklearn-random-forest-error-on-input"">https://stackoverflow.com/questions/34771118/sklearn-random-forest-error-on-input</a> and it worked!</p>
",1,87604,,2,103189,83275,2022-07-22T16:36:20.383,2022-07-22T16:36:20.383,1,2,,
46881,1,2019-03-07T18:30:05.747,3,899,<machine-learning><python><scikit-learn><pca>,Why do we choose principal components based on maximum variance explained?,"<p>I've seen many people choose # of principal components for PCA based on maximum variance explained. So my question is do we always have to choose principal components based on maximum variance explained? Is it applicable for all scenarios i.e text count vectors(BoW, tfidf..) where number of dimensions are really high.</p>

<p>Does maximum variance means most information about my data in higher dimension is captured into lower dimension?</p>

<p>Usually I'd plot something like this to see the variance explained.</p>

<pre><code>plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('Principal Components')
plt.ylabel('Variance ratio')
plt.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/NTuFm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NTuFm.png"" alt=""PCA""></a></p>
",1,46920,,3,60105,,2019-03-09T07:39:04.003,,2,1,,
77590,1,2020-07-12T11:40:23.823,1,106,<machine-learning><python><churn>,How to use multiple cross-section observations per subject for churn prediction?,"<p>Recently I have started to teach myself about machine learning and I have ran into a dataset, which got me a bit confused.</p>
<p><strong>Dataset:</strong> The subjects of the dataset are university students (student ID == &quot;Key&quot; feature), and each observation is a summary of their semester (grade averages, ECTS taken and completed, etc.) plus their general programme-related data (enrollment and scholarship status, date of enrollment, programme code, etc.). The data is in hungarian, but in the context of the issue, it is not important to understand the meaning of the feature names and values. Below is an example of an observation:</p>
<p><a href=""https://i.stack.imgur.com/1LGe4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1LGe4.png"" alt=""enter image description here"" /></a></p>
<p><strong>My goal:</strong> I want to build a model, which predicts student churn.</p>
<p><strong>Problem:</strong> The dataset contains a single or multiple observations per student, based on the number of university semesters, and the observation periods are not consistent between the students, since it is based on the individual date of enrollment.</p>
<p><a href=""https://i.stack.imgur.com/NitHq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NitHq.png"" alt=""enter image description here"" /></a></p>
<p>In the example picture above, you can see, that student no.1 has 7 observations (=7 semesters completed) and started his programme on 2009.09.10 (Képzés jogviszony kezdete == Date of programme enrollment), while student no.2 has 3 observations and started his programme on 2008.09.12.</p>
<p>I am wondering, should I use only one observation (e.g.: the last completed university semester) per student ,or does it make sense to use all observations per student?</p>
<p>Thank you for the feedbacks in advance!</p>
<p>(Also, I am new on the forum, so if you have any constructive criticism regarding the content and the format of my question, please, share with me.)</p>
",1,77667,,1,100637,,2020-07-13T20:18:44.677,,1,2,,
49484,1,2019-04-17T15:29:44.787,2,664,<python><pandas>,Delete all rows between two values in a dataframe that repeat multiple times in a column,"<p>I have dataframe and let's say inside of it is a column_A. This column_A has 3 strings as values, call them 'new_records', 'deletions', 'changes'  that repeat across the dataframe multiple times in that order always with multiple rows in between. I want to delete all rows from the beginning of deletions to the end of changes, i.e. I want to leave only new_records in the dataframe. The dataframe looks like this: </p>

<pre><code>column_A         column_B     column_C ....
NEW_RECORDS        val1         val2
string1_new        val3         val4 
string2_new        val5         val6 
  NaN              val9         val10
  NaN              val11        val12 
string3_new
 ...
DELETIONS          val7         val8
string1_del         ...           ...
   NaN              ...           ...
string2_del         ...           ...
  ...    
CHANGES             ...           ...
 str1_ch            ... 
 str2_ch
  ... 
NEW_RECORDS
 str200_new        ...
 str300_new           ...
  NaN
  NaN
  ...
DELETIONS
 NaN
 str100_del
 NaN
 str290_del        ...
  ...
CHANGES
 str1000
 str20000
  NaN
   ...           ...
</code></pre>

<p>I want to have at the end only chunks of rows between new_records and deletions values, without rows that belong to the deletions group and changes group. How can I do that?</p>

<p>UPDATE:</p>

<p>There are many rows after the 'new_records' and before the start of 'deletions' group and there are many rows after the start of deletions group and beginning of the 'changes' group. I need to extract only rows that belong to the new_records group. So all rows after the value 'new_records' and before the value of 'deletions' across all dataframe.</p>
",1,49537,,2,31608,31608,2019-04-23T10:20:30.843,2019-04-23T10:20:30.843,1,5,,
115586,1,2022-10-25T16:52:19.477,2,509,<python><outlier><grid-search><isolation-forest>,Can GridSearchCV be used for unsupervised learning?,"<p>im trying to build an outlier detector to find outliers in test data. That data varies a bit (more test channels, longer/shorter testing).</p>
<p>First im applying the train test split because i want to use grid search for hypertuning. This is timeseries data from multiple sensors and i removed the time column beforehand.</p>
<pre><code>X shape : (25433, 17)
y shape : (25433, 1)

X_train, X_test, y_train, y_test = train_test_split(X,
                                                    y,
                                                    test_size=0.33,
                                                    random_state=(0))
</code></pre>
<p>Standardize afterwards and then i changed them into an int Array because GridSearch doesnt seem to like continuous data. This surely can be done better, but i want this to work before i optimize the coding.</p>
<pre><code>'X'
mean = StandardScaler().fit(X_train)
X_train = mean.transform(X_train)
X_test = mean.transform(X_test)

X_train = np.round(X_train,2)*100
X_train = X_train.astype(int)
X_test = np.round(X_test,2)*100
X_test = X_test.astype(int)

'y'
yeah = StandardScaler().fit(y_train)
y_train = yeah.transform(y_train)
y_test = yeah.transform(y_test)
y_train = np.round(y_train,2)*100
y_train = y_train.astype(int)
y_test = np.round(y_test,2)*100
y_test = y_test.astype(int)
</code></pre>
<p>I chose the IForrest because its fast, has pretty good results and can handle huge data sets (i currently only use a chunk of the data for testing). Setting Up the GridSearchCV:</p>
<pre><code>clf = IForest(random_state=47, behaviour='new',
          n_jobs=-1)

param_grid = {'n_estimators': [20,40,70,100], 
              'max_samples': [10,20,40,60], 
              'contamination': [0.1, 0.01, 0.001], 
              'max_features': [5,15,30], 
              'bootstrap': [True, False]}

fbeta = make_scorer(fbeta_score,
                    average = 'micro',
                    needs_proba=True,
                    beta=1)

grid_estimator = model_selection.GridSearchCV(clf, 
                                              param_grid,
                                              scoring=fbeta,
                                              cv=5,
                                              n_jobs=-1,
                                              return_train_score=True,
                                              error_score='raise',
                                              verbose=3)

grid_estimator.fit(X_train, y_train)
</code></pre>
<p><strong>The Problem:</strong></p>
<p>I cant fit the  grid_estimator.
GridSearchCV needs an y_argument, without <code>y</code> its passing me the &quot;missing y_true&quot; error.
What should be used as a target here ? Atm i just passed an important data column to <code>y</code> for testing, but im getting this error that i dont understand:</p>
<pre><code>ValueError: Classification metrics can't handle a mix of multiclass and continuous-multioutput 
targets
</code></pre>
<p>I also got the advice that the i need a scoring function and the iForest doesnt have one.
I couldnt find useful information for this, are there any helpful guides or info that can help me ?</p>
",1,115593,,2,141984,,2022-10-26T09:32:48.320,,1,1,,
114294,1,2022-09-10T15:07:59.933,0,222,<python><clustering><k-means>,Perform k-means clustering over multiple columns and get the cluster center values?,"<p>I read <a href=""https://datascience.stackexchange.com/questions/48693/perform-k-means-clustering-over-multiple-columns"">here</a> how to show the number of clusters over <span class=""math-container"">$n$</span> columns.</p>
<p>I would like to know how to get in a table, the values of the clusters centers. Could someone help me with this?</p>
",1,114301,,0,140272,29169,2022-09-18T23:03:23.733,2022-09-18T23:03:23.733,1,1,,
19523,1,2017-06-07T07:39:26.060,7,6859,<machine-learning><python><r><recommender-system>,"Recommender system based on purchase history, not ratings","<p>I'm exploring options for recommender systems optimized for the insurance industry, which would take into account</p>

<p>i) product holdings</p>

<p>ii) user characteristics (segment, age, affluence, etc.).</p>

<p>I want to stress that</p>

<p>a) there are no product ratings available, thus collaborative filtering is not an option</p>

<p>b) recommended products don't have to be similar to products that have already been purchased, thus item-to-item recommendations are most probably not relevant.</p>

<p>Keep in mind that in insurance you rarely want to recommend similar products to those already purchased ones, as someone with the Car insurance is unlikely to want to buy another Motor product, rather Home or maybe Travel, etc. </p>

<p><strong>That's why I want to develop recommendations on similarities between the users based on their purchase history and/or demographics</strong></p>

<p>Ideally, I'd like to be able to implement it in R, if not possible, then in Python. Thanks for help and suggestions!</p>
",1,19526,,7,28291,28291,2019-04-19T08:11:34.893,2017-06-07T10:47:16.913,2,2,,
53133,1,2019-06-03T13:58:38.640,1,366,<python><r><matlab><sql><julia>,What should I master better for professional data science in economics and finance?,"<p>First, excuse me for the noob and long question which is probably doesn’t even belong to here, I know there are several question been answered like this out there, but I think this is going to be up-to-date. Stack Overflow deleted my question and redirected me to here.</p>

<p>I study economics and finance on undergraduate level, and to be honest, I am not really into programming so far. However, I must admit it you can't doing really well nowadays without specific softwares and programming languages on economics/finance related fields.</p>

<p>According to my curriculum, I’ve encountered Matlab, some econometrics softwares, and of course MS Office, especially Excel with VBA. I have some shady framework in my mind, and please feel free to correct me if I am wrong. So as I experienced, for numerical calculations and doing the vast majority of math, Matlab, Octave and Mathematica exists. For econometrics, there are professional softwares like eViews, STATA, SPSS or the open source Gretl and Tableau for data visualization. And last, we can use Excel to manage databases.</p>

<p>Long story short, my basic question would be that, are these above the best tools for doing the job ? Or should I switch to more professional tools – like real programming languages - to being better in solving mathematical problems, numerical calculations, econometrics, data science and exquisite, high-quality data visualization? What are the most desirable skills in the data science industry nowadays in economic/financial areas?</p>

<p>I heard that R is a quite trending statistical programming language in these days, and getting better and better each day - I already wrote some functions and visualizations in Rstudio. I also heard that SQL is also a better option to manage really massive data sets instead of Excel, but is SQL able to do every kind of stuff with data what can be done in Excel ? It seems to me Python is generally the number one language for data analysis, it’s flexible and usable on a broad scale. I find Python libraries - such as matplotlib, numpy, pandas, bokeh - extremely attractive. What about Julia , is this going to be the next R in the future ? To be honest, I am also still confused a little bit by such terms like data science, data analysis, data mining, machine learning, big data – are there any serious difference between these phrases?</p>

<p>From above, which one is that I should really focus on and master it ? Keep practicing on popular softwares, or switch to R , Python, Julia, SQL ? Maybe both of them? Again, we are talking about only graduate and undergraduate level of economics and finance, and related jobs. I don’t want to develop serious and complex softwares/applications, just quantitatively analyze stock prices, corporate and economic data, like annual reports, employments, GDP and so on.</p>

<p>Experienced data analysts, please guide me through the confusing forest of data analysis tools. I appreciate every kind of comment.</p>
",1,53154,,1,75369,,2019-06-03T19:40:33.230,,1,4,2019-06-03T22:10:22.460,
10060,1,2016-02-02T01:42:38.053,6,2973,<python><text-mining><apache-hadoop><k-means><distance>,Improve k-means accuracy,"<p><strong>Our weapons</strong>:</p>

<p>I am experimenting with k-means and Hadoop, where I am chained to these options for various reasons (e.g. <a href=""https://askubuntu.com/questions/725444/help-me-win-this-war"">Help me win this war!</a>).</p>

<hr>

<p><strong>The battlefield</strong>:</p>

<p>I have articles, which belong to <em>c</em> categories, where <em>c</em> is fixed. I am vectorizing the contents of the articles to <strong>TF-IDF</strong> features. Now I am running a naive k-means algorithm, which takes <code>c</code> centroids to begin with and starts, iteratively, grouping articles (i.e. rows of the TF-IDF matrix, where you can see <a href=""https://stackoverflow.com/questions/35109424/how-to-make-tf-idf-matrix-dense"">here</a> how I built it), until converenge occurs.</p>

<hr>

<p><strong>Special notes</strong>:</p>

<ol>
<li><p>Initial centroids: Tried with random from within each category or
with the mean of all the articles from each category.</p></li>
<li><p>Distance function: Euclidean.</p></li>
</ol>

<hr>

<p><strong>Question(s)</strong>:</p>

<p>The accuracy is poor, as expected, can I do any better, by making another choice for the initial centroids, or/and pick another distance function?</p>

<hr>

<p><sub>print ""Hello Data Science site!"" :)</sub></p>
",1,10067,,6,15927,-1,2016-02-02T18:28:38.880,2017-05-23T12:38:53.587,1,1,,
57371,1,2019-08-11T02:38:59.623,2,217,<machine-learning><python><feature-selection><random-forest><dimensionality-reduction>,Using random forest for selecting variables returns the entire dataframe,"<p>I am in the process of dimensionality reduction.  I am using Random Forest to find the columns with the highest
level of correlation with the target SalePrice column.</p>

<p>The problem is that the output is too large.  Definitely not what I want from it.  It is returning 259 columns.  Some of these
columns are a result of one-hot-encoding the categorical variables and adding them back into the dataframe,
which logically increases the dimension of the dataset.  However, I only wanted to return the columns
with the highest correlation to the target variable 'SalePrice'.  Not the whole damn dataframe.</p>

<p>Here is the output:</p>

<pre><code>       0   1     2      3     4    5    6    ... 252 253 254 255 256 257 258
0        1  RL  65.0   8450  Pave  NaN  Reg  ...   0   1   0   0   1   0   1
1        2  RL  80.0   9600  Pave  NaN  Reg  ...   0   1   0   0   1   0   1
2        3  RL  68.0  11250  Pave  NaN  IR1  ...   0   1   0   0   1   0   1
3        4  RL  60.0   9550  Pave  NaN  IR1  ...   0   0   0   0   1   0   1
4        5  RL  84.0  14260  Pave  NaN  IR1  ...   0   1   0   0   1   0   1
...    ...  ..   ...    ...   ...  ...  ...  ...  ..  ..  ..  ..  ..  ..  ..
1455  1456  RL  62.0   7917  Pave  NaN  Reg  ...   0   1   0   0   1   0   1
1456  1457  RL  85.0  13175  Pave  NaN  Reg  ...   0   1   0   0   1   0   1
1457  1458  RL  66.0   9042  Pave  NaN  Reg  ...   0   1   0   0   1   0   1
1458  1459  RL  68.0   9717  Pave  NaN  Reg  ...   0   1   0   0   1   0   1
1459  1460  RL  75.0   9937  Pave  NaN  Reg  ...   0   1   0   0   1   0   1

[1460 rows x 259 columns]
</code></pre>

<p>Here is my code:</p>

<pre><code>import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import train_test_split

train = pd.read_csv(""https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/train.csv"")
test = pd.read_csv(""https://raw.githubusercontent.com/oo92/Boston-Kaggle/master/test.csv"")

categorical_columns = ['MSSubClass', 'MSZoning', 'LotShape', 'LandContour', 'LotConfig', 'Neighborhood', 'Condition1',
                       'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',
                       'Foundation', 'Heating', 'Electrical', 'Functional', 'GarageType', 'PavedDrive', 'Fence',
                       'MiscFeature', 'SaleType', 'SaleCondition', 'Street', 'CentralAir']

ranked_columns = ['Utilities', 'LandSlope', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure',
                  'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond',
                  'PoolQC', 'OverallQual', 'OverallCond']

numerical_columns = ['LotArea', 'LotFrontage', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',
                     'BsmtUnfSF','TotalBsmtSF', '1stFlrSF', '2ndFlrSf', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',
                     'BsmtHalfBath', 'FullBath', 'HalfBath', 'Bedroom', 'Kitchen', 'TotRmsAbvGrd', 'Fireplaces',
                     'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch',
                     '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']


def feature_encoding(df, categorical_list):

    # take one-hot encoding
    OHE_sdf = pd.get_dummies(df[categorical_list])

    # drop the old categorical column from original df
    df.drop(columns = categorical_list, inplace = True)

    # attach one-hot encoded columns to original dataframe
    df = pd.concat([df, OHE_sdf], axis = 1, ignore_index = True)

    # Integer Encoding
    df['Utilities'] = df['Utilities'].replace(['AllPub', 'NoSeWa'], [2, 1])  # Utilities
    df['ExterQual'] = df['ExterQual'].replace(['Ex', 'Gd', 'TA', 'Fa'], [4, 3, 2, 1])  # Exterior Quality
    df['LandSlope'] = df['LandSlope'].replace(['Gtl', 'Mod', 'Sev'], [3, 2, 1])  # Land Slope
    df['ExterCond'] = df['ExterCond'].replace(['Ex', 'Gd', 'TA', 'Fa', 'Po'], [4, 3, 2, 1, 0])  # Exterior Condition
    df['HeatingQC'] = df['HeatingQC'].replace(['Ex', 'Gd', 'TA', 'Fa', 'Po'], [4, 3, 2, 1, 0])  # Heating Quality and Condition
    df['KitchenQual'] = df['KitchenQual'].replace(['Ex', 'Gd', 'TA', 'Fa'], [3, 2, 1, 0])  # Kitchen Quality

    # Replacing the NA values of each column with XX to avoid pandas from listing them as NaN
    na_data = ['Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'FireplaceQu',
               'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']

    for i in na_data:
        df[i] = df[i].fillna('XX')

    # Replaced the NaN values of LotFrontage and MasVnrArea with the mean of their column
    df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].mean())
    df['MasVnrArea'] = df['MasVnrArea'].fillna(df['MasVnrArea'].mean())

    x_train, x_test, y_train, y_test = train_test_split(df, df['SalePrice'], test_size = 0.3, random_state = 42)

    sel = SelectFromModel(RandomForestClassifier(n_estimators = 100), threshold = 300 * ""mean"")
    sel.fit(x_train, y_train)
    sel.get_support()

    selected_feat = x_train.columns[sel.get_support()]

    return selected_feat


print(feature_encoding(train, categorical_columns))
</code></pre>

<p>The code for Random Forest is right after the train-test-split.</p>

<p><strong>Update</strong></p>

<p>After changing the code to the above version, I am getting the following error:</p>

<pre><code>Traceback (most recent call last):
  File ""C:\Users\security\AppData\Roaming\Python\Python37\site-packages\pandas\core\indexes\base.py"", line 2657, in get_loc
    return self._engine.get_loc(key)
  File ""pandas\_libs\index.pyx"", line 108, in pandas._libs.index.IndexEngine.get_loc
  File ""pandas\_libs\index.pyx"", line 129, in pandas._libs.index.IndexEngine.get_loc
  File ""pandas\_libs\index_class_helper.pxi"", line 91, in pandas._libs.index.Int64Engine._check_type
KeyError: 'Utilities'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/security/Downloads/AP/Boston-Kaggle/Boston.py"", line 66, in &lt;module&gt;
    print(feature_encoding(train, categorical_columns))
  File ""C:/Users/security/Downloads/AP/Boston-Kaggle/Boston.py"", line 37, in feature_encoding
    df['Utilities'] = df['Utilities'].replace(['AllPub', 'NoSeWa'], [2, 1])  # Utilities
  File ""C:\Users\security\AppData\Roaming\Python\Python37\site-packages\pandas\core\frame.py"", line 2927, in __getitem__
    indexer = self.columns.get_loc(key)
  File ""C:\Users\security\AppData\Roaming\Python\Python37\site-packages\pandas\core\indexes\base.py"", line 2659, in get_loc
    return self._engine.get_loc(self._maybe_cast_indexer(key))
  File ""pandas\_libs\index.pyx"", line 108, in pandas._libs.index.IndexEngine.get_loc
  File ""pandas\_libs\index.pyx"", line 129, in pandas._libs.index.IndexEngine.get_loc
  File ""pandas\_libs\index_class_helper.pxi"", line 91, in pandas._libs.index.Int64Engine._check_type
KeyError: 'Utilities'
</code></pre>
",1,57416,,2,59028,59028,2019-08-13T09:56:57.610,2019-08-13T09:56:57.610,2,1,,
16805,1,2017-02-07T11:55:53.757,1,249,<python><algorithms>,Integer programming formulation: which algorithms,"<p>I have a complex problem that I have simplified coming to a simple <em>integer linear programming</em> formulation.</p>

<p>Given the scalar $K &gt; 0$, the vectors $v(t) \in R^n$ and $b_i \in R^n, \forall i=1,\ldots,K$ are known. In particular $v(t)$  is the measured value (ex: every 10 minutes) while the $b_i$ are fixed (computed ones, previously).
Consider that I have: $$K &gt;&gt; n,$$ 
i.e., I have to identify the presence of $K$ (ex: $K=20$) elements, each one of dimension $n$ (ex: $n=2$).</p>

<p>So, for every fixed $t$, the problem that I have to solve has the following formulation:</p>

<p>$$ \newcommand\norm[1]{\left\lVert#1\right\rVert}
\begin{equation*}\begin{aligned}
&amp; \underset{x_i}{\text{minimize}}
&amp; &amp; \norm{v - \sum_{i=1}^{K} b_i x_i}_{2} \\
&amp; \text{subject to}
&amp; &amp; x_i \in \{0,1\},\ \forall i = 1, \ldots, K.
\end{aligned} \end{equation*}$$</p>

<p>Do you know which algorithms solve that formulation? In particular I am looking for an algorithm implemented in Python.</p>
",1,16868,,1,10024,10024,2017-02-10T05:40:32.373,2017-02-09T09:57:20.193,3,1,,
39095,1,2018-10-03T09:01:46.480,6,221,<python><neural-network><image-classification><convolution><pytorch>,Combining 2 Neural Networks,"<p><strong>2 images</strong> as input, <strong>x1</strong> and <strong>x2</strong>  and try to use convolution as a <strong>similarity measure</strong>. The idea is that the learned weights substitute more traditional measure of similarity (cross correlation, NN, ...). Defining my forward function as follows:</p>

<pre><code>def forward(self,x1,x2):
    out_conv1a = self.conv1(x1)
    out_conv2a = self.conv2(out_conv1a)
    out_conv3a = self.conv3(out_conv2a)

    out_conv1b = self.conv1(x2)
    out_conv2b = self.conv2(out_conv1b)
    out_conv3b = self.conv3(out_conv2b)
</code></pre>

<p>Now for the similarity measure:</p>

<pre><code>out_cat = torch.cat([out_conv3a, out_conv3b],dim=1)
futher_conv = nn.Conv2d(out_cat)
</code></pre>

<p><strong>Question is as follows:</strong></p>

<ol>
<li><p>Would Depthwise/Separable Convolutions as in the google <a href=""https://arxiv.org/pdf/1706.03059.pdf"" rel=""nofollow noreferrer"">paper</a> yield any advantage over 2d convolution of the concatenated input. For that matter can convolution be a similarity measure, cross correlation and convolution are very similar.</p></li>
<li><p>It is my understanding that the <code>groups=2</code> option in <code>conv2d</code> would provide 2 separate inputs to train weights with, in this case each of the previous networks weights. How are these combined afterwards?</p></li>
</ol>
",1,53616,,6,47730,26562,2019-06-12T06:57:41.710,2018-10-04T00:29:04.160,2,2,,
103440,1,2021-10-24T08:05:43.143,2,95,<python><machine-learning><pytorch><statistics>,Is my approach about the ML model correct?,"<p>First of all, I am a newbie here and it is my first question on this platform, so I apologize for the mistakes about the format if there are any.</p>
<p>In my thesis study, I am trying to identify the non-normal fuel consumption of an aircraft for a specific flight by looking at the commercial aviation parameters. To achieve this, I use two separate databases; one is the actual flight data (QAR data), while the other is high-fidelity simulations (Operational Flight Plans). My strategy is to train the feed-forward ML model (I use Pytorch) with simulations (OFP) and test them with QAR data. Below is the best model result with certain ML conditions.</p>
<p><img src=""https://i.stack.imgur.com/7wgSW.png"" alt=""Best Model goes here"" /></p>
<p>The above means, the trained model can predict an actual flight's fuel burn with less than %5 error for %99.3 of the flights. In the same manner, error&lt;%3 --&gt; %93.4 of flights,  error&lt;%2 --&gt; %78.9 of flights.</p>
<p>This is where my confusion begins.</p>
<p>Let's say, %0.7 of the flights burned %5 fuel less or more. How could I be sure this is not caused by the training error? If I test the model with OFP parameters and look at the model's error flight-by-flight and identify the flights with training errors (i.e. %5 more or less fuel burn), and exclude them from the first non-normal identification process, would that work? In my opinion,  this idea won't work since the training dataset will be the same as the test dataset and the model will overfit.</p>
<p>Do you think the above approach is correct? Is there any other option that I can stick with to overcome the training errors? Or should I accept the training errors as they are because there is nothing to do about them in this case?</p>
",1,103450,,2,126905,,2021-10-24T15:39:20.373,,1,2,,
13567,1,2016-08-20T06:51:26.563,33,25303,<machine-learning><python><feature-engineering><feature-scaling><normalization>,Ways to deal with longitude/latitude feature,"<p>I am working on a fictional dataset with 25 features. Two of the features are latitude and longitude of a place and others are pH values, elevation, windSpeed etc with varying ranges. I can perform normalization on the other features but how do I approach latitude/longitude features?</p>

<p>Edit: This is a problem to predict agriculture yield. I would think lat/long is very important since locations can be vital in prediction and hence the dilemma.</p>
",1,13575,,33,23600,23600,2017-03-02T19:08:25.743,2016-08-20T18:56:59.550,1,7,2016-08-20T17:20:30.537,
82889,1,2020-10-12T00:55:06.937,1,254,<machine-learning><python><scikit-learn><linear-regression><training>,TicTacToe Linear Regression low accuracy and R^2 score,"<p>Im using the python sklearn library to attempt a linear regression TicTacToe AI.</p>
<p>I create my training set by simply having the computer play random 'blind' games against itself. For example... Player one plays a random segment of the board. Next player two plays a random valid segment of the board etc. This goes on until the board is full or someone has won. Each time player one wins, i store the board states leading up to the win. Every loss, i simply mark that board state (and past board states of the same game )  as a loss for player one. For every tie game(full board) I do not count it as anything. I play about 20k of these games. At the end I get my training data set which includes the board state (the feature set) and the outcome which is the percentage (a floating pint value. eg .8 is 80%) of games won for that state.</p>
<p>So for example going from board top left to bottom right: [1, 1, 1, 2, 0, 2, 0, 0, 0] would be:</p>
<pre><code>X X X
O - O
- - -
</code></pre>
<p>would have a '1' or 100 percent after playing 20k random games etc.</p>
<p>I'm trying to predict the success rate of player one's next move. Basically the success rate of any free segment based on the board state.</p>
<p>However; after training sklearn linear regression with my training data, I get a very low R^2 score of .14 and any test is highly inaccurate. I'm beginning to think there is a flaw in my data? Is this how data scientists would go about creating the training set for tic tac toe?</p>
",1,82896,,1,105985,105985,2020-10-12T07:56:39.413,2020-10-12T04:47:38.750,1,2,,
26555,1,2018-01-12T08:21:16.300,2,54787,<machine-learning><python><regression><linear-regression>,"ValueError: shapes (1,10) and (2,) not aligned: 10 (dim 1) != 2 (dim 0)","<p>I am running a multiple linear regression using backward elimination. Below is the code</p>

<pre><code>import statsmodels.formula.api as sm
X = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis = 
1)
X_opt = X[:,[0,1,2,3,4,5]]
regressor_OLS = sm.OLS(endog= y, exog = X_opt).fit()
regressor_OLS.summary()
X_opt = X[:,[0,1,3,4,5]]
regressor_OLS = sm.OLS(endog= y, exog = X_opt).fit()
regressor_OLS.summary()
X_opt = X[:,[0,3,4,5]]
regressor_OLS = sm.OLS(endog= y, exog = X_opt).fit()
regressor_OLS.summary()
X_opt = X[:,[0,3,5]]
regressor_OLS = sm.OLS(endog= y, exog = X_opt).fit()
regressor_OLS.summary()
X_opt = X[:,[0,3]]
regressor_OLS = sm.OLS(endog= y, exog = X_opt).fit()
regressor_OLS.summary()
</code></pre>

<p>But when I am predicting using the above regressor_OLS model,</p>

<pre><code>X_new = X[:, 3]
y_pred2 = regressor_OLS.predict(X_new)
</code></pre>

<p>I am getting the below error:</p>

<pre><code>    y_pred2 = regressor_OLS.predict(X_new)
    Traceback (most recent call last):

  File ""&lt;ipython-input-18-263dee38fc26&gt;"", line 1, in &lt;module&gt;
    y_pred2 = regressor_OLS.predict(X_new)

  File ""/Users/ritesh.satapathy/anaconda/lib/python3.6/site-packages/statsmodels/base/model.py"", line 749, in predict
    return self.model.predict(self.params, exog, *args, **kwargs)

  File ""/Users/ritesh.satapathy/anaconda/lib/python3.6/site-packages/statsmodels/regression/linear_model.py"", line 359, in predict
    return np.dot(exog, params)

ValueError: shapes (1,50) and (2,) not aligned: 50 (dim 1) != 2 (dim 0)
</code></pre>

<p>I tried <code>X_new = X_test[:,3]</code> but still same error.</p>

<pre><code>Traceback (most recent call last):

  File ""&lt;ipython-input-19-5020d55a4448&gt;"", line 1, in &lt;module&gt;
    y_pred2 = regressor_OLS.predict(X_ne1)

  File ""/Users/ritesh.satapathy/anaconda/lib/python3.6/site-packages/statsmodels/base/model.py"", line 749, in predict
    return self.model.predict(self.params, exog, *args, **kwargs)

  File ""/Users/ritesh.satapathy/anaconda/lib/python3.6/site-packages/statsmodels/regression/linear_model.py"", line 359, in predict
    return np.dot(exog, params)

ValueError: shapes (1,10) and (2,) not aligned: 10 (dim 1) != 2 (dim 0)
</code></pre>
",1,27182,,2,44519,,2023-02-04T10:34:57.987,,5,3,,
102886,1,2021-10-07T09:48:48.397,1,43,<machine-learning><python><scikit-learn><pipelines>,"when I only give command 'fit', my class does 'transform' too","<p>I have created 2 classes, first of which is:</p>
<pre><code>away_defencePressure_idx = 15

class IterImputer(TransformerMixin):
    def __init__(self):
        self.imputer = IterativeImputer(max_iter=10)
        
    def fit(self, X, y=None):
        self.imputer.fit(X)
        return self
    
    def transform(self, X, y=None):
        imputed = self.imputer.transform(X)
        X['away_defencePressure'] = imputed[:,away_defencePressure_idx]
        return X
</code></pre>
<p>and the second one is</p>
<pre><code>home_chanceCreationPassing_idx = 3

class KneighborImputer(TransformerMixin):
    def __init__(self):
        self.imputer = KNNImputer(n_neighbors=1)
        
    def fit(self, X, y=None):
        self.imputer.fit(X)
        return self
    
    def transform(self, X, y=None):
        imputed = self.imputer.transform(X)
        X['home_chanceCreationPassing'] = imputed[:,home_chanceCreationPassing_idx]
        return X
</code></pre>
<p>When I put <code>IterImputer()</code> in a pipeline and <code>fit_transform</code>, the outcome is:</p>
<pre><code>******************** Before Imputing ********************
7856     49.166667
12154    44.666667
10195    48.333333
18871    57.333333
267      48.833333
Name: home_chanceCreationPassing, dtype: float64
# of null values 70
******************** After Imputing ********************
7856     49.166667
12154    44.666667
10195    48.333333
18871    57.333333
267      48.833333
Name: home_chanceCreationPassing, dtype: float64
# of null values 0
</code></pre>
<p>It works fine.</p>
<p>But then if I put the two imputers into one pipeline as follows and fit:</p>
<pre><code>p = Pipeline([
              ('imputerA', IterImputer()),
              ('imputerB', KneighborImputer())
              ])


p = Pipeline([
              ('imputerA', IterImputer()),
              ('imputerB', KneighborImputer())
              ])

X = X_train.copy()

p.fit(X)
</code></pre>
<p>even without transforming</p>
<pre><code>display(X.head())
print('# of null values', X.isnull().sum())
</code></pre>
<p>the outcome would be like</p>
<pre><code>    home_buildUpPlaySpeed   home_buildUpPlayDribbling   home_buildUpPlayPassing home_chanceCreationPassing  home_chanceCreationCrossing home_chanceCreationShooting home_defencePressure    home_defenceAggression  home_defenceTeamWidth   away_buildUpPlaySpeed   away_buildUpPlayDribbling   away_buildUpPlayPassing away_chanceCreationPassing  away_chanceCreationCrossing away_chanceCreationShooting away_defencePressure    away_defenceAggression  away_defenceTeamWidth
7856    50.833333   44.5    37.666667   49.166667   55.000000   48.166667   49.333333   43.000000   53.166667   61.333333   56.0    51.333333   67.000000   58.333333   57.166667   55.000000   47.166667   53.000000
12154   59.333333   69.0    42.666667   44.666667   59.166667   52.333333   40.333333   41.833333   52.666667   47.000000   54.0    41.166667   60.833333   53.833333   54.833333   49.666667   47.500000   56.500000
10195   58.000000   54.0    57.666667   48.333333   53.833333   55.833333   34.833333   60.333333   53.166667   56.333333   41.5    42.333333   52.166667   51.666667   57.166667   46.333333   53.666667   53.333333
18871   61.833333   54.5    58.000000   57.333333   55.000000   49.500000   47.833333   48.000000   57.000000   59.000000   64.0    57.333333   52.500000   63.000000   58.666667   46.500000   47.666667   60.833333
267 49.166667   52.0    46.500000   48.833333   55.833333   47.666667   53.666667   53.833333   54.666667   59.666667   45.0    60.333333   54.666667   58.833333   61.333333   51.500000   57.500000   56.500000
# of null values home_buildUpPlaySpeed           0
home_buildUpPlayDribbling       0
home_buildUpPlayPassing         0
home_chanceCreationPassing     70
home_chanceCreationCrossing     0
home_chanceCreationShooting     0
home_defencePressure            0
home_defenceAggression          0
home_defenceTeamWidth           0
away_buildUpPlaySpeed           0
away_buildUpPlayDribbling       0
away_buildUpPlayPassing         0
away_chanceCreationPassing      0
away_chanceCreationCrossing     0
away_chanceCreationShooting     0
away_defencePressure            0
away_defenceAggression          0
away_defenceTeamWidth           0
dtype: int64
</code></pre>
<p>So the thing is only by doing 'fit', second last step is commited! and the last step is commited when I do 'transform'.</p>
<p>Does anyone know why such thing happens?</p>
",1,102955,,1,126181,120060,2021-10-15T16:23:15.593,2021-10-15T16:23:15.593,1,1,,
11935,1,2016-05-26T15:38:15.903,0,2842,<python><pandas><performance>,python pandas optimization: filtering on text index values,"<p>I have to filter a pandas data frame by matching a complex regular expression on a text index.</p>

<p>The data frame is multi level indexed, and contains more than 2 million records.</p>

<p>The way I'm doing is:</p>

<pre><code>identifiers = self._data.index.get_level_values('identifier')
filt = ... # an_array_of_np.bool_with_the_same_length_as_my_data

pattern = ... # a complex regular expression, as a string
filt = filt &amp; np.array(identifiers.str.contains(pat=pattern, case=False, regex=True), dtype=np.bool)

... # other filterings
</code></pre>

<p>Unfortunately, the line beginning by <code>filt = filt &amp;</code> is very slow.</p>

<p>I'm wondering if you have some ideas to make it faster. I guess that's because of the <code>identifiers.str.contains</code></p>

<p>Thanks a lot!</p>

<hr>

<p>EDIT:</p>

<p>Thanks @Emre</p>

<p>I'm not allowed to share those data, but the code below demonstrates the problem:</p>

<ul>
<li>Step 0: 0:00:00.013527</li>
<li>Step 1: 0:00:00.010127</li>
<li>Step 2: 0:00:04.468114</li>
<li>Step 3: 0:00:02.109594</li>
<li>Step 4: 0:00:00.027437</li>
</ul>

<p>In fact, my feeling is that we apply the regular expression on all the values of the identifiers, while I would expect that the filter applies on the possible values of the index (lost of values are reused many times).</p>

<pre><code>import pandas as pd
import numpy as np
import datetime

N = 2000000
N_DVC = 10000

def getData():
    identifiers = np.random.choice(np.array([
        ""need"", ""need: foo"", ""need: bar"", ""need: foo: bar"", ""foo: need"", ""bar: need"",
        ""not: need"", ""not: need: foo"", ""not: need: bar"", ""not: need: foo: bar"", ""foo: need: not"", ""bar: need: not"",
        ""need ign"", ""need: foo ign"", ""need: bar ign"", ""need: foo: bar ign"", ""foo: need ign"", ""bar: need ign"",
        ""ign need"", ""need: ign foo"", ""need: ign bar"", ""need: foo: ign bar"",
    ]), N)
    devices = np.random.choice(np.arange(N_DVC))
    timestamps = np.random.choice(pd.date_range('1/1/2016 00:00:00', periods=60*60*24, freq='s'), N)
    x = np.random.rand(N)
    y = np.random.rand(N)
    data = pd.DataFrame({'identifier': identifiers, 'device': devices, 'timestamp': timestamps, 'x': x, 'y': y})
    data.set_index(['device', 'identifier', 'timestamp'], drop=True, inplace=True)
    return data

def filterData(data):
    # I know those regular expressions are not perfect for the example,
    # but it mimics the real expressions I have
    rexpPlus = '^(?:[^\s]+:\s)*need(?:(?::\s[^\s]+)*:\s[^\s]+)?$'
    rexpMinus = '(?::\s)(?:(?:not)|(?:ign))(?::\s)'

    tic = datetime.datetime.now()
    identifiers = data.index.get_level_values('identifier')
    print(""- Step 0: %s"" % str(datetime.datetime.now() - tic))

    tic = datetime.datetime.now()
    filt = np.repeat(np.False_, data.shape[0])
    print(""- Step 1: %s"" % str(datetime.datetime.now() - tic))

    tic = datetime.datetime.now()
    filt = filt | np.array(identifiers.str.contains(pat=rexpPlus, case=False, regex=True), dtype=np.bool)
    print(""- Step 2: %s"" % str(datetime.datetime.now() - tic))

    tic = datetime.datetime.now()
    filt = filt &amp; (~np.array(identifiers.str.contains(pat=rexpMinus, case=False, regex=True), dtype=np.bool))
    print(""- Step 3: %s"" % str(datetime.datetime.now() - tic))

    tic = datetime.datetime.now()
    data = data.loc[filt, :]
    print(""- Step 4: %s"" % str(datetime.datetime.now() - tic))

    return data

if __name__ == ""__main__"":
    filterData(getData())
</code></pre>
",1,11952,,0,3024,3024,2016-07-26T12:04:21.913,2016-05-27T10:55:56.833,1,1,,
42891,1,2018-12-19T16:58:27.747,0,2253,<machine-learning><python><dataset><pandas>,How Can I Solve it? TypeError: fillna() got an unexpected keyword argument 'implace',"<p>I am trying to replace NaN values in a given dataset with this</p>

<pre><code>import pandas as pd 
import quandl
import math

df.fillna(-9999, implace=True)
</code></pre>

<p>But I keep on getting this error:</p>

<p>**</p>

<p>Traceback (most recent call last):</p>

<p>File ""regression.py"", line 44, in 
    df.fillna(0,implace=True)   </p>

<p>File ""/home/compname/.local/lib/python3.6/site-packages/pandas/core/frame.py"", line 3790, in fillna
    downcast=downcast, **kwargs) </p>

<p>TypeError: fillna() got an unexpected keyword argument 'implace'</p>

<p>**</p>
",1,42892,,0,64593,,2018-12-19T17:02:45.447,,1,2,2018-12-20T00:34:15.743,
104925,1,2021-12-09T12:35:09.690,1,551,<python><neural-network><multiclass-classification><jupyter><smote>,SMOTE for multi-class balance changes the shape of my dataset,"<p>So I have a dataset of shape (430,17), that consists of 13 classes (<strong>imbalanced</strong>) and 17 features.
The end goal is to create a NN which btw works when I import the imblanced dataset, however when i try to over-sample the minority classes using <strong>SMOTE in jupyter notebook</strong>, the classes do get balanced but also the shape changes.</p>
<pre><code>from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import OneHotEncoder
from imblearn.pipeline import Pipelineenter 

steps = [('onehot', OneHotEncoder()), ('smt', SMOTE())]
pipeline = Pipeline(steps=steps)

X_res, y_res = pipeline.fit_resample(X, y)
</code></pre>
<p>The y_res shape is (754,) from  y shape which was (430,), so upsampling works, also by checking:</p>
<pre><code>unique, counts = np.unique(y_res, return_counts=True)
print(np.asarray((unique, counts)).T)
</code></pre>
<p>the classes have been balanced.
However, the X_res shape has now changed to (754, 5553), from X shape which was (430, 17).
Then, if I fit these data in my NN it doesnt work of course since the input_dim has changed for my input layer.</p>
<p>My <strong>question</strong> is, did the SMOTE procedure add not only rows to balance the classes but also columns?
<strong>Should't I got X_res with shape (754, 17)?</strong> and because I need these data for a NN they have to be arrays, or numpys, instead of pd.dataframes, which is also complicated to understand where that 5553 columns come from.</p>
<p>I am new in python and jupyter so I do not know how to solve this, and I would really appreciate any help :)</p>
",1,104927,,1,128690,,2021-12-09T14:43:34.543,,1,1,,
39960,1,2018-10-20T10:51:00.063,0,26975,<machine-learning><python><nltk><ipython>,remove special character in a List or String,"<p><a href=""https://i.stack.imgur.com/HYB0T.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HYB0T.png"" alt=""enter image description here""></a></p>

<p>Input_String is Text_Corpus of Jane Austen Book</p>

<p>output Should be :
['to', 'be', 'or', 'not', 'to', 'be', 'that', 'is', 'the', 'question']</p>

<p>But getting this Output :
['to', '<strong>be,</strong>', 'or', 'not', 'to', '<strong>be:</strong>', '<strong>that'</strong>, 'is', 'the', '<strong>question!</strong>']</p>
",1,39976,,0,61071,61071,2021-02-08T15:39:44.580,2018-10-20T15:45:01.677,5,1,,
14730,1,2016-10-24T05:34:37.707,0,731,<machine-learning><python><classification><feature-engineering><text>,"Which approach for user classification on chat text (classifier, representation, features)?","<p>I'm trying to train a classifier to classify text from a chat between 2 users so later on I can predict who of the two users is more likely to say X sentence/word. To get there I mined the text from the chat log and ended up with two arrays of words, <code>UserA_words</code> and <code>UserB_words</code>. </p>

<p>Which classifier should I use fot this purpose and what structure the training data should have? I've researched for the bag of words structure but dont know exactly how to train a classifier with data in that format. </p>

<p>To clarify this last point, for now I have the data in a dict like <code>{""hello"":34, ""how"":12}</code> and so on, being the terms word:frequency of each user. As far as I know, there is no way to use this two dicts as a classifier fit input. So, how do I transform this 2 dicts into an array that I can use to train a classifier (let's say I want to use a gaussian Naive Bayes just for the sake of the example)</p>
",1,14768,,0,25526,8501,2016-10-27T09:34:24.390,2016-10-27T09:34:24.390,1,12,,
15043,1,2016-11-10T12:09:42.713,7,12648,<python><pandas><visualization><distribution><histogram>,Plotting different values in pandas histogram with different colors,"<p>I am working on a dataset. The dataset consists of 16 different features each feature having values belonging to the set (0, 1, 2). In order to check the distribution of values in each column, I used <code>pandas.DataFrame.hist()</code> method which gave me a plot as shown below:
<a href=""https://i.stack.imgur.com/73mY7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/73mY7.png"" alt=""Figure"" /></a></p>
<p>I want to represent the distribution for each value in a column with different color. For example, in column 1, all the values corresponding to '0' should be in red color while the values corresponding to '1' in green color and so on. How can I do this? Please help!</p>
",1,15185,,7,15412,1330,2022-09-07T12:46:12.683,2022-09-07T12:46:12.683,2,4,,
32103,1,2018-05-24T11:44:56.247,2,311,<python><pandas><matplotlib>,n days back average for each day,"<p>I have a dataset as below and I want to see 3 days high low average, back from for each day in the same plot.</p>

<pre><code>    index   closed  high    low     open
tarih                   
2018-05-18  1364    0.00000442  0.00000445  0.00000405  0.00000416
2018-05-19  1365    0.00000458  0.00000465  0.00000427  0.00000442
2018-05-20  1366    0.00000482  0.00000489  0.00000448  0.00000455
2018-05-21  1367    0.00000489  0.00000492  0.00000463  0.00000482
2018-05-22  1368    0.00000475  0.00000492  0.00000465  0.00000487
2018-05-23  1369    0.00000461  0.00000486  0.00000450  0.00000475
2018-05-24  1370    0.00000462  0.00000480  0.00000455  0.00000464
</code></pre>

<p>for example for 05-24 it will calculate 21,22,23 days high low average and point it to 05-24.</p>
",1,49124,,2,52651,201,2019-04-11T13:02:33.997,2019-04-03T06:09:15.503,1,3,,
21677,1,2017-07-25T11:55:54.600,1,2933,<python><data-mining><scikit-learn><decision-trees>,How to use boolean data in DecisionTreeClassifier in sklearn?,"<p>I am trying to build a decision tree using python and sklearn DecisionTreeClassifier.</p>

<p>One of the data_type used for splitting the tree  is Boolean(let it be x).However the tree that is generated contains comparisons like x&lt;=0.5 . 
This does not make sense.</p>

<p>Can anybody suggest how to use boolean values in Decision trees.</p>
",1,21683,,1,37063,33701,2017-07-25T14:43:36.630,2017-07-25T12:18:31.423,1,1,,
28405,1,2018-02-28T13:12:11.137,1,238,<python><clustering><bigdata><categorical-data><dimensionality-reduction>,Applying machine learning algorithms to subset of attributes in dataframe,"<p>I have this huge mixed data set consisting of both numerical and categorical attributes which upon OneHotEncoding results into a data set with very high dimensionality. </p>

<p>Is it wise to apply machine learning algorithms like K-means clustering, dimensionality reduction and regression on subsets of data set? For example applying K-means clustering to numerical columns first and join the result with categorical data set later.</p>
",1,28410,,1,44701,,2018-02-28T15:38:15.987,,1,1,,
76399,1,2020-06-21T13:10:01.493,2,98,<machine-learning><python><scikit-learn><random-forest><accuracy>,Overfitting results with Random Forest Regression,"<p>I have one image that contains for each pixel 4 different values.
I have used RF in order to see if I can predict the 4th value based on the other 3 values of each pixel. for that I have used python and scikit learn. first I have fit the model, and after validate it I used it to predict this image.
I was very happy and scared to see that I got very high accuracy for my model : 99.95%!
but then when I saw the resulted image it absolutly wasn't 99.95% of accuracy:</p>
<p>original image:</p>
<p><a href=""https://i.stack.imgur.com/Jqsv5.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Jqsv5.jpg"" alt=""enter image description here"" /></a></p>
<p>result image:</p>
<p><a href=""https://i.stack.imgur.com/Ui21R.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Ui21R.jpg"" alt=""enter image description here"" /></a></p>
<p>(I have makrd the biggest and most visible difference).</p>
<p><strong>My question is- why would I get this high accuracy when the visualization shows very well that there is much less accuracy? I understand it might come from overfitting but then how this different is not detected?</strong></p>
<p>edit:
Mean Absolute Error: 0.048246606512422616
Mean Squared Error: 0.00670919112477127
Root Mean Squared Error: 0.0819096522076078
Accuracy: 99.95175339348758</p>
",1,76400,,2,98535,98535,2020-06-21T13:47:47.513,2020-06-21T13:47:47.513,1,3,,
13358,1,2016-08-10T17:11:59.087,3,325,<machine-learning><python><pca>,PCA algorithm problems - Python,"<p>I have implemented PCA algorithm and I understood it very well but still I have some questions. My code is below and it's very simple implementation.</p>

<pre><code>import numpy as np

x = np.loadtxt('CCPP', delimiter=',')
row, column = x.shape

# Mean normalization
for i in range(column):
    x[:,i] = (x[:,i] - x[:,i].mean()) / (x[:,i].max() - x[:,i].min())

sigma = x.transpose().dot(x) / row
u, s, v = np.linalg.svd(sigma, 0)
z = x.dot(u[:,:3]) ## new features

new_x = z.dot(u[:,:3].transpose()) ##reconstruction
</code></pre>

<p><strong>First Question</strong></p>

<p>As you can see above my sigma variable is </p>

<blockquote>
  <p>x.transpose().dot(x) / row</p>
</blockquote>

<p>It's giving to me an nxn matrix (n is number of features). But sigma's formula is $$\Sigma = \frac{1}{n} \sum_{i=1}^n x^{(i)} {x^{(i)}}^T$$</p>

<p>Why there is a summation symbol in formula? I mean, if I use this sigma formulation then sigma is going to be a number, not a matrix. I have to get nxn matrix, right? So is my sigma implementation correct? or am I missing something about the formula?</p>

<p><strong>Second Question</strong></p>

<p>When we are reconstructing X (at the bottom in the code), should new_x equal to my first X? I mean, I reduced dimension of the data set, then I reconstructed it, original dataset and reconstructed dataset must be the same, right? This is my second question.</p>

<p><strong>Third Question</strong></p>

<p>This one is easy. Should I use data compression for each of my dataset which has 1000, 100000 or more features? I mean, can I always use it? Is it a good choice to use it every time?</p>
",1,13388,,3,20926,23283,2016-08-12T09:33:49.477,2016-08-11T07:10:01.160,2,2,,
38548,1,2018-09-20T14:18:36.347,1,2969,<python><time-series><lstm><forecasting>,LSTM future steps prediction with shifted y_train relatively to X_train,"<p>I'm trying to predict simple one feature time series data with shifted train data. The source looks like this:</p>
<pre><code>   DATE              PRICE
0  1987-05-20        18.63
1  1987-05-21        18.45
2  1987-05-22        18.55
3  1987-05-25        18.60
4  1987-05-26        18.63
</code></pre>
<p>Actual code with data link download gisted here: <a href=""https://gist.github.com/georgeMuraveiAlkh/c42f720fb128859e19aeeea1326a934d"" rel=""nofollow noreferrer"">gist</a></p>
<p>So the main problem is that it actually can't predict next steps. Roughly speaking: y_train &quot;shifted&quot; relatively to X_train by timesteps defined in parameters. So we getting for X_train and y_train something like this:</p>
<pre><code>timesteps = 5
data = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]
# After manipulations which you can find in gist we getting this:
X_train =
    [[ 1  2  3  4  5]
     [ 2  3  4  5  6]
     [ 3  4  5  6  7]
     [ 4  5  6  7  8]
     [ 5  6  7  8  9]
     [ 6  7  8  9 10]
     [ 7  8  9 10 11]
     [ 8  9 10 11 12]
     [ 9 10 11 12 13]
     [10 11 12 13 14]]
y_train =
    [[ 6  7  8  9 10]
     [ 7  8  9 10 11]
     [ 8  9 10 11 12]
     [ 9 10 11 12 13]
     [10 11 12 13 14]
     [11 12 13 14 15]
     [12 13 14 15 16]
     [13 14 15 16 17]
     [14 15 16 17 18]
     [15 16 17 18 19]]
</code></pre>
<p>So it is fair to assume that after training LSTM model with X_train (as input) and y_train (as output) we getting model which able to forecast n timesteps ahead. BUT I encountered a problem that trained model not predicting anything - only &quot;duplicates&quot; X_test data. For the convenience
I rebuild X_test data and plot it with y_test data which returns from model.predict():
<a href=""https://i.stack.imgur.com/dtnQQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/dtnQQ.png"" alt=""plot of X_test and y_test"" /></a></p>
<p>So this is result which also contains 'Dataset prices' (pure data from dataset[upper_train + timesteps:]) for clarity.</p>
<p>I can not find where I made a mistake (or maybe this approach is bad?) so I will be grateful for any help!</p>
",1,38553,,1,59377,-1,2019-10-06T09:52:40.270,2020-06-16T11:08:43.077,2,1,,
25073,1,2017-11-24T10:15:36.180,5,3519,<python><scikit-learn><dataset>,How can l get 50 % examples in training set and 50% in test set for each class when splitting data?,"<p>l have a dataset of 200 examples with 10 classes. l would like to split the dataset into training set 50% and test set 50%.</p>

<p>for each class, l have 20 examples. Hence, l would like to get for each class : 10 training examples and 10 test examples.</p>

<p>Here are my classes :</p>

<pre><code>classes=['BenchPress', 'ApplyLipstick', 'BabyCrawling', 'BandMarching', 'Archery', 'Basketball', 'ApplyEyeMakeup', 'BalanceBeam', 'BaseballPitch', 'BasketballDunk']
</code></pre>

<p>l tried the following :</p>

<pre><code>from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(final_data, true_label, test_size=0.50, random_state=42)
</code></pre>

<p>However it returns a 50% training set and 50 % test set, without respecting the proportion for each class (l would like to get 10 examples in test set and 10 examples in training set for each class).
Here is the resulted splitting : </p>

<p><a href=""https://i.stack.imgur.com/1W20m.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/1W20m.png"" alt=""enter image description here""></a></p>
",1,25077,,5,42275,,2018-12-17T10:19:38.147,,1,1,,
9793,1,2016-01-14T16:37:46.247,1,1213,<machine-learning><python><scikit-learn><prediction>,Running examples from scikit-learn tutorials,"<p>I am new to scikit-learn. I went through the examples given in the docs and I downloaded the script for recognizing images of hand-written digits. When I made the script to run on my laptop, I got the following errors:</p>
<pre><code>Traceback (most recent call last):
   File &quot;C:\Python34\plot_digits_classification.py&quot;, line 22, in &lt;module&gt;
    from sklearn import datasets, svm, metrics
    File &quot;C:\Python34\lib\site-packages\sklearn\__init__.py&quot;, line 57, in&lt;module&gt;
    from .base import clone
   File &quot;C:\Python34\lib\site-packages\sklearn\base.py&quot;, line 11, in &lt;module&gt;
  from .utils.fixes import signature
  File &quot;C:\Python34\lib\site-packages\sklearn\utils\__init__.py&quot;, line 11, in &lt;module&gt;
   from .validation import (as_float_array,
   File &quot;C:\Python34\lib\site-packages\sklearn\utils\validation.py&quot;, line 16, in &lt;module&gt;
   from ..utils.fixes import signature
  File &quot;C:\Python34\lib\site-packages\sklearn\utils\fixes.py&quot;, line 324, in &lt;module&gt;
   from scipy.sparse.linalg import lsqr as sparse_lsqr
   File &quot;C:\Python34\lib\site-packages\scipy\sparse\linalg\__init__.py&quot;, line 109, in &lt;module&gt;
   from .isolve import *
  File &quot;C:\Python34\lib\site-packages\scipy\sparse\linalg\isolve\__init__.py&quot;, line 6, in &lt;module&gt;
  from .iterative import *
  File &quot;C:\Python34\lib\site-packages\scipy\sparse\linalg\isolve\iterative.py&quot;, line 7, in &lt;module&gt;
  from . import _iterative
  ImportError: DLL load failed: The specified module could not be found.
</code></pre>
<p>Please help me. Also, I want to know if I want to load data for prediction, how should I do that? For example, if I want to test a hand written digit that is stored somewhere on my disk, how to prepare that data for loading and passing into this model for prediction?</p>
",1,9796,,1,15412,85045,2020-12-30T16:04:09.527,2020-12-30T16:04:09.527,2,1,,
12999,1,2016-07-26T08:37:19.570,1,3739,<python><scikit-learn><predictive-modeling><categorical-data><dataframe>,Scikit Learn OneHotEncoded Features causing error in classifier,"<p>I’m trying to prepare data for input to a Decision Tree and Multinomial Naïve Bayes Classifier.</p>
<p>This is what my data looks like (pandas dataframe):</p>
<pre><code>Label  Feat1  Feat2  Feat3  Feat4

0        1     3       2      1
1        0     1       1      2
2        2     2       1      1
3        3     3       2      3
</code></pre>
<p>I have split the data into dataLabel and dataFeatures.
Prepared dataLabel using <code>dataLabel.ravel()</code></p>
<p>I need to discretize features so the classifiers treat them as being categorical not numerical.</p>
<p>I’m trying to do this using <code>OneHotEncoder</code>:</p>
<pre><code>enc = OneHotEncoder()

enc.fit(dataFeatures)
chk = enc.transform(dataFeatures)
from sklearn.naive_bayes import MultinomialNB

mnb = MultinomialNB()

from sklearn import metrics
from sklearn.cross_validation import cross_val_score
scores = cross_val_score(mnb, Y, chk, cv=10, scoring='accuracy')
</code></pre>
<p>I get this error: <code>bad input shape (64, 16)</code></p>
<p>This is the shape of label and input:</p>
<p><code>dataLabel.shape = 72</code>
<code>chk.shape = 72,16</code></p>
<p>Why won't the classifier accept the onehotencoded features?</p>
<p><strong>EDIT: Adding how I got dataFeatures</strong></p>
<p><code>dataFeatures = data[['Accpred', 'Gyrpred', 'Barpred', 'altpred']]</code></p>
<p><code>Y = dataLabel.ravel()</code></p>
",1,13001,,1,17772,85045,2021-01-05T16:04:22.570,2021-01-05T16:04:22.570,1,4,,
46885,1,2019-03-06T22:13:34.553,1,6105,<python><keras>,how to reshape xtrain array and what about input shape?,"<pre><code>from keras.datasets import mnist
from keras.layers import Activation,Dense,Convolution2D
from keras.models import save_model,load_model,Sequential
from keras.callbacks import TensorBoard
import matplotlib.pyplot as pl

(xtrain,ytrain),(xtest,ytest)=mnist.load_data()
model = Sequential()
model.add(Convolution2D(32,3,activation='relu',input_shape=(60000,28,28)))
model.add(Dense(10, activation='relu'))

model.summary()

model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              &lt;space&gt;metrics=['accuracy'])

model.fit(xtrain, ytrain, epochs=10, batch_size=60000)
</code></pre>
",1,46895,,1,69553,29587,2019-03-08T00:08:20.937,2019-03-07T23:55:38.717,1,1,,
21887,1,2017-08-01T16:54:59.527,6,1520,<python><neural-network><deep-learning><keras><q-learning>,Keras input dimension bug?,"<p>Keras has a problem with the input dimension. My first layer looks like this:</p>

<pre><code>model.add(Dense(128, batch_size=1, input_shape=(150,), kernel_initializer=""he_uniform"", kernel_regularizer=regularizers.l2(0.01), activation=""elu""))
</code></pre>

<p>As you can see the input dimension should be (150,) and with the fixed batch_size it is (1, 150)</p>

<p>My data has dimension (150,) and could be for example a numpy array with 150 zeros.</p>

<pre><code>old_qval = model.predict(old_state_m)
</code></pre>

<p>Here I call the model to make a prediction. Normally Keras should automatically add the batch size as an extra dimension so I should end up with (1, 150) which would work. But Keras adds the dimension for the batch size at the wrong place and I end up with (150, 1). I tried tensorflow and theano backend. </p>

<p>Do I have a bug in my code or is it a problem with Keras?</p>

<p>How can I fix the problem? I could reshape my input data but it already has the needed shape of (150,) and should be fine. What else could I do?</p>

<p>If I should provide more data or code feel free to ask.</p>
",1,21899,,6,37300,836,2017-08-02T12:17:05.573,2017-08-02T11:29:50.797,1,4,,
9652,1,2016-01-06T15:07:08.563,2,272,<python><bigdata>,Writing custom data analysis program,"<p>I have a number of large datasets (10GBs) each with data fetched from a NoSQL database that I have remotely downloaded on my desktop. I would like to write a Python program to run some custom data analysis (plots - preferably interactive) and export custom reports in html or pdf.</p>

<p>I was wondering how people do the following:</p>

<p>1) Store the data. For the moment I have plain text files (each file has rows of a fixed number of columns - most of the data are categorical). Would it make sense to save those in some database (SQL) or hdf5? Any hints on which is preferrable?</p>

<p>2) Which plotting library would you propose for the graphs? I have seen about bookeh and matplotlib supports interactive widgets but I don't know what people normally use.</p>

<p>3) Could I export the analysis results in an IPython notebook and then in html programmatically?</p>
",1,9654,,2,14487,14487,2016-01-06T16:30:57.220,2016-01-06T16:05:26.653,1,1,,
111456,1,2022-05-31T19:14:05.520,0,62,<machine-learning><python><classification>,Classification Produces too Many False Positives or False Negatives,"<p>I trying to classify this data set (<a href=""https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset"" rel=""nofollow noreferrer"">https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset</a>) to classify if a patient is at risk for having a stroke. As the title says, whatever test I run to classify the patients, I keep running into the final results having too many false-positives or too many false-negative results.</p>
<p>The data itself is severely imbalanced (95% 0s to 5% 1 (had a stroke)) and in spite of doing various things to try and balance it or compensate for it, I keep running into the same ends.</p>
<p>For the record, yes, I have tried SMOTEing the training data set with no success. Furthermore, I've read a few articles against SMOTEing the test data set due to data leakage (e.g. <a href=""https://machinelearningmastery.com/data-leakage-machine-learning/"" rel=""nofollow noreferrer"">https://machinelearningmastery.com/data-leakage-machine-learning/</a> and <a href=""https://imbalanced-learn.org/stable/common_pitfalls.html#data-leakage"" rel=""nofollow noreferrer"">https://imbalanced-learn.org/stable/common_pitfalls.html#data-leakage</a>).</p>
<p>Here are the codes I've been using. I'm using Python 3.10:</p>
<pre><code>X = stroke_red.drop('stroke', axis=1)  # Removes the &quot;stroke&quot; column.
Y = stroke_red.stroke  # We're storing the dependent variable here.
####### Pipelining #######
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer

cat_pipe = Pipeline(
    steps=[
        (&quot;impute&quot;, SimpleImputer(strategy=&quot;most_frequent&quot;)),
        (&quot;oh-encode&quot;, OneHotEncoder(handle_unknown='ignore', sparse=False))
    ]
)
num_pipe = Pipeline(
    steps=[
        (&quot;impute&quot;, SimpleImputer(strategy=&quot;mean&quot;)),
        (&quot;scale&quot;,StandardScaler())
    ]
)

cont_cols = X.select_dtypes(include=&quot;number&quot;).columns
cat_cols = X.select_dtypes(exclude=&quot;number&quot;).columns

process = ColumnTransformer(
    transformers=[
        (&quot;numeric&quot;, num_pipe, cont_cols),
        (&quot;categorical&quot;, cat_pipe, cat_cols)
    ]
)

####### Splitting the data into train/test #######
from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, StratifiedKFold

#preprocessing.

X_process = process.fit_transform(X)
Y_process = SimpleImputer(strategy=&quot;most_frequent&quot;).fit_transform(
    Y.values.reshape(-1,1)
)

X_train, X_test, Y_train, Y_test = train_test_split(X_process, Y_process, test_size=0.3,
                                                    random_state=1111)  # Splits data into train/test sections. Random_state = seed.
</code></pre>
<pre><code>from imblearn.over_sampling import SMOTENC
from imblearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression

sm = SMOTENC(categorical_features=[0,2,3], random_state=1111)
X_train, Y_train = sm.fit_resample(X_train, Y_train)
</code></pre>
<p>Finally, the Extreme Gradient Boosting algorithm:</p>
<pre><code>import xgboost as xgb
boostah = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100000, max_depth=5,
                            learning_rate=0.000001, n_jobs=-1, scale_pos_weight=20
                            ) # scale_pos_weight is a weight. #0s / #1s .
boostah.fit(X_train,Y_train)

predict = boostah.predict(X_test)

print('Accuracy = ', accuracy_score(predict, Y_test))
print(&quot;F1 Score = &quot;, f1_score(Y_test, predict))
print(classification_report(Y_test, predict))
print(confusion_matrix(Y_test, predict))
</code></pre>
<p>Here are the confusion matrix results. Bear in mind, I had the SMOTE section commented out when running this:</p>
<pre><code>Accuracy =  0.6966731898238747
F1 Score =  0.2078364565587734
              precision    recall  f1-score   support
           0       0.99      0.69      0.81      1459
           1       0.12      0.82      0.21        74
    accuracy                           0.70      1533
   macro avg       0.55      0.76      0.51      1533
weighted avg       0.95      0.70      0.78      1533
[[1007  452]
 [  13   61]]
</code></pre>
<p>Here are the results with SMOTE on:</p>
<pre><code>Accuracy =  0.39008480104370513
F1 Score =  0.13506012950971324
              precision    recall  f1-score   support
           0       1.00      0.36      0.53      1459
           1       0.07      0.99      0.14        74
    accuracy                           0.39      1533
   macro avg       0.54      0.67      0.33      1533
weighted avg       0.95      0.39      0.51      1533
[[525 934]
 [  1  73]]
</code></pre>
<p>Any tips on fixing this? If you need my complete code, let me know, and I'll get it to you.</p>
",1,111487,,0,136403,,2022-06-02T06:39:00.300,,1,1,,
74313,1,2020-05-16T23:41:32.193,0,406,<python><clustering><pandas><k-means><matplotlib>,Plotting clustered sentences in Python,"<p>I have the following three sentences, extracted from a dataframe. I would like to check the similarity and create clusters based on their level of similarity. </p>

<pre><code>Authors       Sentences
John Smith   Some people do not completely understand the risk of UV rays. 
Jane Lower   People do not understand the risk of UV rays, wrote the journalist in the Herald. 
Craig Avatan In Berlin, people do not know how dangerous can be for their health a long exposure to UV rays. 
</code></pre>

<p>I would need to cluster them based on words and their sequences (like plagiarism). 
I have tried to use k-means, but I have not completely understood how to create clusters to plot. 
Something like this: </p>

<p><a href=""https://i.stack.imgur.com/S7NVs.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/S7NVs.png"" alt=""enter image description here""></a></p>

<p>I have tried to use k-mean as follows: </p>

<pre><code>def sent_tokenization (line):
    line = re.sub(r""[^a-zA-Z]"", "" "", line.lower())
    words = word_tokenize(line)
    words_lemmed = [WordNetLemmatizer().lemmatize(w) for w in words if w not in stop_words_list]
    return words_lemmed

tfidf_vect = TfidfVectorizer(tokenizer= sent_tokenization)
tfidf = tfidf_vect.fit_transform(df['Sentences'])

kmeans = KMeans(n_clusters=2).fit(tfidf)
</code></pre>

<p>However I am not able to plot the results. What I am looking for is something that can be easily visualised. Specifically, I would need to plot in a scatter plot as in the example, which can show the name of authors based on their sentence similarity, like in plagiarism. I am trying to see which authors have written similar texts. </p>

<p>In my example, I should have the first two authors closers than the third one, as their sentences are very similar (in terms of words and structure). </p>

<p>Could you please give me advice on how to plot/cluster the above information? 
If you need more information, feel free to ask. </p>
",1,74320,,0,96815,,2021-07-02T18:02:00.327,,1,4,,
116255,1,2022-11-17T10:24:33.317,0,46,<python><preprocessing>,preprocess unbalanced skewed data,"<p>I am trying to find a way to preprocess my data.
The data is as follow:</p>
<div class=""s-table-container"">
<table class=""s-table"">
<thead>
<tr>
<th style=""text-align: left;"">study</th>
<th style=""text-align: center;"">person_id</th>
<th style=""text-align: center;"">energy_1</th>
<th style=""text-align: center;"">energy_2</th>
<th style=""text-align: left;"">y</th>
</tr>
</thead>
<tbody>
<tr>
<td style=""text-align: left;"">study_id</td>
<td style=""text-align: center;"">A</td>
<td style=""text-align: center;"">2.3</td>
<td style=""text-align: center;"">-1.05</td>
<td style=""text-align: left;"">1</td>
</tr>
<tr>
<td style=""text-align: left;"">study_id2</td>
<td style=""text-align: center;"">B</td>
<td style=""text-align: center;"">1.03</td>
<td style=""text-align: center;"">0.04</td>
<td style=""text-align: left;"">0</td>
</tr>
</tbody>
</table>
</div>
<p>Statistically speaking, we can see that for each study, the value of energy_1 and energy_2 brings a lot of value to determine wether the person is 0 or 1 in the y column: We can mostly only use them to make the prediction.
But when we are using the whole dataset and mixing the studies together, the model used (a binary XGBoost classifier) is no longer able to properly predict the label.</p>
<p>Can you give hints on how to  preprocess/transform my data so that the model could react properly independently of the study?</p>
<p>I am aware that XGBoost do not need normalized data.</p>
",1,116263,,0,131441,131441,2022-11-18T15:21:39.437,2022-11-17T12:46:08.570,1,8,,
40394,1,2018-10-29T17:03:42.697,1,593,<python><linear-regression>,Linear Regression in python with multiple outputs,"<p>I have a time series dataset which represented as following: </p>

<pre><code>x=[ 
       [12.19047619,  18.28571429,   6.0952381 ] ,

       [ 80.98765432,  14.17283951,  11.13580247 ] ,

       [ 50.82644628,  16.26446281,   9.14876033 ] , .... ]


and to predicted --&gt;
 Y  = [13.9,  18,   14.987]
</code></pre>

<p>How I can use LASSO and SVR linear regression models in python to predict Y (which represented as a vector as shown in the above example) </p>
",1,40400,,1,49752,,2018-10-29T18:45:33.033,,1,3,,
55213,1,2019-07-07T12:14:51.077,2,114,<python><pandas><numpy>,Converting a Pandas Series string of multiple attributes into individual attributes?,"<p>I'm working on an Airbnb dataset in order to predict the nightly price--where each example is one Airbnb listing (ie a listing for someone's house, room, apartment, etc). Each feature is a characteristic of the listing (ie # bedrooms, # bathrooms, average review score etc).</p>

<p>One of the features is 'amenities', which are the amenities offered for the listing (ie wifi, tv, kitchen, etc). Each example contains a string of its own amenities like so:</p>

<pre><code>{TV,""Cable TV"",Wifi,""Air conditioning"",Kitchen,Elevator,Heating,Washer,Dryer,""Smoke detector"",""Fire extinguisher"",Essentials,Shampoo,Hangers,""Hair dryer"",Iron,""Laptop friendly workspace"",""Self check-in"",Keypad,""Private living room"",""Hot water"",""Bed linens"",Microwave,""Coffee maker"",Refrigerator,Dishwasher,""Dishes and silverware"",""Cooking basics"",Oven,Stove,""Long term stays allowed""}
</code></pre>

<p>Dtype is a string ('O' in pandas).</p>

<p>I plan to remove the {} on the ends and the "" quote signs using pd.Series.str.replace() for each character--unless those are useful to keep.</p>

<p>But past that I'm not sure of the best way to go about handling the feature itself.</p>

<p>My questions is:</p>

<p>Should I create individual binary columns for each amenity (ie 1 in column ""TV"" if TV is an amenity, 0 in column ""wifi"" if wifi isn't offered)? I'm hesitant because that would add a few dozen columns. If I should do this, how can I convert the current format to binary columns with Pandas?</p>
",1,55250,,2,71231,,2020-08-14T08:15:12.663,,1,2,,
65984,1,2020-01-06T20:06:31.553,2,32,<machine-learning><python><scikit-learn><data-mining><optimization>,Maximize one data point,"<p>I am completely new to data science and looking to narrow down the search and reduce the learning curve required to solve problems like the one given below</p>

<hr>

<p>I have a data set with 7 columns , 
Column A(all positive decimal) is the data point I want to maximize.
Column B and C are boolean values
remaining columns are a combination of positive and negative decimal numbers.
I want to find some relation and insights from all colums such that I can maximize the sum of column A.</p>
",1,65986,,2,87930,,2020-01-06T21:08:07.513,,1,2,,
56178,1,2019-07-22T18:01:31.530,5,611,<machine-learning><python><classification><dataset><xgboost>,"XGBoost, binary classification: uneven number of observations per user","<p>I'm working on a binary classification problem with XGBoost and I have a dataset, which has uneven number of observations per user. For some users there are over 100 observations, whereas for some users there are only a few. The ""USER_ID"" feature is not used as an input for XGBoost. </p>

<p>More specifically, I'm trying to model user physical activity (data collected from wearable trackers) in respect to sleep quality, and some of the variables are demographical features such as as age and sex, alongside steps, heart rate etc. Considering the differing amount of data collected from users, some user behaviours (such night-shift work) are represented more in the data than others due to the number of observations. </p>

<p>How should I take this into account when working with XGBoost?</p>

<pre><code>USER_ID  AGE  SEX  X1  X2    ...  y
1        20   M    65  3000  ...  1
1        ...  ...  ... ...   ...  0
1        ...  ...  ... ...   ...  1
2        30   F    80  2500  ...  0
2        ...  ...  ... ...   ...  1
3        40   M    77  8000  ...  0
</code></pre>

<p>The classes are otherwise balanced and I'm able to get good performance for the classifier. </p>
",1,56850,,5,67110,67110,2019-08-02T16:35:17.193,2019-07-23T11:56:26.440,2,3,,
62294,1,2019-10-27T23:24:52.727,0,741,<python><scikit-learn><logistic-regression><missing-data><dummy-variables>,How to Keep Missing Values in Ordinal Logistic Regression,"<p>I’m using <code>mord</code> package in python to do ordinal logit regression (predict response to movie rating 1-5 stars).</p>

<p>One of my predictor variables is also ordinal but there are some missing values where the viewer skipped a question because it wasn’t applicable due to skip logic from a prior question or because they missed it.
What’s the best way to indicate a value is “missing” and/or “not applicable” while also retaining the ordinal nature of this predictor variable for everyone else? I don’t think I should delete this viewer or try to impute the value.</p>

<p>I get an error if I leave the <code>NaN</code>. I thought about dummy coding so I have something like question5_never, question5_sometimes, question5_always, question5_na, question5_missing, but I not sure.</p>
",1,62298,,0,74946,,2019-10-28T19:02:20.643,,2,2,,
62131,1,2019-10-23T15:19:29.537,0,815,<machine-learning><python>,Problem importing dataset,"<p>I am new to machine learning and I am trying to build a classifier. My problem is that I am not able to import the dataset I need. In particular, I put my dataset in the Desktop and what I did is:</p>

<pre><code>#pakages
import numpy as np
import pandas as pd
import jsonlines                   #edit

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import *
from sklearn.naive_bayes import *
from sklearn.metrics import confusion_matrix, classification_report
from sklearn import svm

#for visualizing data
import matplotlib.pyplot as plt
import seaborn as sns; sns.set(font_scale=1.2)

%matplotlib inline

print('Libraries imported.')
</code></pre>

<p>now, after these imports I want to use the function </p>

<pre><code>training_set = pd.read_json('\Desktop\training_dataset.jsonl')  #edit
print(training_set.head())
</code></pre>

<p>to import my dataset. The problem is that what i get is:</p>

<pre><code>ValueError                                Traceback (most recent call last)
&lt;ipython-input-16-f789503c3c7c&gt; in &lt;module&gt;
----&gt; 1 training_set = pd.read_json('\Desktop\training_dataset.json')
      2 print(training_set.head())

~\Anaconda3\lib\site-packages\pandas\io\json\_json.py in 
read_json(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, 
keep_default_dates, numpy, precise_float, date_unit, encoding, lines, 
chunksize, compression)
    590         return json_reader
    591 
--&gt; 592     result = json_reader.read()
    593     if should_close:
    594         try:

~\Anaconda3\lib\site-packages\pandas\io\json\_json.py in read(self)
    715             obj = 
self._get_object_parser(self._combine_lines(data.split(""\n"")))
    716         else:
--&gt; 717             obj = self._get_object_parser(self.data)
    718         self.close()
    719         return obj

~\Anaconda3\lib\site-packages\pandas\io\json\_json.py in 
_get_object_parser(self, json)
    737         obj = None
    738         if typ == ""frame"":
 --&gt; 739             obj = FrameParser(json, **kwargs).parse()
    740 
    741         if typ == ""series"" or obj is None:

~\Anaconda3\lib\site-packages\pandas\io\json\_json.py in parse(self)
    847 
    848         else:
--&gt; 849             self._parse_no_numpy()
    850 
    851         if self.obj is None:

~\Anaconda3\lib\site-packages\pandas\io\json\_json.py in 
_parse_no_numpy(self)
   1091         if orient == ""columns"":
   1092             self.obj = DataFrame(
-&gt; 1093                 loads(json, precise_float=self.precise_float), 
dtype=None
   1094             )
   1095         elif orient == ""split"":

ValueError: Expected object or value
</code></pre>

<p>and I can't understand why. Can somebody please help me? Thank's in advance.</p>

<p>[EDIT] the file is a .jsonl file, but yet I don't know how to import the dataset because I cannot use <code>.read_json</code>
      ,I have tried this:</p>

<pre><code>openfile=open('Desktop\training_dataset.jsonl')
jsondata=json.load(openfile)
df=pd.DataFrame(jsondata)
openfile.close()
print(df)
</code></pre>

<p>but gives me the following error message:</p>

<pre><code>OSError                                   Traceback (most recent call last)
&lt;ipython-input-28-2422c1a9a77b&gt; in &lt;module&gt;
----&gt; 1 openfile=open('Desktop\training_dataset.jsonl')
      2 jsondata=json.load(openfile)
      3 df=pd.DataFrame(jsondata)
      4 openfile.close()
      5 print(df)

OSError: [Errno 22] Invalid argument: 'Desktop\training_dataset.jsonl'
</code></pre>

<p>[EDIT 2] by doing as suggested, so:</p>

<pre><code>with open(""\Desktop\training_dataset.jsonl"") as datafile:
data = json.load(datafile)
dataframe = pd.DataFrame(data)
</code></pre>

<p>I again obtain another error message, which is:</p>

<pre><code>OSError                                   Traceback (most recent call last)
&lt;ipython-input-47-1365f26e6db5&gt; in &lt;module&gt;
 ----&gt; 1 with open(""\Desktop\training_dataset.jsonl"") as datafile:
      2     data = json.load(datafile)
      3 dataframe = pd.DataFrame(data)

OSError: [Errno 22] Invalid argument: '\\Desktop\training_dataset.jsonl'
</code></pre>

<p>but I don' understand, because my dataset is placed in my desktop.</p>
",1,62135,,0,84229,84229,2019-10-27T17:35:38.507,2019-10-23T18:29:09.367,2,2,,
86143,1,2020-11-30T22:26:22.743,2,130,<machine-learning><python><deep-learning>,Causal inference VS Active learning?,"<p>Imagine we have some lists of features that are changing in time. Each row of the list corresponds to a sample (Change in space). I would like to know whether machine learning is able to determine the effect of each sample on another sample. For instance, the target value for the sample &quot;S&quot; is dependent on features of samples &quot;S-4&quot;,&quot;S-3&quot;,&quot;S-2&quot;,&quot;S-1&quot;,&quot;S+1&quot;,&quot;S+2&quot;,&quot;S+3&quot;. I have seen something like Active learning and Causal Inference but still not sure each of which would be useful for my aim.
To elaborate more, imagine we have the picture below:
<a href=""https://i.stack.imgur.com/NquFP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NquFP.png"" alt=""enter image description here"" /></a></p>
<p>the red line is a result for one year and the blue one is next year. we have these results in an appropriate amount so in this manner we do not have problem. for the target that has been shown by the red circle and other samples, we have different features. But I am looking for an algorithm to tell me whether group 1 is affecting my target in the red circle point or group 2. To this aim, it is good to use <code>Causal inference</code> or <code>Active Learning</code>?</p>
",1,86162,,2,108185,108185,2020-12-01T16:27:09.490,2020-12-01T11:51:43.957,1,3,,
31271,1,2018-05-06T07:45:12.430,0,7538,<python><pandas>,custom delimiter for dat file,"<p>I've a <code>dat</code> file in the following format which I'm trying to load using <code>pandas</code>.</p>

<pre><code>28::Persuasion (1995)::Romance
29::City of Lost Children, The (1995)::Adventure|Sci-Fi
30::Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)::Drama
31::Dangerous Minds (1995)::Drama
32::Twelve Monkeys (1995)::Drama|Sci-Fi
33::Wings of Courage (1995)::Adventure|Romance
34::Babe (1995)::Children's|Comedy|Drama
</code></pre>

<p>Code</p>

<pre><code>movies = pd.read_csv('movies.dat')
</code></pre>

<p>I'm getting this error </p>

<pre><code>ParserError: Error tokenizing data. C error: Expected 1 fields in line 11, saw 2
</code></pre>

<p>Line 11: </p>

<pre><code>11::American President, The (1995)::Comedy|Drama|Romance
</code></pre>

<p>I understand that it's because of the comma. One option I found is to skip these lines, which I don't want to. Is it possible to set newline as the delimiter here? Any help will be truly appreciated.</p>
",1,31272,,0,51670,51670,2020-05-11T17:49:53.727,2018-05-06T07:52:57.713,1,3,,
27563,1,2018-02-07T14:49:20.597,16,19617,<python><keras><rnn><lstm>,Multi-dimentional and multivariate Time-Series forecast (RNN/LSTM) Keras,"<p>I have been trying to understand how to represent and shape data to make a <strong>multidimentional</strong> and <strong>multivariate</strong> time series forecast using Keras (or TensorFlow) but I am still very unclear after reading many blog posts/tutorials/documentation about how to present the data in the correct shape (most examples being of slightly less </p>

<p><strong>My Dataset:</strong></p>

<ul>
<li>several cities</li>
<li>for which I have info about say temperature, car traffic, humidity</li>
<li>for say the last 2 years (one record for each day)</li>
</ul>

<p><strong>What I want to do:</strong>
I'd like to forecast for each city the temperatures I can expect for the next year using a possibly lagged version of temperature, car traffic and humidity (of course there would be several more features but this is just an example for thought).</p>

<p><strong>What I am confused about:</strong>
If I have 2 cities, for which I recorded 3 features for 365 days. How should I shape my input so that the model can output a forecast for 365 days for these two cities (i.e. 2 time series of temperatures for 365 days)?</p>

<p>Intuitively the tensor shape would be <code>(?, 365, 3)</code> for 365 days and 3 features. But I'm not sure what to stick into the first dimension and, most importantly, I would be surprised if it had to be for the number of cities. But at the same time, I have no idea how to specify into the model that it has to understand the dimensions properly. </p>

<p>Any pointers will be helpful. I'm pretty familiar with the rest of the problem (i.e. how you build a network in Keras etc since I have done this for other neural networks but more specifically how best to encode the sequence for the desired input.)</p>

<p><em>Oh and also</em>, I guess I could train and predict for each city independently, but I'm sure everyone will agree there are probably things to be learned that are not particular to any city but that can only be seen if considering several of them, hence why I think it is important to encode it in the model.</p>
",1,27572,,16,45892,,2020-05-09T17:10:47.860,,1,2,,
28069,1,2018-02-20T22:56:39.053,1,24,<python><pandas>,Get a portion of a long field in Pandas?,"<p>I have a Pandas dataframe that has some fields that contain very verbose text. I want to be able to iterate through the DF but only display a limited set of words. I have code similar to:</p>

<pre><code>for index, row in df.iterrows() :
    print(row['A'], row['B'])
</code></pre>

<p>How can I make sure that I only print the first 300 characters from 'A'?</p>
",1,28092,,1,23240,,2018-02-21T09:39:15.887,,1,2,2018-02-22T22:42:49.317,
29671,1,2018-03-28T21:17:59.260,3,46948,<python><pandas>,How to count occurrences of values within specific range by row,"<p>I have a data frame of 3000 rows x 101 columns like as follow:</p>

<pre><code>Time   id0  id1  id2     ………… id99

1      1.71 6.99 4.01    ………… 4.98

2      1.72 6.78 3.15    ………… 4.97

.

.

3000   0.36 0.23 0.14    ………… 0.28
</code></pre>

<p>Using Python, how could we add a column that counts for each row the number of values (in column <code>id0</code>, to <code>id99</code>) that are within a specific range?</p>
",1,29684,,3,49624,24000,2018-03-29T07:08:41.363,2018-03-29T05:38:08.747,2,3,,
22470,1,2017-08-22T09:31:03.423,24,38046,<python><logistic-regression><cost-function>,Python implementation of cost function in logistic regression: why dot multiplication in one expression but element-wise multiplication in another,"<p>I have a very basic question which relates to Python, numpy and multiplication of matrices in the setting of logistic regression.</p>
<p>First, let me apologise for not using math notation.</p>
<p>I am confused about the use of matrix dot multiplication versus element wise pultiplication. The cost function is given by:</p>
<p><span class=""math-container"">$J = - {1\over m} \sum_{i=1}^m y^{(i)}log(a^{(i)})+(1 - y^{(i)})log(1-a^{(i)})$</span></p>
<p>And in python I have written this as</p>
<pre><code>    cost = -1/m * np.sum(Y * np.log(A) + (1-Y) * (np.log(1-A)))
</code></pre>
<p>But for example this expression (the first one - the derivative of J with respect to w)</p>
<p><span class=""math-container"">${\partial J \over{\partial w}} = {1 \over{m}} X(A-Y)^T$</span></p>
<p><span class=""math-container"">${\partial J\over{\partial b}} = {1\over{m}} \sum \limits_{i = 1}^m (a^{(i)}-y^{(i)})$</span></p>
<p>is</p>
<pre><code>   dw = 1/m * np.dot(X, dz.T)
</code></pre>
<p>I don't understand why it is correct to use dot multiplication in the above, but use element wise multiplication in the cost function i.e why not:</p>
<pre><code>   cost = -1/m * np.sum(np.dot(Y,np.log(A)) + np.dot(1-Y, np.log(1-A)))
</code></pre>
<p>I fully get that this is not elaborately explained but I am guessing that the question is so simple that anyone with even basic logistic regression experience will understand my problem.</p>
",1,22472,,24,38306,29169,2021-06-06T18:46:11.230,2021-03-11T20:24:28.610,3,2,,
23211,1,2017-09-21T14:45:54.727,0,1066,<python>,What is the order of elements in an image in python?,"<p>I have a set of images which are loaded from an <code>h5</code> file. I checked their dimensions and I get <code>(209, 64, 64, 3)</code>.</p>

<pre><code>read = h5py.File('datasets/train_catvnoncat.h5', 'r')
read['train_set_x'].shape
</code></pre>

<blockquote>
  <p>(209, 64, 64, 3)</p>
</blockquote>

<p>it means that there are 209 images but the point that I cannot understand is that, what is (64, 64, 3)? <br />
I have used the following code for plotting: <br /></p>

<pre><code>import matplotlib.pyplot as plt

plt.imshow(read['train_set_x'][1])
plt.show()
</code></pre>

<p>and I get a colored image which is 64 by 64. before this, I thought for (., ., .) shapes, the second number specifies the number of lines and the third one specifies the number of rows. also the first one specifies the number of the mentioned (row and column) arrays.<br />
My question is that in <code>numpy</code> if you have a three dimensional array, for accessing rows and columns you have to change the second and third entries in the indexing operator; Why this is different in images and rows and columns are arranged differently in images. Shouldn't it be (3, 64, 64)?</p>
",1,23218,,0,28175,28175,2017-09-21T17:35:33.577,2017-09-21T17:20:00.677,1,4,,
21952,1,2017-08-04T05:40:43.620,3,1054,<python><pandas>,Need rules of thumb for out of core larger than ram dataset on a laptop,"<p>totally new to larger than ram datasets but I have csv files that are about 100 gb each with around 300 million rows each  (just two of them). </p>

<p>What I am looking for is something like: don't go analyzing more than 1 terabyte of data on a laptop. Or don't analyze data that is more than 10x your ram or the wait times will prove frustrating. This is what I mean by rules of thumb. </p>

<p>I have a mac laptop with an i5, 8gb ram, ssd is it reasonable to process this data (100gb per file and I have 2 files) with either dask or blaze in python?</p>

<p>I have tried and could read in the csv but when doing simple trials like dropping one column or finding the length of the data frame it takes at least an hour For the drop (I gave up waiting) and half an hour for the length() (that did finish). Way too slow to be productive. I changed the data format to parquet and amazingly the data is down to just 10 gb. This is the only way they the length() command ever even finished. </p>

<p>So my question is: are these response times normal experience in general given my hardware and csv size? Are my expectations for what dask can do way too high? Any rough guidelines on how to troubleshoot or is this clearly underpowered hardware？</p>
",1,22739,,3,32637,32637,2017-08-31T10:01:17.463,2017-08-04T15:21:18.043,1,8,,
38080,1,2018-09-11T06:19:43.463,17,12080,<machine-learning><python><data><labels>,Interactive labeling/annotating of time series data,"<p>I have a data set of time series data. I'm looking for an annotation (or labeling) tool to visualize it and to be able to interactively add labels on it, in order to get annotated data that I can use for supervised ML.</p>

<p>E.g. the input data is a csv-file and the output is another csv-file of the format timestamp,label.</p>

<p>Therefore I need something like this:</p>

<ol>
<li>to visualize data </li>
<li>to select a specific area</li>
<li>output the labels with timestamps</li>
</ol>

<p>As an example:</p>

<p><a href=""https://i.stack.imgur.com/QWTEz.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/QWTEz.png"" alt=""An example""></a></p>

<p>Building such a tool in python will not take too long, however I was just wondering how other people solve this problem and maybe there are already nice OS tools for doing this. Thank you!</p>
",1,61732,,17,58905,,2021-03-24T22:42:29.730,,7,4,,
9208,1,2015-12-04T14:24:09.310,8,871,<machine-learning><python><neural-network>,Pylearn2 vs TensorFlow,"<p>I am about to dive into a long NN research project and wanted a push in the direction of Pylearn2 or TensorFlow?  As of Dec 2015 has the community started to lean one direction or another?</p>

<p>This <a href=""http://deeplearning4j.org/compare-dl4j-torch7-pylearn.html"">link</a> has given me concern about getting tied to TenserFlow.</p>
",1,9239,,8,14535,11097,2015-12-07T01:03:55.753,2015-12-04T15:42:32.287,2,1,,
21782,1,2017-07-28T14:36:29.707,2,3621,<machine-learning><python><scikit-learn><pandas>,Pandas index error,"<p>I am trying to use <code>train_test_split</code> to split my data. However, I am getting an index error. I pasted part of the error message below. I am using Python 3.5 version and <code>sklearn</code> 0.18.1. The code worked with my previous dataset that was different. Features here are in Pandas <code>DataFrame</code> and labels are in Pandas
<code>Series</code>. </p>

<pre><code>from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=1)

KeyError                                  
Traceback (most recent call last)
/apps/anaconda/anaconda-3.5/lib/python3.5/site-
    packages/pandas/indexes/base.py in get_loc(self, key, method, tolerance)
   2133             try:
-&gt; 2134                 return self._engine.get_loc(key)
   2135             except KeyError:&lt;br&gt;&lt;br&gt;
pandas/index.pyx in pandas.index.IndexEngine.get_loc (pandas/index.c:4443)()&lt;br&gt;&lt;br&gt;
pandas/index.pyx in pandas.index.IndexEngine.get_loc (pandas/index.c:4289)()&lt;br&gt;&lt;br&gt;
pandas/src/hashtable_class_helper.pxi in pandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13733)()&lt;br&gt;&lt;br&gt;
pandas/src/hashtable_class_helper.pxi in pandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13687)()&lt;br&gt;&lt;br&gt;
KeyError: 0
</code></pre>
",1,21785,,2,28584,381,2017-07-28T21:01:55.630,2017-07-28T16:13:59.290,1,1,,
53585,1,2019-06-11T17:40:54.760,3,156,<python><clustering><graphs><community>,How can I get the diameter of each community,"<p>I am trying to calculate the diameter of each community in my dataset, <em>Zachary's karate club</em> using Jupyter. I created a loop to iterate through, but it gives me the diameter of the whole network rather than of each community.</p>

<pre><code>import pandas as pd 
data = pd.read_csv('zachary.txt',sep ="" "", header = None)
data_values = data.values
g = Graph()
new_data = data_values.tolist()
data_graph = g.Adjacency(new_data, mode = 'undirected')
s = data_graph.community_infomap()
print(s)
s_List = list(s)
print(s_List)
for ic in s_List:
    y = data_graph.diameter(ic)
    print(y)
</code></pre>

<p>I expect the output to be like ""<span class=""math-container"">$1,2,2$</span>"" or ""<span class=""math-container"">$1,3,1$</span>"" but the actual output is ""<span class=""math-container"">$5,5,5$</span>"", which is the diameter of the whole community.</p>
",1,53593,,3,75831,29575,2019-06-11T21:17:11.960,2019-06-11T21:17:11.960,1,2,,
5601,1,2015-04-24T07:50:31.950,1,1343,<classification><python><svm>,How to classify whether text answer is relevant to an initial text question,"<p>I have a text classification problem in which i need to classify an answer to a message as either relevant or not. </p>

<p>In the first phase of my calculations, I have already used a SVM to determine if the original message was relevant or not, deciding whether a message contains a hint or question if somebody's twitter account has been hacked.</p>

<pre><code>example:
""Hey @foobar, have you been hacked?""   &lt;-- relevant
""My bank account has just been hacked"" &lt;-- not relevant
</code></pre>

<p>However, when I want to classify whether the answer is relevant, I would want to have both the original message and the answer as input, right? An answer is relevant in my case if it, in any way, responds to the original message. Is this approach possible using a SVM or any other machine learning tool? I'm using python with the scikit-learn library.</p>

<pre><code>example:
""Hey @foobar, have you been hacked?""
""@barfoo it seems so, thx for suggesting"" &lt;-- relevant

""Hey @foobar, have you been hacked?""
""Lose 20 pounds quickly! http://blabla.com"" &lt;-- not relevant
</code></pre>

<p>I'm not very experienced in this field, so any input would be very appreciated.</p>
",1,5603,,1,9281,836,2015-04-25T19:34:52.587,2015-04-25T19:34:52.587,1,1,,
64427,1,2019-12-08T15:49:45.023,3,1041,<python><classification><svm><nlp>,NLP and one-class classifier building,"<p>I have a big dataset containing almost 0.5 billions of tweets. I'm doing some research about how firms are engaged in activism and so far, I have labelled tweets which can be clustered in an activism category according to the presence of certain hashtags within the tweets.</p>

<p>Now, let's suppose firms are tweeting about an activism topic without inserting any hashtag in the tweet. My code won't categorized it and my idea was to run a SVM classifier with only one class.</p>

<p>This lead to the following question:</p>

<ul>
<li>Is this solution data-scientifically feasible?</li>
<li>Does exists any other one-class classifier? </li>
<li>(Most important of all) Are there any other ways to find if a tweet is similar to the ensable of tweets containing activism hashtags?</li>
</ul>
",1,64440,,3,86599,,2019-12-09T01:36:53.253,,3,4,,
92636,1,2021-04-06T13:18:33.770,1,38,<python><clustering><visualization><plotly>,Incorrect visualisation using Plotly,"<pre><code>kmeans = KMeans(n_clusters=4)

model = kmeans.fit(europe_july)
pred = model.labels_
europe_july['cluster'] = pred

pca = PCA(n_components=2)
pca_model = pca.fit_transform(europe_july)
data_transform = pd.DataFrame(data = pca_model, columns = ['PCA1', 'PCA2'])
data_transform['Cluster'] = pred

plt.figure(figsize=(8,8))
g = sns.scatterplot(data=data_transform, x='PCA1', y='PCA2',\
                    palette=sns.color_palette()[:4], hue='Cluster')
title = plt.title('World countries clusters with PCA')
</code></pre>
<p><a href=""https://i.stack.imgur.com/8ljXn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8ljXn.png"" alt=""PCA"" /></a></p>
<p>But when I run this code it does not seem to take into account this model.</p>
<pre><code>europe_july['country'] = countries
europe_july['iso_alpha'] = iso_alpha


fig = px.choropleth(data_frame = europe_july,
                    locations= &quot;iso_alpha&quot;,
                    scope= 'world',
                    title='2020-11-07 (World)',
                    color= &quot;cluster&quot;,
                    hover_name= &quot;country&quot;,
                    color_continuous_scale= 'earth',
                    )

fig.show()
</code></pre>
<p>Since this is the output that I get, as you can see there is clearly a cluster with only three countries, when there is no such cluster predicted by the model.</p>
<p>This is the output of the predictions for clusters and it matches the visualizations by PCA:</p>
<pre><code>array([2, 3, 1, 0, 2, 0, 0, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 3, 1, 2, 0,
       1, 1, 0, 1, 2, 3, 0, 2, 3, 2, 2, 1, 2, 3, 2, 0, 2, 2, 3, 3, 1, 2,
       2, 1, 2, 3, 1, 3, 3, 3, 2, 3, 2, 0, 1, 1, 1, 1, 2, 2, 3, 2, 0, 0,
       2, 3, 3, 0, 2, 2, 3, 3, 2, 0, 3, 0, 2, 3, 1, 0, 2, 2, 1, 2, 1, 3,
       3, 3, 1, 1, 3, 1, 3, 0, 3, 3, 1, 3, 0, 2, 1, 2, 0, 3, 1, 2, 3, 3,
       2, 2, 2, 0, 3, 3, 3, 2, 2, 3, 1, 2, 3, 2, 3, 1, 1, 0, 1, 3, 0, 2,
       2, 1, 2, 1, 3, 0, 3, 0, 2, 2, 0, 3, 1, 1, 2, 3, 2, 1, 3, 1, 3, 3,
       3, 3, 3, 3, 2, 0, 1, 0, 0, 2, 3, 2, 1, 3, 2, 3, 0, 3, 3, 2, 1, 3,
       2, 3, 3, 2, 1, 2, 3, 3, 2, 3, 1, 2, 1, 2, 2, 1, 1, 3, 0, 2, 3, 3,
       3, 3, 3, 3, 2, 0, 2, 1, 0, 2, 2, 2, 1, 0], dtype=int32)
</code></pre>
<p><a href=""https://i.stack.imgur.com/Tp7fR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Tp7fR.png"" alt=""vis"" /></a></p>
<p>Could someone please guide on why my visualisation is wrong?</p>
",1,92790,,1,85744,92050,2021-04-09T08:00:26.260,2021-04-06T18:35:47.237,1,4,,
42061,1,2018-12-03T16:23:37.233,2,2609,<machine-learning><python><scikit-learn><random-forest>,learning curve Sklearn,"<p>I was trying Random Forest Algorithm on <a href=""https://www.kaggle.com/c/boston-housing"" rel=""nofollow noreferrer"">Boston</a> dataset to predict the house prices <code>medv</code> with the help of sklearn's <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"" rel=""nofollow noreferrer"">RandomForestRegressor</a>.</p>

<p>Just to evaluate how good is the model performing I tried sklearn's <a href=""https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html"" rel=""nofollow noreferrer"">learning curve</a> with below code</p>

<pre><code> train_sizes = [1, 25, 50, 100, 200, 390] # 390 is 80% of shape(X)

    from sklearn.model_selection import learning_curve
    def learning_curves(estimator, X, y, train_sizes, cv):
        train_sizes, train_scores, validation_scores = learning_curve(
                                                     estimator, X, y, train_sizes = train_sizes,
                                                     cv = cv, scoring = 'neg_mean_squared_error')
        #print('Training scores:\n\n', train_scores)
        #print('\n', '-' * 70) # separator to make the output easy to read
        #print('\nValidation scores:\n\n', validation_scores)
        train_scores_mean = -train_scores.mean(axis = 1)
        print(train_scores_mean)
        validation_scores_mean = -validation_scores.mean(axis = 1)
        print(validation_scores_mean)

        plt.plot(train_sizes, train_scores_mean, label = 'Training error')
        plt.plot(train_sizes, validation_scores_mean, label = 'Validation error')

        plt.ylabel('MSE', fontsize = 14)
        plt.xlabel('Training set size', fontsize = 14)
        title = 'Learning curves for a ' + str(estimator).split('(')[0] + ' model'
        plt.title(title, fontsize = 18, y = 1.03)
        plt.legend()
        plt.ylim(0,40)
</code></pre>

<p>If you notice I have passed <code>X, y</code> and not <code>X_train, y_train</code> to <code>learning_curve</code>.</p>

<p>I am not understanding should I pass <code>X, y</code> or only the training subset <code>X_train, y_train</code> to <code>learning_curve</code>.</p>

<p><strong>Update 1</strong></p>

<p><code>Dimensions of my Train/Test split (75%:Train and 25%:Test)
        X.shape: (489, 11)
        X_train.shape: (366, 11)
        X_test.shape: (123, 11)</code>
I had few additional questions regarding the working of <code>learning_curve</code></p>

<ol>
<li><p>Does the size of test data set varies according to the size of train dataset as mentioned in list <code>train_sizes</code> or it is always fixed (which would be 25% in my case according to train/test split which is 123 samples) for example</p>

<ul>
<li>When <code>train dataset size = 1</code> the will the test data size be 488 or will it be 123(the size of X_test)</li>
<li>When <code>train dataset size = 25</code> the will the test data size be 464 or will it be 123(the size of X_test)</li>
<li>When <code>train dataset size = 50</code> the will the test data size be 439 or will it be 123(the size of X_test)</li>
</ul></li>
</ol>

<p><strong>Update 2</strong></p>

<p>In the <a href=""https://www.dataquest.io/blog/learning-curves-machine-learning/"" rel=""nofollow noreferrer"">blog</a> the dataset has 9568 observations and the blogger passes entire dataset <code>X</code> to <code>learning_curve</code>.</p>

<p><code>train_sizes = [1, 100, 500, 2000, 5000, 7654]</code></p>

<p>In first iteration when <code>train_size</code> is 1 then the <code>test_size</code> should be <code>9567</code> but why he say that </p>

<blockquote>
  <p>But when tested on the validation set (which has 1914 instances), the MSE rockets up to roughly 423.4. </p>
</blockquote>

<p>Shouldnt the <code>test_size</code> be 9567 instead of 1914 for first iteration</p>

<p>In second iteration when the <code>train_size</code> is 100 then the <code>test_size</code> should be <code>9468</code></p>

<p>What I meant to say is the <code>test_size</code> will be variable according to <code>train_size</code> correct me if I am wrong</p>
",1,42077,,2,63655,63655,2018-12-04T16:49:53.557,2018-12-04T05:46:24.533,1,1,,
32405,1,2018-05-30T15:54:05.363,2,150,<python><numpy>,Dimensions For Matrix Multiplication,"<p>Can anyone explain why the following code produces <em>input_t</em> with a shape of (32,) instead of (,32), given the fact that <em>inputs</em> has a shape (100, 32)? Shouldn't input_t produce a vector with 32 attributes/columns?</p>

<pre><code>import numpy as np

timesteps = 100
input_features = 32
output_features = 64

inputs = np.random.random((timesteps, input_features))

state_t = np.zeros((output_features,))

W = np.random.random((output_features, input_features))
U = np.random.random((output_features, output_features))
b = np.random.random((output_features,))

successive_outputs = [ ]

for input_t in inputs:
    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)
    successive_outputs.append(output_t)
    state_t = output_t 
</code></pre>
",1,32406,,2,52713,,2018-05-30T15:59:02.223,,1,2,,
87626,1,2021-01-07T10:15:46.827,1,229,<machine-learning><python><classification><xgboost><features>,Xgboost : A variable specific Feature importance,"<p>I have a data set something like this:</p>
<pre><code>data = [['Alex',10,13,1,0],['Bob',11,14,12,0],['Clarke',13,15,13,1],['bob',12,15,1,1]]
df = pd.DataFrame(data,columns = [&quot;dealer&quot;,&quot;x&quot;,&quot;y&quot;,&quot;z&quot;,&quot;loss&quot;])
</code></pre>
<p>I am trying to predict binary column loss, I have done this <strong>xgboost</strong> model. I got Overall feature importance. Now I need t<strong>op 5 most important features dealer wise</strong>.</p>
<p>How to do that?</p>
<p>I have tried to use <strong>lime package</strong> but it is only working for Random forest.</p>
<p>If I get Feature importance for <strong>each observation(row)</strong> then also I can compute the feature importance dealer wise.</p>
<p>kindly help</p>
<p>Desired Output :
<a href=""https://i.stack.imgur.com/3TQlJ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/3TQlJ.png"" alt=""enter image description here"" /></a></p>
",1,87640,,1,98753,98753,2021-01-08T22:38:08.233,2021-01-07T12:15:47.297,2,5,,
42773,1,2018-12-17T18:02:47.983,3,907,<python><neural-network><deep-learning><keras><tensorflow>,How do I build a permutation invariance neural network in keras?,"<p>My question is about the structure of the network required to solve my problem with fewer data.</p>

<p>I have a sensor device that simply reports the color of the thing it's seeing in front of it. One sensor reports me 4 numbers: Red, Green, Blue, and Alpha. 
The intensity of the color changes depends on the distance and the thing it's seeing.
I have 6 such sensors attached on each side of a small cube. The cube can be moved and rotated using the hand.</p>

<p>I want to predict the position of the cube in space in real-time.</p>

<p>My problem:</p>

<p>Input: 6 identical sensors, each giving 4 numbers. Total=6*4=24 numbers.</p>

<p>Output: 3 numbers, X, Y, Z, (Position of the cube)</p>

<p>I have my data ready with label XYZ.</p>

<p>Now, train a simple Multi-layer perceptron which takes 24 numbers and output 3 numbers.
This is working quite fine but it needs hell lots of data in a cubic meter space to predict accurately.</p>

<p>The problem is about the rotation. I need to rotate and cover 360 degrees for every location for it to predict well.</p>

<p>But I know for the fact that each sensor is identical so I want to share the weight of each sensor. I know that when you rotate the cube 90 degrees, it should not affect the output position at all. So this should mean the order of the sensors is not important. This means I should somehow use <code>add</code> or <code>average</code> to merge my sensors' layer. If I use <code>concatenate</code> it will preserve the order which make the output position changes.</p>

<p>The way I'm doing it is that I feed 4 numbers into a <strong>sensor model</strong> that are shared among all sensors, get the encoding, add them up, then connect it to Dense layers. Following is the model prototype:</p>

<pre><code>from keras.layers import Input, Dense
from keras.models import Model, Sequential

sensor1 = Input(shape=(4,))
sensor2 = Input(shape=(4,))
sensor3 = Input(shape=(4,))
sensor4 = Input(shape=(4,))
sensor5 = Input(shape=(4,))
sensor6 = Input(shape=(4,))
sensor_model = Sequential([
    Dense(64, activation='relu'),
    Dense(64, activation='relu'),
])
sensor1_encoding = sensor_model(sensor1)
sensor2_encoding = sensor_model(sensor2)
sensor3_encoding = sensor_model(sensor3)
sensor4_encoding = sensor_model(sensor4)
sensor5_encoding = sensor_model(sensor5)
sensor6_encoding = sensor_model(sensor6)
sensor_encoding = average([
    sensor1_encoding,
    sensor2_encoding,
    sensor3_encoding,
    sensor4_encoding,
    sensor5_encoding,
    sensor6_encoding,
])
h = sensor_encoding
h = Dense(128, activation='relu')(h)
h = Dense(128, activation='relu')(h)
h = Dense(3, activation='linear')
model = Model(inputs=[sensor1, sensor2, sensor3, sensor4, sensor5, sensor6], outputs=[h])
</code></pre>

<p>Right now, when I change the <code>average</code> function to <code>concatenate</code>, the model loss is lower on both training and validation set which contradicts with my intuition. What is wrong with my thinking?
What do you think? How do I adjust this model in order for it to predict the same position if I rotate 90 degrees while also not suffering from 45 degrees rotation. And also make it in such a way that it does not remove the useful relationship between the inputs.</p>
",1,42844,,3,37814,37814,2019-01-30T09:55:54.560,2018-12-18T07:42:52.300,2,7,,
102278,1,2021-09-21T09:46:57.357,1,62,<python><dataset><dataframe>,convert a column into rows,"<p>I used a webscraper and i got data only in one column like<br>
A<br>B<br>C<br>1<br>2<br>3<br>4<br>5<br>6<br>
I need the data in this form<br>
A  B  C<br>1  2  3<br>4  5  6<br>
Is there any way?</p>
",1,102292,,1,125523,,2021-09-21T15:20:42.023,,1,1,2021-09-21T16:58:10.990,
41531,1,2018-11-22T02:57:16.517,0,884,<machine-learning><python><classification><scikit-learn><logistic-regression>,Difference between sklearn’s “log_loss” and “LogisticRegression”?,"<p>I am a newbie currently learning data science from scratch and I have a rather stupid question to ask. I’m currently learning about binary classification, and I understand that the logistic function is a useful tool for this. I looked up the documentation and noticed that there are two logistic related functions I can import, i.e. <code>sklearn.metric.log_loss</code> and <code>sklearn.linear_model.LogisticRegression</code>. When and where should I use them, and what’s the difference?</p>

<p>On a broader note, what’s the difference between a metric and a model, and why is the log loss function a metric? Apologies if this question sounds completely nonsensical, but this is a genuine source of confusion for me!</p>
",1,41534,,0,63027,,2018-11-22T10:05:59.150,,1,1,,
15006,1,2016-11-08T19:00:48.267,11,22229,<python><pandas><indexing>,Counting indexes in pandas,"<p>I feel like this is a rudimentary question but I'm very new to this and just haven't been able to crack it / find the answer.</p>

<p>Ultimately what I'm trying to do here is to count unique values on a certain column and then determine which of those unique values have more than one unique value in a matching column.</p>

<p>So for this data, what I am trying to determine is ""who"" has ""more than one receipt"" for all purchases, then determine the same information based on each product category.</p>

<h3>My approach so far:</h3>

<p>We have a dataset like this:</p>

<pre><code>receipt,name,etc,category
1,george,xxx,fish
1,george,xxx,cat
2,george,xxx,fish
3,bill,xxx,fish
3,bill,xxx,dog
4,jill,xxx,cat
5,bill,xxx,cat
5,bill,xxx,cat
5,bill,xxx,dog
6,george,xxx,fish
</code></pre>

<p>So then I can do this:</p>

<p><code>df.set_index(['name','receipt'])</code></p>

<p>And get the more interesting</p>

<pre><code>                etc category
name   receipt
george 1        xxx     fish
       1        xxx      cat
       2        xxx     fish
bill   3        xxx     fish
       3        xxx      dog
jill   4        xxx      cat
bill   5        xxx      cat
       5        xxx      cat
       5        xxx      dog
george 6        xxx     fish
</code></pre>

<p>At this point it feels to me like the data is easy to work with, but I haven't figured it out. </p>

<p>One thing that is interesting to me is that if I sort the data by name before indexing it, the data displays grouped by name. In both cases the index is the same, so I don't know how to play with the representation of the data after indexing.</p>

<p>It is easy to find the data by category using</p>

<pre><code>&gt;&gt;&gt; orders.loc[orders['category'] == 'fish']
                etc category
name   receipt
george 1        xxx     fish
       2        xxx     fish
bill   3        xxx     fish
george 6        xxx     fish
</code></pre>

<p>But what I can't figure out is how to tell pandas ""Find me the list of names that have more than one receipt"".</p>

<p>Smaller questions:</p>

<ul>
<li>What is the ""pandas way"" to get the length of the names part of the index? I'm supposing I could just turn the <code>name</code> column into a set and get the length of that. But I'm curious about indexes.</li>
</ul>

<h3>Edit / Update</h3>

<p>Thanks for those answers! Here is clarification on what I am looking for:</p>

<p>I'm trying to find ""repeat customers"": people with more than one receipt.</p>

<p>So my set of all customers would be:</p>

<pre><code>names: ['george','bill','jill'], ratio: 1.0
</code></pre>

<p>My repeat customers:</p>

<pre><code>names: ['george','bill'], ratio 0.66
</code></pre>

<p>All 'fish' customers:</p>

<pre><code>names: ['george','bill'], ratio: 0.666
</code></pre>

<p>My repeat 'fish' customers:</p>

<pre><code>names: ['george'], ratio: 0.333
</code></pre>

<p>I think the examples given look helpful, but feel free to add anything.</p>
",1,15007,,11,25970,25970,2016-11-09T00:23:14.450,2016-11-09T00:23:14.450,2,1,,
31352,1,2018-05-08T00:20:45.883,11,7794,<python><scipy>,Understanding scipy sparse matrix types,"<p>I am trying to select the best scipy sparse matrix type to use in my algorithm. In that, I should initialize data in a vij way, then I should use it to perform matrix vector multiplication. Eventually I have to add rows and cols. Trying to select the best for my problem, I want to understand which are the best cases to use each of this types: lil_matrix, coo_matrix, csr_matrix, csc_matrix, dok_matrix. Can someone explain me? Its not necessary to show examples of all the types in the same answer. </p>
",1,31356,,11,49914,,2018-09-17T05:06:49.840,,2,1,,
71846,1,2020-04-06T13:55:46.980,0,30,<python><keras><tensorflow><cnn>,value of fit_generator parameters,"<p>I am doing simple CNN based binary image classification on classifying types of waste as organic and recyclable using image augmentation. How ever I have a doubt.</p>

<p><a href=""https://i.stack.imgur.com/bMsx4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bMsx4.png"" alt=""First part of the code""></a></p>

<p><a href=""https://i.stack.imgur.com/fzMI9.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/fzMI9.png"" alt=""Second part of the code""></a></p>

<p><a href=""https://i.stack.imgur.com/xBQrZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xBQrZ.png"" alt=""Results""></a></p>

<p>In the third figure i have set the steps_per_epoch = 22564/32= 705 where 32 is batch size and validation_steps as 2513/32 = 79 as per documentation does that mean out of 22564 training and 2513 validation samples 705 and 79 are trained and validated ?</p>
",1,72220,,0,70662,,2020-04-13T04:12:10.997,,1,2,,
85053,1,2020-11-07T07:24:40.423,0,110,<machine-learning><python><deep-learning>,How to create a model to suggest similar words in realtime?,"<p>I have a huge database of job titles, I want to build a system where if you enter something like &quot;jav &quot; then it should suggest next some similar job titles like (java developer, java engineer) etc..</p>
<p>How should one approach this problem? How can build something like this, the latency is biggest concern because it has to be real time. We have to integrate this in UI at the end.</p>
<p>Any suggestions how to proceed further?</p>
",1,85054,,0,61261,,2020-11-07T08:29:55.107,,1,2,,
66577,1,2020-01-16T12:35:11.563,8,4307,<machine-learning><python><deep-learning><keras><object-detection>,How can we extract fields from images?,"<p>I am making an document parser which extracts data fields from the documents and store them in a structured way. Each field in my dataset is horizontal which is easy to extract.</p>

<p><a href=""https://i.stack.imgur.com/VHfI2.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/VHfI2.jpg"" alt=""enter image description here""></a></p>

<p>But the model fails on following type of example -</p>

<p><a href=""https://i.stack.imgur.com/wiH4U.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/wiH4U.png"" alt=""enter image description here""></a></p>

<p>Is there any way to extract invoice number and date from such images.</p>
",1,66908,,8,83100,83100,2020-08-11T08:18:48.277,2020-01-20T06:04:07.583,5,4,,
62430,1,2019-10-30T16:50:44.523,3,4198,<python><pandas><data>,pd.qcut bins error!,"<p>Hi Data Science community! </p>

<p>I'm working on some RFM analysis, but while setting up the bins, I'm getting an error.  Here's my code and below the exact error. </p>

<pre><code>import modules
import pandas as pd # for dataframes
import matplotlib.pyplot as plt # for plotting graphs
import seaborn as sns # for plotting graphs
import datetime as dt

#Load the file
data = pd.read_excel('Orders.xlsx')
#EDA (Exploratory Data Analysis)
data.head()
data.info()
data.describe()

#Removing null values
data= data[pd.notnull(data['CustomerID'])]

#Delete duplicate records
filtered_data=data[['Country','CustomerID','InvoiceNo','Description']].drop_duplicates()
filtered_data.info()

#Top ten country's customer
filtered_data.Country.value_counts()[:10].plot(kind='bar')

#Filter US customers only
us_data=data[data.Country=='US']
us_data.info()
us_data.describe()

#Filter out unit price &lt;= 0
us_data = us_data[(us_data['UnitPrice']&gt;0)]
us_data.info()
us_data.describe()

#Filter to only required columns for RFM Analysis
us_data=us_data[['CustomerID','InvoiceDate','InvoiceNo','Quantity','UnitPrice']]
#Create TotalPrice column
us_data['TotalPrice'] = us_data['Quantity'] * us_data['UnitPrice']
#Find the oldest and newest dates
us_data['InvoiceDate'].min(),us_data['InvoiceDate'].max()
#Define the present date
PRESENT = dt.datetime(2019,10,1)
#Covert InvoiceDate to to_datetime
us_data['InvoiceDate'] = pd.to_datetime(us_data['InvoiceDate'])
us_data.head()

#RFM Analysis
rfm= us_data.groupby('CustomerID').agg({'InvoiceDate': lambda date: (PRESENT - date.max()).days,
                                        'InvoiceNo': lambda num: len(num),
                                        'TotalPrice': lambda price: price.sum()})
rfm.columns
# Change the name of the columns
rfm.columns=['recency','frequency','monetary']
rfm['recency'] = rfm['recency'].astype(int)
rfm.head()

#Computing Quantile of RFM values
rfm['r_quartile'] = pd.qcut(rfm['recency'], 4, ['1','2','3','4'])
rfm['f_quartile'] = pd.qcut(rfm['frequency'], 4, ['1','2','3','4'])
rfm['m_quartile'] = pd.qcut(rfm['monetary'], 4, ['1','2','3','4'])
rfm.head()
</code></pre>

<p>And here's the traceback:</p>

<pre><code>Traceback (most recent call last):

  File ""&lt;ipython-input-57-e15dc8d2e29f&gt;"", line 2, in &lt;module&gt;
    rfm['f_quartile'] = pd.qcut(rfm['frequency'], 4, ['1','2','3','4'])

  File ""/Users/omarmartinez/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 313, in qcut
    dtype=dtype, duplicates=duplicates)

  File ""/Users/omarmartinez/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 339, in _bins_to_cuts
    ""the 'duplicates' kwarg"".format(bins=bins))

ValueError: Bin edges must be unique: array([ 1.,  1.,  1.,  1., 37.]).
You can drop duplicate edges by setting the 'duplicates' kwarg
</code></pre>

<p>I tried including the duplicates='drop' argument, like this:</p>

<pre><code>#Computing Quantile of RFM values
rfm['r_quartile'] = pd.qcut(rfm['recency'], 4, ['1','2','3','4'], duplicates='drop')
rfm['f_quartile'] = pd.qcut(rfm['frequency'], 4, ['1','2','3','4'],duplicates='drop')
rfm['m_quartile'] = pd.qcut(rfm['monetary'], 4, ['1','2','3','4'],duplicates='drop')
rfm.head()
</code></pre>

<p>But then I get another traceback:</p>

<pre><code>Traceback (most recent call last):

  File ""&lt;ipython-input-59-bf551522a462&gt;"", line 2, in &lt;module&gt;
    rfm['f_quartile'] = pd.qcut(rfm['frequency'], 4, ['1','2','3','4'],duplicates='drop')

  File ""/Users/omarmartinez/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 313, in qcut
    dtype=dtype, duplicates=duplicates)

  File ""/Users/omarmartinez/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 359, in _bins_to_cuts
    raise ValueError('Bin labels must be one fewer than '

ValueError: Bin labels must be one fewer than the number of bin edges
</code></pre>

<p>I'm a little bit lost here, so any help on this will be highly appreciated. </p>

<p>Thank you in advance for the support!</p>
",1,64064,,3,80416,,2020-03-25T16:14:17.657,,1,2,,
22018,1,2017-08-07T01:49:36.047,1,287,<python><predictive-modeling>,Python model persistence without pickling,"<p>Are there any Python machine learning libraries, which allow model persistence without pickling?</p>

<p>More specifically, I want to avoid problems (and time sinks) that could arise upon sharing models with others. (In my case: academic collaborators in non-computational research fields.)</p>
",1,75916,,1,23437,23437,2020-06-12T20:20:44.120,2017-08-07T05:48:32.070,1,2,,
33885,1,2018-07-02T13:19:05.200,2,1455,<python><xgboost>,eta and learning_rate different in xgboost,"<p>I am creating a classification model using xgboost in python. I am using different <strong>eta</strong> values to check its effect on the model. My code is-</p>

<pre><code>for eta in np.arange(0.2, 0.51, 0.03):
    xgb_model = xgboost.XGBClassifier(objective = 'multi:softmax', num_class = 5, eta = eta)
    xgb_model.fit(x_train, y_train)
    xgb_out = xgb_model.predict(x_test)
    print(""For eta %f, accuracy is %2.3f"" %(eta,metrics.accuracy_score(y_test, xgb_out)*100))
</code></pre>

<p>I expected different accuracies for some eta values, but to my surprise I got same accuracy for each eta. When I printed the model, I got this-</p>

<pre><code>&gt;&gt;&gt; print(xgb_model)
XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, eta=0.5, gamma=0, learning_rate=0.1,
       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,
       n_estimators=100, n_jobs=1, nthread=None, num_class=5,
       objective='multi:softprob', random_state=0, reg_alpha=0,
       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,
       subsample=1)
</code></pre>

<p>Here you can see <code>eta = 0.5</code>, but <code>learning_rate = 0.1</code>. While in <a href=""http://xgboost.readthedocs.io/en/latest/parameter.html"" rel=""nofollow noreferrer"">xgboost docs</a>, learning_rate is an alias for eta. So how is this possible that both have different values?</p>
",1,50935,,2,44139,,2019-05-25T19:02:55.327,,1,2,,
32455,1,2018-05-31T14:00:36.890,7,19217,<python><keras><tensorflow>,Which convolution should I use? Conv2d or Conv1d,"<p>I've dataset which contains dlib landmark points of the faces. I'm using keras to train a model.</p>
<p>The dataset shape is <code>(length_of_dataset,68,2)</code>. I know that I've two options.</p>
<ul>
<li>The first is using <code>conv1d</code> with <code>input_shape = (68,2)</code>.</li>
<li>The second is using <code>conv2d</code> with <code>input_shape = (1,68,2)</code>.</li>
</ul>
<p>My question is which one is better? And why?</p>
",1,32462,,7,52910,98307,2020-08-02T12:23:45.540,2020-08-02T11:20:10.363,2,1,,
64821,1,2019-12-14T08:26:30.063,0,1131,<python><statistics><numpy>,Trouble in calculating the covariance matrix,"<p>I'm trying to calculate the covariance matrix for a dummy dataset using the following formula, but it's not matching with the actual result.</p>

<p><a href=""https://i.stack.imgur.com/hBQlM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hBQlM.png"" alt=""enter image description here""></a></p>

<p>Let's say the dummy dataset contains three features, <em>#rooms</em>, <em>sqft</em> and <em>#crimes</em>. Each column is a feature vector, and we have 5 data points. I'm creating this dataset using the following code:</p>

<pre><code>matrix = np.array([[2., 3., 5., 1., 4.], 
                   [500., 700., 1800., 300., 1200.], 
                   [2., 1., 2., 3., 2.]])
</code></pre>

<p>Let's normalize the data, so the mean becomes zero.</p>

<pre><code>D = matrix.shape[0]
for row in range(D):
    mean, stddev = np.mean(matrix[row,:]), np.std(matrix[row,:])   
    matrix[row,:] = (matrix[row,:] - mean)/stddev
</code></pre>

<p>Now, I can write a naive covariance calculator that looks at all possible pairs of features, and that works perfectly.</p>

<pre><code>def cov_naive(X):
    """"""Compute the covariance for a dataset of size (D,N) 
    where D is the dimension and N is the number of data points""""""
    D, N = X.shape
    covariance = np.zeros((D, D))

    for i in range(D):
        for j in range(i, D):                      
            x = X[i, :]
            y = X[j, :]
            sum_xy = np.dot(x, y) / N
            if i == j:
                covariance[i, j] = sum_xy
            else:                        
                covariance[i, j] = covariance[j, i] = sum_xy
    return covariance
</code></pre>

<p>But, if I try to implement the formula mentioned in the beginning, the result is incorrect. The method I am trying out is as follows:</p>

<pre><code>def cov_naive_2(X):
    """"""Compute the covariance for a dataset of size (D,N) 
    where D is the dimension and N is the number of data points""""""
    D, N = X.shape
    covariance = np.zeros((D, D))

    for i in range(N):                     
        x = X[:, i]
        covariance += x @ x.T
    return covariance / N
</code></pre>

<p>What am I doing wrong here?</p>

<p><strong>Expected output</strong>:</p>

<pre><code>array([[ 1.        ,  0.96833426, -0.4472136 ],
       [ 0.96833426,  1.        , -0.23408229],
       [-0.4472136 , -0.23408229,  1.        ]])
</code></pre>

<p><strong>Actual output from cov_naive_2</strong></p>

<pre><code>array([[3., 3., 3.],
       [3., 3., 3.],
       [3., 3., 3.]])
</code></pre>
",1,64825,,0,49795,49795,2019-12-14T10:27:07.537,2019-12-14T09:41:34.763,1,2,,
19641,1,2017-06-12T12:06:43.070,1,10821,<python><pandas>,How to change a cell in Pandas dataframe with respective frequency of the cell in respective column,"<p>I have a pandas dataframe with binary value columns. I would like to replace values in each cell with its frequency in rspective column in place. My question is how to keep track of the current column while using apply on the subset of columns like here: (to be applied from 8th columns to the end) : </p>

<pre><code>train_data.ix[:,8:] = train_data.ix[:,8:].apply(x: what should come here?)
</code></pre>

<p>I know that <code>train_data.ix[:,col_number].value_counts()[0]</code> will return number of zeros in col_number but how can I use it inside apply function?</p>
",1,19695,,1,15064,32230,2017-06-14T10:11:06.443,2017-06-12T20:53:44.860,1,4,,
26955,1,2018-01-23T12:25:04.987,2,3405,<machine-learning><python><scikit-learn><decision-trees><cross-validation>,validation_curve differs from cross_val_score?,"<p>I'm trying to see how well a decision tree classifier performs on my input. For this I'm trying to use the <a href=""http://scikit-learn.org/stable/modules/learning_curve.html"" rel=""nofollow noreferrer"">validation and learning curves</a> and SKLearn's <a href=""http://scikit-learn.org/stable/modules/cross_validation.html"" rel=""nofollow noreferrer"">cross-validation methods</a>. However, they differ, and I don't know what to make of it.</p>

<p>The validation curve shows up as follows:
<a href=""https://i.stack.imgur.com/MoZqH.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MoZqH.png"" alt=""enter image description here""></a></p>

<p>Based on varying the maximum depth parameter, I'm getting worse and worse cross-val scores. However, when I try the <code>cross_val_score</code>, I get ~72% accuracy reliably:</p>

<p><a href=""https://i.stack.imgur.com/LjBDY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LjBDY.png"" alt=""enter image description here""></a></p>

<p>While I was using the default tree depth for <code>clf</code> here, it still puzzles me how the validation curve never reaches even 0.6, but the cross-val scores are all above 0.7. What does this mean? Why is there a discrepancy?</p>

<hr>

<p>Code for reference below.</p>

<p>For the Validation curve:</p>

<pre><code>import matplotlib.pyplot as plt
import numpy as np

from sklearn.datasets import load_digits
from sklearn.svm import SVC
from sklearn.model_selection import validation_curve

X, y = prepareDataframeX.values, prepareDataframeY.values.ravel()

param_range = np.arange(1, 50, 5)
train_scores, test_scores = validation_curve(
    DecisionTreeClassifier(class_weight='balanced'), X, y, param_name=""max_depth"", param_range=param_range,
    cv=None, scoring=""accuracy"", n_jobs=1)
train_scores_mean = np.mean(train_scores, axis=1)
train_scores_std = np.std(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)
test_scores_std = np.std(test_scores, axis=1)

plt.title(""Validation Curve with Decision Tree Classifier"")
plt.xlabel(""max_depth"")
#plt.xticks(param_range)
plt.ylabel(""Score"")
plt.ylim(0.0, 1.1)
lw = 2
plt.plot(param_range, train_scores_mean, label=""Training score"",
             color=""darkorange"", lw=lw)
plt.fill_between(param_range, train_scores_mean - train_scores_std,
                 train_scores_mean + train_scores_std, alpha=0.2,
                 color=""darkorange"", lw=lw)
plt.plot(param_range, test_scores_mean, label=""Cross-validation score"",
             color=""navy"", lw=lw)
plt.fill_between(param_range, test_scores_mean - test_scores_std,
                 test_scores_mean + test_scores_std, alpha=0.2,
                 color=""navy"", lw=lw)
plt.legend(loc=""best"")
plt.show()
</code></pre>

<p>For the cross-val scores:</p>

<pre><code>clf = DecisionTreeClassifier(class_weight='balanced')
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.33, random_state=42)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
clf.score(X_test, y_test)
</code></pre>

<p><strong>UPDATE</strong>
A comment has been asked about shuffling. When I shuffle the data by </p>

<pre><code>X, y = prepareDataframeX.values, prepareDataframeY.values.ravel()
indices = np.arange(y.shape[0])
np.random.shuffle(indices)
X, y = X[indices], y[indices]
</code></pre>

<p>I get:</p>

<p><a href=""https://i.stack.imgur.com/zaAcd.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zaAcd.png"" alt=""enter image description here""></a></p>

<p>Which makes even less sense to me. What does this mean? </p>
",1,26957,,2,21254,28175,2020-05-19T13:16:33.147,2018-01-23T13:13:52.883,1,8,,
98096,1,2021-07-20T04:01:31.433,2,467,<python><scikit-learn><xgboost>,Possible to use predict_proba without normalizing to 1?,"<p>I'm using <code>xgboost multi-class classifier</code> to predict a collection of things likely to fail. I want to run that prediction, and report anything that the classifier identifies with <code>probability &gt; 75%</code>. However if I use <code>xgb.predict_proba()</code>, the sum of the results in the array add up to 1. So, if there are a lot of things likely to fail, they will all have tiny percentages in the result array.</p>
<p>Looking at <a href=""https://github.com/scikit-learn/scikit-learn/blob/7b136e92acf49d46251479b75c88cba632de1937/sklearn/multiclass.py#L351"" rel=""nofollow noreferrer"">the predict_proba code</a>, I can see where the array is getting normalized. However I can't figure out how to prevent this.</p>
<p>In the end, I think my code would look something like this (except with the pre-normalized probabilities):</p>
<pre><code>probas = xgb.predict_proba(single_element_dataframe)

for class_name in xgb.classes_:
    class_index = np.where(xgb.classes_ == class_name)
    proba = probas[0][class_index]
    if proba &gt; 0:
        print(f&quot;{class_name}: {proba}&quot;)
</code></pre>
<p>Any ideas?</p>
",1,98111,,2,120937,120060,2021-07-21T15:10:04.957,2021-07-21T15:10:04.957,1,1,,
37220,1,2018-08-21T06:46:14.300,3,3136,<python><classification><scikit-learn><class-imbalance><metric>,How to compute G-mean score?,"<p>I would greatly appreciate if you could let me know how to fix the following issue: </p>

<p>I used <a href=""http://scikit-learn.org/stable/modules/generated/sklearn.metrics.fowlkes_mallows_score.html"" rel=""nofollow noreferrer"">sklearn.metrics.fowlkes_mallows_score</a> to compute G-mean score for my binary classification problem, but it produces <code>nan</code>:</p>

<pre><code>AUC: 0.960674 
Accuracy: 0.949137 
Cohen Kappa: 0.484456 
F_measure: 0.508772 
G-mean: 0.833217 
G-mean1: nan 
Matthews: CorrCoef 0.510088 
Precision: 0.391892 
Recall: 0.725 
</code></pre>

<p>However, it should be: <code>0.533031</code></p>

<p>Thanks in advance.</p>
",1,103921,,3,26019,26019,2021-11-08T01:42:51.413,2018-08-21T09:27:41.427,2,5,,
56747,1,2019-08-01T09:49:50.063,1,6583,<machine-learning><python><optimization>,How to use Chi-square test in dataset with negative values,"<p>I could not fully explain the title. In order to use the Chi-square test in my dataset, I am finding the smallest value and add each cell with that value. (for example, the range of data here is [-8,11] so I added +8 to each cell and the range turned to [0,19]).</p>

<p>dataValues variable is DataFrame type that holds my all data and contains ~2000 features, ~1000 rows, dataTargetEncoded variable is Array type that contains results as 0 and 1.</p>

<pre><code>for i in range(len(dataValues.index)):
    for j in range(len(dataValues.columns)):
        dataValues.iat[i, j] += 8

#fit chi2 and get results
bestfeatures = SelectKBest(score_func=chi2, k=""all"")
fit = bestfeatures.fit(dataValues, dataTargetEncoded)
feat_importances = pd.Series(fit.scores_, index=dataValues.columns)

#print top 10 feature
print(feat_importances.nlargest(10).index.values)

# back to normal
for i in range(len(dataValues.index)):
    for j in range(len(dataValues.columns)):
        dataValues.iat[i, j] -= 8
</code></pre>

<p>But this causes performance problems. Another solution I'm thinking of is to normalize it. I wrote a function that looks like this:</p>

<pre><code>def normalization(df):
    from sklearn import preprocessing

    x = df.values  # returns a numpy array
    min_max_scaler = preprocessing.MinMaxScaler()
    x_scaled = min_max_scaler.fit_transform(x)
    df = pd.DataFrame(x_scaled, columns=df.columns)

return df
</code></pre>

<p>My program has accelerated lots, but this time my accuracy has decreased. The feature selection process I have done with the first method produces 0.85 accuracy results, this time I am producing 0.70 accuracy.</p>

<p>I want to get rid of this primitive method, but I also want accuracy to remain constant. How do I proceed? Thank you in advance</p>
",1,57092,,1,78808,78808,2020-05-06T10:54:05.510,2019-08-05T09:43:24.070,2,12,,
9632,1,2016-01-05T10:57:35.867,7,15512,<python><optimization><genetic-algorithms>,Simple example of genetic alg minimization,"<p>I have been looking for a while for examples of how I could find the points at which a function achieves its minimum using a genetic algorithm approach in Python. I looked at  DEAP documentation, but the examples there were pretty hard for me to follow. For example:</p>

<pre><code>def  function(x,y):
     return x*y+3*x-x**2
</code></pre>

<p>I  am looking  for some references on how  I can make a genetic algorithm in which I can feed some initial random values for both x and y (not coming from the same dimensions). Can someone with experience creating and using genetic algorithms give me some guidance on this?</p>
",1,9640,,7,14946,13413,2016-01-05T19:47:52.763,2016-01-05T16:58:45.380,1,4,,
62341,1,2019-10-29T03:28:00.167,1,42,<python><predictive-modeling><unsupervised-learning><supervised-learning>,Doing predictive modeling on predicted value,"<p>It's a project that I'm working on. Here are the steps I took:</p>

<p>I want to make a recommendation service based on the customer data. I first used a collaborative filtering method to get the recommended products. Then I am trying to use that result as a target variable of my random forest model.</p>

<p>The specifics:</p>

<ol>
<li>My data: Columns A, B, C, D, E, F. Each row indicates each customer.</li>
<li>Do unsupervised learning(collaborative filtering) to make a recommendation. Only used column A (which has information about the products they have bought)
Choose one recommendation product for each customer, and make that into a categorical column</li>
<li>Merge that column with the original data, and take out column A</li>
<li>My data: Columns B, C, D, E, F, NEW_COLUMN</li>
<li>Use supervised learning to get important features that explains the NEW_COLUMN</li>
<li>I am trying to use supervised learning on the NEW_COLUMN because I want to get some useful predictions that could be used to explain the reason for the NEW_COLUMN(the recommended products)</li>
</ol>

<p>This is the path that I'm taking. However, is it okay to do predictive modeling with the data that I made using predictive modeling?</p>

<p>Also, if there are any references, it would be a great help!</p>
",1,62498,,1,84508,84508,2019-10-31T21:52:50.743,2019-10-31T02:24:14.017,1,4,,
77828,1,2020-07-16T20:21:30.260,0,37,<python><forecasting><data-analysis>,Forecasting using Python,"<p>I have very less training observations (15). I need to predict 6 months into the future. What forecasting model is best suited for this scenario? Here is how my dataset looks</p>
<p>Month        | Response Rate       |% Promoters          |% Detractors        |%Neutrals</p>
<p>2019-01-01     | 5%                 |60%                 |30%                | 10%</p>
<p>2019-02-01</p>
<p>.....</p>
<p>2020-07-01</p>
<p>I need to predict Response Rate, % Promoters, % Detractors and % Neutrals all of which are numeric variables.</p>
<p>I am new to this forum, so pardon me if I have done any mistake while framing the question.</p>
",1,77831,,0,100882,67502,2020-08-16T12:00:40.057,2020-07-16T20:32:35.203,1,2,,
14021,1,2016-09-15T17:08:55.587,1,7438,<machine-learning><python><dataset><csv>,importing csv data in python,"<p>I have a csv file with around 130 columns and 6000 rows</p>

<p>what is the best way to import them into python, so that I can later use them in a classification algorithm(columns are the labels and rows are individual samples)</p>
",1,14023,,1,24355,,2017-07-16T06:44:57.383,,3,2,,
44476,1,2019-01-24T04:59:16.090,5,12514,<python><pandas><bigdata><data-cleaning>,Merging dataframes in Pandas is taking a surprisingly long time,"<p>I'm trying to merge a list of time series dataframes (could be over 100) using Pandas. The largest file has a size of <span class=""math-container"">$\approx$</span> 50 MB. The number of rows and columns vary (for instance, one file could have 45,000 rows and 20 columns, another has 100 rows and 900 columns), but they all have common columns of ""SubjectID"" and ""Date"", which I'm using to merge the dataframes. I read the dataframes into the list from CSV files, where I know the datatypes for each column. </p>

<p>However, when I try to merge even 10 of the dataframes, it takes around 7 hours, and for all 100, my kernel crashes. Reading all the files in takes about a minute. These aren't files that I would consider ""big data"" or even large files, like in the posts <a href=""https://datascience.stackexchange.com/questions/13059/merging-large-csv-files-in-pandas"">here</a>, <a href=""https://datascience.stackexchange.com/questions/18609/performance-issues-when-merging-two-dataframe-columns-into-one-on-millions-rows"">here</a>, or <a href=""https://datascience.stackexchange.com/questions/2344/pandas-dataframes-memory"">here</a>, so I'm surprised it's taking so long to merge them all. For all 100 dataframes, I'd expect the final dataframe size to be about 1.5 GB, but even that I think Pandas could handle. My code to merge the dataframes is</p>

<pre><code>merged_df = reduce(lambda l,r: l.merge(r, on=['SubjectID', 'Date'], how='outer', suffixes=['_COPYL', '_COPYR']), df_list)
</code></pre>

<p>because I want columns to be added on at if they don't already exist for a subjectID and date (I take care of duplicates later). </p>

<p><strong>EDIT</strong></p>

<p>Some sample dataframes are produced by the following code</p>

<pre><code>import numpy as np
import pandas as pd
from functools import reduce

df1 = pd.DataFrame({'SubjectID': ['A', 'A', 'A', 'B', 'B', 'C', 'A'], 'Date': ['2010-03-14', '2010-03-15', '2010-03-16', '2010-03-14','2010-05-15', '2010-03-14', '2010-03-14'], 'Var1': [np.nan, 1, 4, 7, 90, np.nan, 9], 'Var2': [np.nan, 0, 1, 1, 0, np.nan, 1]})
df2 = pd.DataFrame({'SubjectID': ['A', 'A', 'B', 'B', 'C', 'A'], 'Date': ['2010-03-14', '2010-03-15', '2010-03-14', '2010-05-15', '2010-03-14', '2010-03-14'], 'Var2': [ np.nan, 0, 1, 1, np.nan, 1], 'Var3': [0, 0, 1, np.nan, 0, 1]})

df3 = pd.DataFrame({'SubjectID': ['A', 'A', 'A', 'B', 'B', 'C'], 'Date':['2010-03-14', '2010-03-15', '2010-03-16', '2010-03-14', '2010-05-15', '2010-03-14'], 'Var3': [np.nan, 1, 0, np.nan, 0, 1]})

df1['Date'] = pd.to_datetime(df1['Date'])
df2['Date'] = pd.to_datetime(df2['Date'])
df3['Date'] = pd.to_datetime(df3['Date'])
</code></pre>

<p>My code to merge the dataframes is</p>

<pre><code>df_list = [df1, df2, df3]
merged_df = reduce(lambda l,r: l.merge(r, on=['SubjectID', 'Date'], how='outer', suffixes=['_COPYL', '_COPYR']), df_list)
merged_df = merged_df.groupby([x.split('_COPY')[0] for x in merged_df.columns], 1).apply(lambda x: x.mode(1)[0])
merged_df['Date'] = pd.to_datetime(merged_df['Date'])
</code></pre>

<p>My expected output is</p>

<pre><code>            Date    SubjectID   Var1    Var2    Var3
0     2010-03-14           A    NaN      NaN    0.0
1     2010-03-14           A    NaN      1.0    1.0
2     2010-03-14           A    9.0      1.0    0.0
3     2010-03-14           A    9.0      1.0    1.0
4     2010-03-15           A    1.0      0.0    0.0
5     2010-03-16           A    4.0      1.0    0.0
6     2010-03-14           B    7.0      1.0    1.0
7     2010-05-15           B    90.0     0.0    0.0
8     2010-03-14           C    NaN      NaN    0.0
</code></pre>

<p>So far, I've tried reducing the memory of each column datatype by downcasting, different ways to merge in Pandas and CSV files, converting to a sparse dataframe (my data does have a fair amount of NaN), using Dask, and I'm at the point where I'm considering creating a relational database using sqllite in Python. My versions are python-64 3.7.0, pandas 0.23.4, Ipython 6.5.0, using a Mac OSX Darwin with 32 GB memory. I would think my computer should have no trouble doing this, but it does. Is there really no better way or am I doing something wrong that I'm missing?</p>
",1,60788,,5,65153,65153,2019-09-26T01:35:04.350,2019-01-25T04:55:42.387,2,4,,
45873,1,2019-02-20T12:12:54.127,0,113,<python><scikit-learn><predictive-modeling><prediction><machine-learning-model>,How to launch a Machine Learning model?,"<p>First of all thank you for taking your time to read my question. I have done a Machine Learning model with a dataset (The famous one about Cancer) and I want to know how can I do to predict the results for new variables. I think that I have to keep training the data (often) to have more accured data to use in my prediction but for predicting new data, ¿Is as simple as changing the test data (y variable) to the new data? Thank you so much for taking your time and any help would be appreciate it.</p>
",1,45880,,0,68037,,2019-02-20T13:20:48.363,,1,1,2019-02-21T01:25:24.233,
52630,1,2019-05-26T04:38:57.410,1,2286,<python><data-formats>,.h5 file format does not close properly,"<pre class=""lang-py prettyprint-override""><code>import h5py #added
hf = h5py.File('../images.h5', 'w') #added
hf.close() #added

h5_file = tables.open_file(""images.h5"", mode=""w"")
</code></pre>

<p>I also tried: </p>

<pre class=""lang-py prettyprint-override""><code>h5py.File.close(hf)
</code></pre>

<p>the error that pops up in both cases is:</p>

<pre><code>ValueError: The file 'restricted_images.h5' is already opened.  Please close it before reopening in write mode.
</code></pre>

<p>I've also tried:</p>

<pre class=""lang-py prettyprint-override""><code>if isinstance(obj, h5py.File):   # Just HDF5 files
    obj.close()
</code></pre>

<p>while </p>

<pre class=""lang-py prettyprint-override""><code>In[]: hf
Out[]: &lt;Closed HDF5 file&gt; 
</code></pre>

<p>, the file is not closed yet.</p>
",1,52638,,1,74421,74421,2019-05-27T02:06:18.537,2019-05-27T02:06:18.537,1,2,,
11797,1,2016-05-17T01:37:04.153,9,30316,<python><pandas>,Split a list of values into columns of a dataframe?,"<p>I am new to python and stuck at a particular problem involving dataframes.</p>

<p><a href=""https://i.stack.imgur.com/0KGgA.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/0KGgA.png"" alt=""Sample Image clipped from Spyder""></a></p>

<p>The image has a sample column, however the data is not consistent. There are also some floats and NAN. I need these to be split across columns. That is each unique value becomes a column in the df.</p>

<p>Any insights?</p>
",1,11799,,9,10345,,2019-01-22T13:49:05.290,,3,1,,
93440,1,2021-04-23T07:22:06.150,1,3542,<python><logistic-regression>,Preparing for interview - Logistic regression question,"<p>So I'm doing some exercises to prepare for a interview test. However there's one of the assignments I don't understand. Maybe some of you can explain what they want me to do? It would help me to understand the underlying questionframes I may come across.</p>
<p>This is the assignment:</p>
<p><em>Logit Regression
Have the function LogitRegression(arr) read the input array of 4 numbers x, y, a, b, separated by space, and return an output of two numbers for updated a and b (assume the learning rate is 1). Save up to 3 digits after the decimal points for a and b. The output should be a string in the format: a, b</em></p>
<pre><code>  def LogitRegression(arr):

  # code goes here
  return arr

  # keep this function call here 
  print(LogitRegression(input()))
</code></pre>
<p><em>Logistic regression is a simple approach to do classification, and the same formula is also commonly used as the output layer in neural networks.
We assume both the input and output variables are scalars, and the logistic regression can be written as:<br>
y = 1.0 / (1.0 + exp(-ax - b)) <br>
After observing a data example (x, y), the parameter a and b can be updated using gradient descent with a learning rate.
Examples:<br>
Input: [1, 1, 1, 1] <br>
Output: 0.881, 0.881 <br>
Input: [2.2, 0.0, 5.1, 5.7] <br>
Output: 7.3, 6.7</em> <br></p>
<p>What I don't understand is, do they only give me 4 scalars and want me to train on x, y and then predict a and b. Or is a and be supposed to be weights and bias and I need to return the trained ones? The output numbers in the second example doesn't match probabilities so it can't be that. I might be overthinking this and it's just a simple thing I need to do?</p>
<p>This is the code I've tried:</p>
<pre><code>arr = np.array([2.2, 0.0, 5.1, 5.7])
arr2 = np.array([1.0, 1.0, 1.0,1.0])

def Logit(arr):
    learnrate = 1
    X = arr[0]
    y = arr[1]
    weights = arr[2]
    bias = arr[3]
    
    y_hat = 1/(1+np.exp(np.dot(X, -weights) - bias))
    new_weights = weights + learnrate * (y - y_hat) * X
    new_bias = bias + learnrate*(y - y_hat)
    print(new_weights, new_bias)
    
Logit(arr)
</code></pre>
<p>Output:</p>
<pre><code>2.900000098664297 4.700000044847409
</code></pre>
",1,93441,,1,116522,116522,2022-08-01T20:57:45.393,2021-04-23T09:24:50.247,1,1,,
103031,1,2021-10-11T13:51:03.913,5,1459,<python><scikit-learn><bigdata><jupyter>,Best platform to work with when having millions of rows in dataframe,"<p>I have table with around 20 features and millions of observations (rows).</p>
<p>I need to create model base on this table, however, as it is huge, training models like random forest or XGB takes forever. I'm working mainly with scikit-learn and the XGBoost packages on Jupyter lab server, using python, and i'm struggling with this when the dataframes are very large. Also it is important to mention that I have windows (not Linux).</p>
<p><strong>My question is for people with more experience than I have: what way do you deal with huge dataframes? are there any better packages or platforms to work with when the data is so big?</strong></p>
",1,103069,,5,98535,98535,2021-10-25T07:38:27.683,2021-10-11T14:32:42.907,4,3,,
28825,1,2018-03-08T18:55:29.587,1,272,<machine-learning><python><clustering><jupyter>,How to extract all information by using id,"<p>I need to apply classifier algorithm after clustering. Now after clustering I find the id numbers that which id belongs which cluster. I clustered them into 2 cluster.</p>

<p>Now I need to collect those data by using those id. But I don't know how I can collect all information by using those id.</p>

<p>As I use jupyeter notebook and in main data I have no attribute named id and those id assigned jupyter notebook when I load data from main data file.</p>

<p>This is my main data</p>

<p><a href=""https://i.stack.imgur.com/411Mi.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/411Mi.png"" alt=""enter image description here""></a></p>

<p>Here is my code to find which data belongs which cluster.</p>

<pre><code>x = 0.10
i=0
C_i = np.where(labels == i)[0].tolist()
n_i = len(C_i) # number of points in cluster i

# (2) indices of the points from X to be sampled from cluster i
sample_i = np.random.choice(C_i, int(x * n_i)) 
print (i, sample_i)
</code></pre>

<p>and after clustering I find these ids</p>

<p><a href=""https://i.stack.imgur.com/L7ApH.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/L7ApH.png"" alt=""enter image description here""></a></p>

<p>New addition:</p>

<p>suppose my loading file name is train.
now using <code>train.loc[26]</code> command I get the info of that specific id.</p>

<p><a href=""https://i.stack.imgur.com/krIh5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/krIh5.png"" alt=""enter image description here""></a></p>

<p>But I need to collect all info into a new data frame like as <code>train</code> dataframe</p>
",1,29267,,1,43455,43455,2018-03-19T15:56:26.393,2018-03-19T15:56:26.393,2,3,,
62252,1,2019-10-26T14:46:07.630,1,366,<python><scikit-learn><linear-regression>,Why I am having ValueError in this Linear Regression?,"<pre class=""lang-py prettyprint-override""><code>from sklearn.linear_model import LinearRegression

ClosePrices = data['Close'].tolist()
OpenPrices = data['Open'].tolist()


OpenPrices = np.reshape(OpenPrices, (len(OpenPrices), 1))
ClosePrices = np.reshape(ClosePrices, (len(ClosePrices), 1))

regressor = LinearRegression()
regressor.fit(OpenPrices, ClosePrices)
</code></pre>

<p>I am having the error </p>

<pre><code>ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
</code></pre>

<p>What is the solution?</p>
",1,62260,,1,84376,1330,2019-10-27T00:07:44.053,2019-10-27T00:07:44.053,2,7,,
18481,1,2017-04-20T13:24:46.320,14,8112,<machine-learning><python><predictive-modeling><time-series><scikit-learn>,"How to train model to predict events 30 minutes prior, from multi-dimensionnal timeseries","<p>Experts in my field are capable of <strong>predicting the likelyhood an event (binary spike in yellow)</strong>  30 minutes <strong>before it occurs</strong>. Frequency here is 1 sec, this view represents a few hours worth of data, <strong>i have circled in black where ""malicious"" pattern should be</strong>.
Interactions between the dimensions exist, therefore dimensions cannot be studied individually (or can they?)</p>

<p><a href=""https://i.stack.imgur.com/bhiom.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/bhiom.png"" alt=""enter image description here""></a></p>

<p>I'm trying to build a <strong>supervised</strong> ML model using Scikit Learn <strong>which learns a normal rythm, and detects when symptoms might lead to a spike</strong>. I am lost for which direction to take. I have tried Anomaly detection, but it only works for on the spot detection, not prior.</p>

<p><strong>How could I detect ""malicious"" patterns prior to those events (taking them as target variables) ?</strong></p>

<p>I welcome any advice on which algorithms or data processing pipeline might help, thank you :)</p>
",1,18483,,14,31260,,2020-08-01T13:12:34.087,,2,1,,
18154,1,2017-04-06T08:23:21.717,6,18006,<python><pandas>,How to count categorical values including zero occurrence?,"<p>I want to count number of code by month.
This is my example dataframe.</p>

<pre><code>        id    month  code
0     sally    0  s_A
1     sally    0    s_B
2     sally    0   s_C
3     sally    0   s_D
4     sally    0    s_E
5     sally    0   s_A
6     sally    0    s_A
7     sally    0   s_B
8     sally    0   s_C
9     sally    0   s_A
</code></pre>

<p>I transformed to this Series using count().</p>

<pre><code>df.groupby(['id', 'code', 'month']).m.count()

id      code   month  count
sally  s_A      0    12
                1    10
                2     3
                7    15
</code></pre>

<p>But, I want to include zero occurrence, like this.</p>

<pre><code>id      code   month  count
sally  s_A      0    12
                1    10
                2     3
                3    0
                4    0
                5    0
                6    0
                7    15
                8    0
                9    0
                10   0
                11   0
</code></pre>
",1,24501,,6,22054,,2020-03-24T18:22:48.390,,2,4,,
1246,1,2014-10-10T13:34:11.543,10,8760,<python><gradient-descent><regression>,Stochastic gradient descent based on vector operations?,"<p>let's assume that I want to train a stochastic gradient descent regression algorithm using a dataset that has N samples. Since the size of the dataset is fixed, I will reuse the data T times. At each iteration or ""epoch"", I use each training sample exactly once after randomly reordering the whole training set.</p>

<p>My implementation is based on Python and Numpy. Therefore, using vector operations can remarkably decrease computation time. Coming up with a vectorized implementation of batch gradient descent is quite straightforward. However, in the case of stochastic gradient descent I can not figure out how to avoid the outer loop that iterates through all the samples at each epoch.</p>

<p>Does anybody know any vectorized implementation of stochastic gradient descent? </p>

<p><strong>EDIT</strong>: I've been asked why would I like to use online gradient descent if the size of my dataset is fixed. </p>

<p>From [1], one can see that online gradient descent converges slower than batch gradient descent to the minimum of the empirical cost. However, it converges faster to the minimum of the expected cost, which measures generalization performance. I'd like to test the impact of these theoretical results in my particular problem, by means of cross validation. Without a vectorized implementation, my online gradient descent code is much slower than the batch gradient descent one. That remarkably increases the time it takes to the cross validation process to be completed.</p>

<p><strong>EDIT</strong>: I include here the pseudocode of my on-line gradient descent implementation, as requested by ffriend. I am solving a regression problem.</p>

<pre><code>Method: on-line gradient descent (regression)
Input: X (nxp matrix; each line contains a training sample, represented as a length-p vector), Y (length-n vector; output of the training samples)
Output: A (length-p+1 vector of coefficients)

Initialize coefficients (assign value 0 to all coefficients)
Calculate outputs F
prev_error = inf
error = sum((F-Y)^2)/n
it = 0
while abs(error - prev_error)&gt;ERROR_THRESHOLD and it&lt;=MAX_ITERATIONS:
    Randomly shuffle training samples
    for each training sample i:
        Compute error for training sample i
        Update coefficients based on the error above
    prev_error = error
    Calculate outputs F
    error = sum((F-Y)^2)/n
    it = it + 1
</code></pre>

<p>[1] ""Large Scale Online Learning"", L. Bottou, Y. Le Cunn, NIPS 2003.</p>
",1,2515,,10,2576,2576,2014-11-21T11:50:47.717,2014-11-21T10:02:39.520,2,9,,
55060,1,2019-07-04T14:58:36.710,1,87,<python><keras>,Keras - understanding target dimensions for custom-object YOLOv2,"<p>I'm trying to implement custom object detection by taking a trained YOLOv2 model in Keras, replacing the last layer and retraining just the last layer with new data (~transfer learning).  I have annotated a bunch of pictures with bounding boxes using the YOLO annotation, and put them in two separate folders (""images"" where the .jpgs reside and ""labels"" where the .txt annotations are).</p>

<p>My question is, how do I load these annotations to be compatible with the network architecture?</p>

<p>The YOLO annotation means there's a separate .txt file for each image, containing separate lines for every object on the image. The first number denotes the category and 4 more numbers the bounding box. </p>

<p>Eg. <code>pic1.txt</code> may contain:</p>

<pre><code>2 0.501471 0.488281 0.997059 0.068359
2 0.501838 0.673828 0.996324 0.091797
</code></pre>

<p>Then <code>pic2.txt</code> again</p>

<pre><code>1 0.501821 0.886291 0.993445 0.044202
2 0.502549 0.937220 0.994902 0.029468
</code></pre>

<p>And so on.</p>

<p>Now I've downloaded the YOLOv2 model with trained weights etc. and loaded it in. Removed the las layer and created a new one. Since I only have two categories for objects, I figured I'd need )4 (bounding boxes) + 1 (confidence score) + 2 (categories)) * 5 (anchor/bounding box types) = 35 filters, so I did the following:</p>

<pre><code>yolo_model = load_model(""model_data/yolo.h5"")
yolo_model.layers.pop()

new_layer = Conv2D(35, activation='linear', name='conv2D_23', kernel_size=(1, 1))
inp = yolo_model.input
out = new_layer(yolo_model.layers[-1].output)

model2 = Model(inp, out)
</code></pre>

<p>So the model <em>should</em> be okay I think. However, I have trouble with the target variables.</p>

<p>I read these into an array of arrays with <code>np.shape(train_y)</code> returning <code>(79,)</code>.</p>

<p>Now when I'm trying to train the model, I do:</p>

<pre><code>model2.compile(loss='categorical_crossentropy',
              optimizer=optimizers.RMSprop(lr=1e-4),
              metrics=['acc'])
history = model2.fit(train_images, train_y)
</code></pre>

<p>This, however, returns an error:</p>

<pre><code>ValueError: Error when checking target: expected conv2d_23 to have 4 dimensions, but got array with shape (79, 1)
</code></pre>

<p>I think that's the target values messing things up, but I'm unsure. How could I reformat them to fit? If I flatten it out, I get more than 79 values of course (as one picture may have multiple objects) and I lose which picture had which objects. </p>

<p>As a bonus, I'm including the <code>summary()</code> of my model:</p>

<pre><code>__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 608, 608, 3)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 608, 608, 32) 864         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 608, 608, 32) 128         conv2d_1[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_1 (LeakyReLU)       (None, 608, 608, 32) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 304, 304, 32) 0           leaky_re_lu_1[0][0]              
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 304, 304, 64) 18432       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 304, 304, 64) 256         conv2d_2[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_2 (LeakyReLU)       (None, 304, 304, 64) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 152, 152, 64) 0           leaky_re_lu_2[0][0]              
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 152, 152, 128 73728       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 152, 152, 128 512         conv2d_3[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_3 (LeakyReLU)       (None, 152, 152, 128 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 152, 152, 64) 8192        leaky_re_lu_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 152, 152, 64) 256         conv2d_4[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_4 (LeakyReLU)       (None, 152, 152, 64) 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 152, 152, 128 73728       leaky_re_lu_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 152, 152, 128 512         conv2d_5[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_5 (LeakyReLU)       (None, 152, 152, 128 0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 76, 76, 128)  0           leaky_re_lu_5[0][0]              
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 76, 76, 256)  294912      max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 76, 76, 256)  1024        conv2d_6[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_6 (LeakyReLU)       (None, 76, 76, 256)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 76, 76, 128)  32768       leaky_re_lu_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 76, 76, 128)  512         conv2d_7[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_7 (LeakyReLU)       (None, 76, 76, 128)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 76, 76, 256)  294912      leaky_re_lu_7[0][0]              
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 76, 76, 256)  1024        conv2d_8[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_8 (LeakyReLU)       (None, 76, 76, 256)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 38, 38, 256)  0           leaky_re_lu_8[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 38, 38, 512)  1179648     max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 38, 38, 512)  2048        conv2d_9[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_9 (LeakyReLU)       (None, 38, 38, 512)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 38, 38, 256)  131072      leaky_re_lu_9[0][0]              
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 38, 38, 256)  1024        conv2d_10[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_10 (LeakyReLU)      (None, 38, 38, 256)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 38, 38, 512)  1179648     leaky_re_lu_10[0][0]             
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 38, 38, 512)  2048        conv2d_11[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_11 (LeakyReLU)      (None, 38, 38, 512)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 38, 38, 256)  131072      leaky_re_lu_11[0][0]             
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 38, 38, 256)  1024        conv2d_12[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_12 (LeakyReLU)      (None, 38, 38, 256)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 38, 38, 512)  1179648     leaky_re_lu_12[0][0]             
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 38, 38, 512)  2048        conv2d_13[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_13 (LeakyReLU)      (None, 38, 38, 512)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
max_pooling2d_5 (MaxPooling2D)  (None, 19, 19, 512)  0           leaky_re_lu_13[0][0]             
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 19, 19, 1024) 4718592     max_pooling2d_5[0][0]            
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 19, 19, 1024) 4096        conv2d_14[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_14 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 19, 19, 512)  524288      leaky_re_lu_14[0][0]             
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 19, 19, 512)  2048        conv2d_15[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_15 (LeakyReLU)      (None, 19, 19, 512)  0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 19, 19, 1024) 4718592     leaky_re_lu_15[0][0]             
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 19, 19, 1024) 4096        conv2d_16[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_16 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 19, 19, 512)  524288      leaky_re_lu_16[0][0]             
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 19, 19, 512)  2048        conv2d_17[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_17 (LeakyReLU)      (None, 19, 19, 512)  0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 19, 19, 1024) 4718592     leaky_re_lu_17[0][0]             
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 19, 19, 1024) 4096        conv2d_18[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_18 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 19, 19, 1024) 9437184     leaky_re_lu_18[0][0]             
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 19, 19, 1024) 4096        conv2d_19[0][0]                  
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 38, 38, 64)   32768       leaky_re_lu_13[0][0]             
__________________________________________________________________________________________________
leaky_re_lu_19 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 38, 38, 64)   256         conv2d_21[0][0]                  
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 19, 19, 1024) 9437184     leaky_re_lu_19[0][0]             
__________________________________________________________________________________________________
leaky_re_lu_21 (LeakyReLU)      (None, 38, 38, 64)   0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 19, 19, 1024) 4096        conv2d_20[0][0]                  
__________________________________________________________________________________________________
space_to_depth_x2 (Lambda)      (None, 19, 19, 256)  0           leaky_re_lu_21[0][0]             
__________________________________________________________________________________________________
leaky_re_lu_20 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 19, 19, 1280) 0           space_to_depth_x2[0][0]          
                                                                 leaky_re_lu_20[0][0]             
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 19, 19, 1024) 11796480    concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 19, 19, 1024) 4096        conv2d_22[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_22 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2D_23 (Conv2D)              (None, 19, 19, 35)   35875       leaky_re_lu_22[0][0]             
==================================================================================================
Total params: 50,583,811
Trainable params: 35,875
Non-trainable params: 50,547,936
__________________________________________________________________________________________________
</code></pre>
",1,56547,,1,21254,,2019-07-29T08:46:51.630,,1,1,,
761,1,2014-07-17T09:50:41.437,65,98707,<machine-learning><python><clustering><k-means><geospatial>,"Clustering geo location coordinates (lat,long pairs)","<p>What is the right approach and clustering algorithm for geolocation clustering?</p>

<p>I'm using the following code to cluster geolocation coordinates:</p>

<pre><code>import numpy as np
import matplotlib.pyplot as plt
from scipy.cluster.vq import kmeans2, whiten

coordinates= np.array([
           [lat, long],
           [lat, long],
            ...
           [lat, long]
           ])
x, y = kmeans2(whiten(coordinates), 3, iter = 20)  
plt.scatter(coordinates[:,0], coordinates[:,1], c=y);
plt.show()
</code></pre>

<p>Is it right to use K-means for geolocation clustering, as it uses Euclidean distance, and not <a href=""https://en.wikipedia.org/wiki/Haversine_formula"" rel=""noreferrer"">Haversine formula</a> as a distance function?</p>
",1,764,,65,2533,31513,2023-01-12T18:50:07.947,2017-05-12T08:39:00.347,9,2,,
50934,1,2019-04-25T18:38:32.953,1,137,<python><tensorflow>,Help with my training data,"<p>I'm working on my first NN following a tensorflow tut and trying to use my own data.
After about 80 attempts of formatting my data and trying to load it into a dataset to train I'm throwing the towel.</p>

<p>Here is how my data currently looks</p>

<pre><code>syslog_data = [
[302014,0,0,63878,30,3,1], [302014,0,0,3891,0,0,0], [302014,0,0,15928,0,0,2], [305013,5,0,123,99999,0,3],
[302014,0,0,5185,0,0,0], [305013,5,0,123,99999,0,3], [302014,0,0,56085,0,0,0], [110002,4,2,50074,99999,0,4],
</code></pre>

<p>In this the last item in each list is the label.
If you can tell me if I need to reformat my data and how or just how to get it loaded into a dataset properly.</p>

<p>Thanks for any help or advice you can give</p>

<p>Here is the full code:</p>

<pre><code>import tensorflow as tf
import numpy as np
from tensorflow.keras import layers
from . import syslog

print(tf.VERSION)
print(tf.keras.__version__)

model = tf.keras.Sequential()
# Adds a densely-connected layer with 64 units to the model:
model.add(layers.Dense(64, activation='relu'))
# Add another:
model.add(layers.Dense(64, activation='relu'))
# Add a softmax layer with 10 output units:
model.add(layers.Dense(10, activation='softmax'))

model.compile(optimizer=tf.train.AdamOptimizer(0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

dataset = tf.data.dataset.from_tensor_slices(syslog)

model.fit(dataset, epochs=10, steps_per_epoch=30)
</code></pre>
",1,50937,,1,73150,71218,2019-04-25T19:38:26.667,2019-04-25T19:27:40.540,2,3,,
14774,1,2016-10-27T00:18:08.207,14,37983,<python><visualization><geospatial>,Heatmap on a map in Python,"<p><a href=""https://community.modeanalytics.com/gallery/geographic-heat-map/"" rel=""nofollow noreferrer"">Mode Analytics</a> has a nice heatmap feature, but it is not conducive to comparing maps (only one per report).</p>
<p><a href=""https://i.stack.imgur.com/QhA1I.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QhA1I.png"" alt=""enter image description here"" /></a></p>
<p>What they do allow is data to be pulled easily into a wrapped python notebook.  And then any image in python can easily be added to a report.</p>
<p>So my question is: how do I recreate a heatmap on an actual map in Python?  I've checked out follium and plotly, but neither seem to have similar functionality.</p>
",1,14785,,14,25611,29169,2021-03-13T20:18:03.603,2021-03-13T20:16:52.410,1,3,,
88346,1,2021-01-22T16:08:43.497,4,222,<python><pandas><class-imbalance><missing-data><smote>,Why removing rows with NA values from the majority class improves model performance,"<p>I have an imbalanced dataset like so:</p>
<pre class=""lang-py prettyprint-override""><code>df['y'].value_counts(normalize=True) * 100
</code></pre>
<pre><code>No     92.769441
Yes     7.230559
Name: y, dtype: float64
</code></pre>
<p>The dataset consists of 13194 rows and 37 features.</p>
<p>I have tried numerous attempts to improve the performance of my models by oversampling and undersampling to balance the data, One Class SVM for outlier detection, using different scores, hyperparametre tuning, etc. Some of these methods have improved the performance slightly, but not as much as I would like:</p>
<p>Applying RandomUnderSampling:</p>
<pre class=""lang-py prettyprint-override""><code>
from imblearn.under_sampling import RandomUnderSampler
rus = RandomUnderSampler(random_state=42)
X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)

# Define and fit AdaBoost classifier using undersampled data 
ada_rus = AdaBoostClassifier(n_estimators=100, random_state=42)
ada_rus.fit(X_train_rus,y_train_rus)
y_pred_rus = ada_rus.predict(X_test) 

evaluate_model(y_test, y_pred_rus)
</code></pre>
<p><a href=""https://i.stack.imgur.com/si6Ks.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/si6Ks.png"" alt=""enter image description here"" /></a></p>
<p>Using Oversampling techniques such as SMOTE:</p>
<pre class=""lang-py prettyprint-override""><code>
# SMOTE
from imblearn.over_sampling import SMOTE

# upsample minority class using SMOTE
sm = SMOTE(random_state=42)
X_train_sm, y_train_sm = sm.fit_sample(X_train, y_train)

# Define and fit AdaBoost classifier using upsample data 
ada_sm = AdaBoostClassifier(n_estimators=100, random_state=42)
ada_sm.fit(X_train_sm,y_train_sm)
y_pred_sm = ada_sm.predict(X_test) 

# compare predicted outcome through AdaBoost upsampled data with real outcome
evaluate_model(y_test, y_pred_sm)
</code></pre>
<p><a href=""https://i.stack.imgur.com/CWVDY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/CWVDY.png"" alt=""enter image description here"" /></a></p>
<p>I then decided to attempt removing rows with missing data from samples from the majority class as I saw this in an article. I did this gradually by increasing the threshold (thresh) parameter in pandas dropna function, and each time I removed more rows, the performance improved. Finally, I removed all rows from the majority class with missing data like so:</p>
<pre class=""lang-py prettyprint-override""><code>df_majority_droppedRows = df.query(&quot;y == 'No'&quot;).dropna()
df_minority = df.query(&quot;y == 'Yes'&quot;)
dfWithDroppedRows = pd.concat([df_majority_droppedRows, df_minority])
print(dfWithDroppedRows.shape)
</code></pre>
<pre class=""lang-py prettyprint-override""><code>(1632, 37)
</code></pre>
<p>This reduced the number of rows I have dramatically down to 1632 and changed the distribution in the target variable such that what was perviously the minority class('Yes') was now the majority class:</p>
<pre><code>Yes    58.455882
No     41.544118
Name: y, dtype: float64
</code></pre>
<p>Testing the model, I found it performed best, with high recall and precision values.</p>
<p><a href=""https://i.stack.imgur.com/3Z4kc.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/3Z4kc.png"" alt=""enter image description here"" /></a></p>
<p>So my questions are,</p>
<ol>
<li><p>Why did this method outperform other oversampling and undersampling techniques?</p>
</li>
<li><p>Is it acceptable that what was previously a minority class is now the majority class or can this cause overfitting?</p>
</li>
<li><p>Is it realistic to build a model that relies on input with no missing data for the majority class samples?</p>
</li>
</ol>
<p><strong>EDIT</strong></p>
<p>In response to the questions in the comment by @Ben Reiniger:</p>
<ul>
<li>I dealt with the missing values like in the data by using KNNImputer for numeric data and SimpleImputer for categorical data like so:</li>
</ul>
<pre class=""lang-py prettyprint-override""><code>
def preprocess (X):
    # define categorical and numeric transformers
    numeric_transformer = Pipeline(steps=[
        ('knnImputer', KNNImputer(n_neighbors=2, weights=&quot;uniform&quot;)),
        ('scaler', StandardScaler())])

    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))])

    preprocessor = ColumnTransformer(transformers=[
        ('cat', categorical_transformer, selector(dtype_include=['object'])),
        ('num', numeric_transformer, selector(dtype_include=['float64','int64']))
    ])

    X = pd.DataFrame(preprocessor.fit_transform(X))
    return X 
</code></pre>
<ul>
<li>After dropping rows, I defined the feature of matrix and the target, preprocessed and then split the data, like so:</li>
</ul>
<pre class=""lang-py prettyprint-override""><code># make feature matrix and target matrix
X = dfWithDroppedRows.drop(columns=['y'])
y = dfWithDroppedRows['y']

# encode target variable 
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

# preprocess feature matrix
X=preprocess(X)

# Split data into training and testing data
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)
</code></pre>
<ul>
<li>Finally, to calculate if the missing values are identically distributed (originally) in the two classes, I ran the following</li>
</ul>
<pre class=""lang-py prettyprint-override""><code>np.count_nonzero(df.query(&quot;y == 'No'&quot;).isna()) / df.query(&quot;y == 'No'&quot;).size
</code></pre>
<pre><code>0.2791467938526762
</code></pre>
<pre class=""lang-py prettyprint-override""><code>np.count_nonzero(df.query(&quot;y == 'Yes'&quot;).isna()) / df.query(&quot;y == 'Yes'&quot;).size
</code></pre>
<pre><code>0.24488639582979205
</code></pre>
<p>So the majority class has about 28% missing data and the minority class has about 25% missing data.</p>
",1,88369,,4,99648,99648,2021-01-26T20:41:02.787,2021-01-26T20:41:02.787,1,2,,
27295,1,2018-01-31T13:28:51.617,1,91398,<python><statistics><scipy>,ValueError: operands could not be broadcast together with shapes while using two sample independent t test,"<p>I am trying to perform two sample t test. My data set consists of 744 rows and 186 columns for which I have calculated total sum and mean. I need to perform two sample t test. My csv looks like this from which I have to calculate ttest and rank sum test for each row as individual row denotes separate ID and have the corresponding values :</p>

<pre><code>SRA ID  ERR169499            ERR169498           ERR169497
Label   1                    0                   1
TaxID   PRJEB3251_ERR169499  PRJEB3251_ERR169499 PRJEB3251_ERR169499
333046  0.05                 0.99                99.61
1049    0.03                 2.34                34.33
337090  0.01                 9.78                23.22
</code></pre>

<p>The labels 0 and 1 are for case and control respectively. So far I have done this:</p>

<pre><code>import pandas as pd
import numpy as np
from scipy.stats import ttest_ind
from scipy.stats import ranksums

def transposer(filename):
file = open(filename, 'rt')
pd.read_csv(file).T.to_csv(str(filename).split(""/"")
[-1].split(""."")[0]+'_transposed.csv',header=False)


pd.read_csv('project.csv').T.to_csv('transposed.csv', header=False)

file = open('transposed.csv', 'rt')
out = open('final_out.csv', 'w')
meta = open('Meta3251.csv', 'rt')
contents = {}
for ids in meta:
    contents[ids.split(',')[1]]=ids.split(',')[-1]
count = 0
for row in file:
    if count == 0:
    out.write('SraID, Label,'+row)
    count=1
else:

    try:
        pid = row.split(',')[0].split('_')[1]
out.write(pid.replace('\n','')+','+contents[pid].replace('\n','')
+','+str(row))
        out.flush()
    except:
        print(pid)
        pass
file.close()
out.close()
transposer('final_out.csv')
file1 = open('final_out_transposed.csv','rt')
label = []
data = {}

x = open('final_out_transposed.csv','rt')
for r in x:
    datas = r.split(',')
    if datas[0] == ' Label':
        label.append(r.split("","")[1:])
label = label[0]
label[-1] = label[-1].replace('\n','')
counter = len(label)
for row in file1:
    content = row.split(',')
if content[0]=='SraID' or content[0]== 'TaxID' or content[0]==' Label':
    pass
else:
    dt = row.split(',')
    dt[-1] = dt[-1].replace('\n','')

    data[dt[0]]=dt[1:]
keys = list(data)
sum_file = open('sum.csv','w')
sum_file.write('TaxId,sum_case,sum_ctrl,case_count,
ctrl_count,case_mean,ctrl_mean,\n')
for key in keys:
    sum_case = 0
    sum_ctrl = 0
    count_case = 0
    count_ctrl = 0
    mean_case = 0
    mean_ctrl = 0
for i in range(counter):
    if label[i] == '0':
        sum_case=np.float64(sum_case)+np.float64(data[key][i])
        count_case = count_case+1
        mean_case = sum_case/count_case
    else:
        sum_ctrl = np.float64(sum_ctrl)+np.float64(data[key][i])
        count_ctrl = count_ctrl+1
        mean_ctrl = sum_ctrl/count_ctrl
sum_file.write(key+','+str(np.float64((sum_case)))+','

+str(np.float64((sum_ctrl)))+','+str(np.float64((count_case)))        
+','+str(np.float64((count_ctrl)))+','+str(np.float64((mean_case)))
+','+str(np.float64((mean_ctrl)))+'\n')
sum_file.flush()
sum_file.close()

df  = pd.read_csv('final_out_transposed.csv', header=[1,2], index_col=[0])
case = df.xs('0', axis=1, level=0).dropna()
ctrl = df.xs('1', axis=1, level=0).dropna()
(tt_val, p_ttest) = ttest_ind(case, ctrl, equal_var=False)
print (tt_val)
print (p_ttest)
</code></pre>

<p>I am getting the error: </p>

<blockquote>
  <p>ValueError: operands could not be broadcast together with shapes (92,) (95,)</p>
</blockquote>

<p>How can I handle this error. I cannot change my data.</p>
",1,27342,,1,45433,29575,2018-02-01T14:31:17.480,2018-02-01T01:36:22.817,1,12,,
42465,1,2018-12-11T16:56:47.267,2,4260,<machine-learning><python><pandas>,Do I need to convert booleans to ints to enter them in a machine learning algorithm?,"<p>My dataset contains a lot of columns with booleans do I really need to change them so I can insert them into the algorithm?</p>

<p>I'm gonna use KNN right now but will test other algorithms later so I'm trying to ready up my dataset</p>
",1,42471,,2,64138,,2018-12-11T18:33:07.297,,1,2,,
109823,1,2022-04-09T12:33:09.370,0,151,<python><r><conda>,Multiple conda enviroments in (R) functions using reticulate,"<p>For an internally used R package I need to have certain functions load python environments to do part of the processing. The environment cannot be the same one for all functions, unfortunately, due to python package conflicts. So I need to find out how to attach to different conda environments.</p>
<p>But I actually fail before that, as what I get when I attach an env:</p>
<pre><code>&gt; reticulate::use_condaenv(&quot;pyannote&quot;)
ERROR: The requested version of Python ('/Users/frkkan96/opt/anaconda3/envs/pyannote/bin/python') cannot be used, as another version of Python
('/Users/frkkan96/Library/r-miniconda/envs/r-reticulate/bin/python') has already been initialized. Please restart the R session if you need to attach reticulate to a different version of Python.
Error in use_python(python, required = required) : 
  failed to initialize requested version of Python
&gt; library(reticulate)
&gt; reticulate::use_condaenv(&quot;pyannote&quot;)
ERROR: The requested version of Python ('/Users/frkkan96/opt/anaconda3/envs/pyannote/bin/python') cannot be used, as another version of Python
('/Users/frkkan96/Library/r-miniconda/envs/r-reticulate/bin/python') has already been initialized. Please restart the R session if you need to attach reticulate to a different version of Python.
Error in use_python(python, required = required) : 
  failed to initialize requested version of Python
</code></pre>
<p>The issues I have then are:</p>
<p>1 - How do I make sure that the correct python is used when I load a conda environment? I would have assumed that I could force a re-discover of the python environment somehow after <code>reticulate</code> has been loaded, but I have so far failed:</p>
<pre><code>&gt; py_discover_config(use_environment = &quot;pyannote&quot;)
python:         /Users/frkkan96/Library/r-miniconda/envs/r-reticulate/bin/python
libpython:      /Users/frkkan96/Library/r-miniconda/envs/r-reticulate/lib/libpython3.6m.dylib
pythonhome:     /Users/frkkan96/Library/r-miniconda/envs/r-reticulate:/Users/frkkan96/Library/r-miniconda/envs/r-reticulate
version:        3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:16)  [GCC Clang 11.0.1]
numpy:          /Users/frkkan96/Library/r-miniconda/envs/r-reticulate/lib/python3.6/site-packages/numpy
numpy_version:  1.19.5
</code></pre>
<p>2 - In my case, I need to be able to switch conda environment to the one appropriate for the R function called. How do I specify the python environment to use on the fly?</p>
<p>I appreciate all the help I can get on these (probably related) isses.</p>
<p>Fredrik</p>
",1,110554,,0,134383,,2022-05-02T09:40:58.153,,1,1,,
6144,1,2015-06-18T16:41:43.320,7,397,<python><statistics><feature-scaling>,Sensitivity to scaling of features in a multivariate gaussians,"<p>I'm using the HMMLearn python package for hidden markov models.  That implementation is build on multivariate gaussian distributions.</p>

<p>So I have a string of features.  How sensitive are gaussians to vastly different feature scales?  Will it be really skewed if one feature is scaled between 0 and 1, and another is scaled between 0 and 1e8?</p>
",1,6524,,7,10187,,2015-07-21T03:40:23.157,,1,2,,
108832,1,2022-03-07T10:08:00.520,3,205,<machine-learning><python><nlp><text-mining>,How to do sentence segmentation without loosing sentence's subject?,"<p>I have some text with different lengths, I want to split it into separate clauses but I also want to preserve the subject</p>
<p>For example;</p>
<pre><code># single subject
Original: &quot;Coffee is very good, but wasn't hot enough&quot;
split: [&quot;Coffee is very good&quot;, &quot;Coffee wasn't hot enough&quot;]

Original: &quot;Joe was the top performer of last year's dance competition, he is also a good singer&quot;
split: [&quot;Joe was the top performer of last year's dance competition&quot;, &quot;Joe is a good singer&quot;]

# multiple subjects
Original: &quot;Delicious food service, but we struggled with the app.&quot;
split: [&quot;Delicious food service&quot;, &quot;We struggled with the app&quot;]
</code></pre>
<p>I don't know how to achieve this, we can maybe split sentences based on punctuation and conjunctions (may not be accurate) but how do we preserve its subject.</p>
<p>Please let me know if you need more information.</p>
",1,108929,,3,88390,,2022-03-10T05:15:21.580,,2,1,,
105101,1,2021-12-14T11:51:56.330,1,2401,<python><keras><multiclass-classification><metric>,Which Keras metric for multiclass classification,"<p>I have a <strong>multiclass classification</strong> data where the <strong>target</strong> has <strong>11 classes</strong>. I am trying to build a Neural Net using <strong>Keras</strong>. I am using <code>softmax</code> as activation function and <code>categorical_crossentropy</code> as the loss function. I have one hot encoded the target before passing it into the net. The issue I am facing is <strong>which Keras metric should I use for this purpose?</strong> The <a href=""https://keras.io/api/metrics/"" rel=""nofollow noreferrer"">official documentation</a> does not mention which metric is suitable for multiclass classification.</p>
<p><a href=""https://stackoverflow.com/questions/59305514/tensorflow-how-to-use-tf-keras-metrics-in-multiclass-classification"">This</a> link mentions to use <code>categorical_accuracy</code> as the metric for multiclass classification but other than that, all other question on this site are about multilabel classification metrics like <a href=""https://stackoverflow.com/questions/53874485/multi-label-classification-keras-metrics/59931955#59931955"">this</a> and <a href=""https://datascience.stackexchange.com/questions/25752/how-does-keras-calculate-accuracy-for-multi-label-classification"">this</a> link.</p>
<p>Is there any implementation of lets say <code>f1_score</code> in Keras using the custom metric function, since <code>f1_score</code> is the go to metric for multiclass classification I guess?</p>
<p><strong>EDIT 1:</strong></p>
<p>Would something like this work using the custom metric functionality in Keras?</p>
<pre><code>from sklearn.metrics import f1_score

def my_metric_fn(y_true, y_pred):
    f1 = f1_score(y_true, y_pred)
    return f1

model = Sequential()

model.add(Dense(input_dim = 12, units = 128, activation = 'relu', kernel_initializer = 'he_uniform'))
model.add(Dense(units = 64, activation = 'relu', kernel_initializer = 'he_uniform'))
model.add(Dense(units = 32, activation = 'relu', kernel_initializer = 'he_uniform'))
model.add(Dense(units = 11,  activation = 'softmax', kernel_initializer = 'glorot_uniform'))
model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = [my_metric_fn])
history = model.fit(train_x5, train_encoded, validation_split = 0.2, epochs = 5, batch_size = 1000)
</code></pre>
<p><strong>EDIT 2:</strong> This is giving me an error in the last line as follows:
<code> OperatorNotAllowedInGraphError: using a tf.Tensor as a Python bool is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.</code></p>
",1,105114,,1,119921,119921,2021-12-14T17:17:28.103,2021-12-14T16:25:16.717,1,6,,
81479,1,2020-09-09T21:04:47.580,1,1536,<python><scikit-learn><data-imputation><pipelines>,sklearn - How to create a sequential pipeline,"<p><strong>Update:</strong> The examples in this post were updated</p>
<p>I am reposting this question here after not getting a clear answer in a <a href=""https://stackoverflow.com/questions/63475704/sklearn-columntransformer-duplicate-columns-in-transformers"">previous SO post</a></p>
<p>I am looking for a help building a data preprocessing pipleline using sklearn's ColumnTransformer functions where the some features are preprocesses sequentially. I am well aware of how to build separate pipelines for different subsets of features. For example, my pipleline may look something like this:</p>
<pre><code>from sklearn.compose import ColumnTransformer 
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import Normalizer

ColumnTransformer(remainder='passthrough',
                  transformers=[
                              ('num_impute', SimpleImputer(strategy='median'), ['feat_1', 'feat_2'])
                                ('Std', StandardScaler(), ['feat_3', 'feat_4']),
                                ('Norm', Normalizer(), ['feat_5', 'feat_6']),
                                ])
</code></pre>
<p>Notice that each transformer is provided a unique set of features.</p>
<p>The issue I am encountering is how to apply sequential processing for the same features (different combinations of transformations and features). For example,</p>
<pre><code>ColumnTransformer(remainder='passthrough',
                  transformers=[
                              ('num_impute', SimpleImputer(strategy='median'), ['feat_1', 'feat_2', , 'feat_5'])
                              ('Std', StandardScaler(), ['feat_1', 'feat_2','feat_3', 'feat_4', 'feat_6']),
                              ('Norm', Normalizer(), ['feat_1', 'feat_6'])

                                ])
</code></pre>
<p>Notice that feat_1 was provided to three transformations, feat_2 was provided to two transformers (impute and Std), and feat_6 was provided to two transformers (Std and Norm)</p>
<p>A pipeline like this will two duplicate columns for feat_2 and feat_3, and three duplicate columns for feat_1. Building a separate pipeline for each transformation/feature combination is not scalable.</p>
",1,81559,,1,89795,89795,2020-09-11T18:45:45.167,2020-09-11T18:45:45.167,2,4,,
16326,1,2017-01-15T13:34:00.177,2,506,<machine-learning><python><predictive-modeling><probability>,Classification problem approach with Python,"<p>I am a Python beginner, just getting into machine learning and need advice on the approach i should use for my problem.</p>

<p>Here is an example of my data-set.
<a href=""https://i.stack.imgur.com/STKE0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/STKE0.png"" alt=""enter image description here""></a></p>

<p>Where the RESULT is a corresponding INDEX in each VALUES array and every row is a separate array, i need to find the probability of each index of an array being the RESULT based on its configuration, where the overall configuration and distribution is most important rather than any individual value.</p>
",1,16327,,2,27962,27962,2017-01-20T05:39:10.783,2017-01-20T05:39:10.783,1,1,,
37914,1,2018-09-07T01:07:58.037,1,2764,<python><dataframe>,Coding Problem - Extracting values from a column and forming a new dataframe [edited],"<p><a href=""https://i.stack.imgur.com/lDBvw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lDBvw.png"" alt=""dataframeimage""></a>The problem statement requires extracting certain weather parameters for every hour in a particular date as denoted in the dataframe. The column 'hourly' consists of 24 lists in each entry, denoting weather parameters for each hour on that particular date. Is there a way that I can extract the parameter 'CloudCover' for all those 24 hours and form a new dataframe whose columns denote the hours in the day and the corresponding CloudCover value for a single date ?</p>

<p>Edit: Based on the suggestions given below, I tinkered my code and a new problem has come up. While the code suggested by @jahKnows works perfectly fine, It gives only the first value of any parameter in the hourly column entries. For eg. in the date 01-01-2016, the corresponding hourly column entry has 24 values of cloudCover. But the code suggested below gives only the first CloudCover value and moves on to the next date leaving out the other 23 CloudCover values in that particular date. Can you suggest me changes to tackle this problem ? I have attached the updated notebook link and the original dataset link below.</p>

<p>Notebook link(edited): <a href=""https://anaconda.org/vishwa989796/okayishtrial/notebook"" rel=""nofollow noreferrer"">https://anaconda.org/vishwa989796/okayishtrial/notebook</a></p>

<p>data set link: <a href=""https://drive.google.com/drive/folders/1wMNOZapHib9AyYFaLdA1jdEdx9DdLnXx"" rel=""nofollow noreferrer"">https://drive.google.com/drive/folders/1wMNOZapHib9AyYFaLdA1jdEdx9DdLnXx</a></p>
",1,37915,,1,58743,58743,2018-09-07T13:26:03.350,2018-09-07T13:26:03.350,1,6,,
